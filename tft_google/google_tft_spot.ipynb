{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c60b608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce623238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker version: 2.103.0\n",
      "Checkpointing Path: s3://sagemaker-us-east-1-551329315830/checkpoints/checkpoint-8faddec6\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import uuid\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "print('SageMaker version: ' + sagemaker.__version__)\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/DEMO-pytorch-cnn-cifar10'\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "checkpoint_suffix = str(uuid.uuid4())[:8]\n",
    "checkpoint_s3_path = 's3://{}/checkpoints/checkpoint-{}'.format(bucket, checkpoint_suffix)\n",
    "\n",
    "print('Checkpointing Path: {}'.format(checkpoint_s3_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5c1ea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity_df = pd.read_csv(\"tft/outputs/data/electricity/hourly_electricity.csv\")\n",
    "\n",
    "electricity_df['hours_from_start'] = electricity_df['hours_from_start'].astype(int)\n",
    "electricity_df['power_usage'] = electricity_df['power_usage'].astype(float)\n",
    "electricity_df['hour'] = electricity_df['hour'].astype(int)\n",
    "electricity_df['day_of_week'] = electricity_df['day_of_week'].astype(int)\n",
    "electricity_df['categorical_id'] = electricity_df['categorical_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce9e931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "def save_local_and_upload_s3(data_df, sagemaker_session, bucket, dir_name = \"timeseries_data\", data_filename = \"data\"):\n",
    "    #create data directory if not exist\n",
    "    if os.path.isdir(dir_name):\n",
    "        print(\"Checkpointing directory {} exists\".format(dir_name))\n",
    "    else:\n",
    "        print(\"Creating Checkpointing directory {}\".format(dir_name))\n",
    "        os.makedirs(dir_name)\n",
    "\n",
    "    data_df.to_parquet('{}/{}.parquet'.format(dir_name, data_filename))   \n",
    "    print(\"saved raw data to {}/{}.parquet\".format(dir_name, data_filename))\n",
    "    \n",
    "    return sagemaker_session.upload_data(path=dir_name, bucket=bucket, key_prefix='data/{}'.format(dir_name))\n",
    "\n",
    "\n",
    "\n",
    "def metadata_json_upload_s3(training_metadata, sagemaker_session, bucket, dir_name = \"timeseries_data\", metadata_filename = \"data_metadata\"):\n",
    "    #create data directory if not exist\n",
    "    if os.path.isdir(dir_name):\n",
    "        print(\"Checkpointing directory {} exists\".format(dir_name))\n",
    "    else:\n",
    "        print(\"Creating Checkpointing directory {}\".format(dir_name))\n",
    "        os.makedirs(dir_name)\n",
    "    \n",
    "    with open('{}/{}.json'.format(dir_name, metadata_filename), 'w') as fp:\n",
    "        json.dump(training_metadata, fp)\n",
    "        print(\"saved metadata to {}/{}.json\".format(dir_name, metadata_filename))\n",
    "    \n",
    "    return sagemaker_session.upload_data(path=dir_name, bucket=bucket, key_prefix='data/{}'.format(dir_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41d8931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_prediction_length = 24\n",
    "# max_encoder_length = 24 * 7\n",
    "# num_epochs = 100\n",
    "# early_stopping_patience = 5\n",
    "# multiprocessing_workers = 5\n",
    "\n",
    "\n",
    "# dropout_rate = 0.1\n",
    "# hidden_layer_size = 160\n",
    "# learning_rate = 0.001\n",
    "# minibatch_size = 64\n",
    "# max_gradient_norm = 0.01\n",
    "# num_heads = 4\n",
    "# stack_size =  1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c01afd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpointing directory timeseries_data/electricity exists\n",
      "saved raw data to timeseries_data/electricity/electricity_training_data.parquet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-551329315830/data/timeseries_data/electricity'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "inputs = save_local_and_upload_s3(electricity_df, sagemaker_session, bucket,\n",
    "                                  dir_name = \"timeseries_data/electricity\",\n",
    "                                  data_filename=\"electricity_training_data\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5088f234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpointing directory timeseries_data/electricity exists\n",
      "saved metadata to timeseries_data/electricity/electricity_metadata.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-551329315830/data/timeseries_data/electricity'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_prediction_length = 24\n",
    "max_encoder_length = 24 * 7\n",
    "\n",
    "\n",
    "training_metadata = {}\n",
    "training_metadata['time_idx'] = \"hours_from_start\"\n",
    "training_metadata['target'] = \"power_usage\"\n",
    "training_metadata['group_ids'] = [\"categorical_id\"]\n",
    "training_metadata['min_encoder_length'] = max_encoder_length      # keep encoder length long (as it is in the validation set)\n",
    "training_metadata['max_encoder_length'] = max_encoder_length\n",
    "training_metadata['min_prediction_length'] = 1      \n",
    "training_metadata['max_prediction_length'] = max_prediction_length\n",
    "training_metadata['static_categoricals'] = [\"categorical_id\"]\n",
    "training_metadata['static_reals'] = []\n",
    "training_metadata['time_varying_known_categoricals'] = []\n",
    "training_metadata['variable_groups'] = {}\n",
    "training_metadata['time_varying_known_reals'] = [\"hours_from_start\", \"day_of_week\", \"hour\"]\n",
    "training_metadata['time_varying_unknown_categoricals'] = []\n",
    "training_metadata['time_varying_unknown_reals'] = []\n",
    "training_metadata['target_normalizer'] = {\n",
    "                            \"normalized_groups\": [\"categorical_id\"],\n",
    "                            \"normalization_transformation\": 'softplus'\n",
    "                        }\n",
    "training_metadata['add_relative_time_idx'] = True\n",
    "training_metadata['add_target_scales'] = True\n",
    "training_metadata['add_encoder_length'] = True\n",
    "training_metadata['allow_missing_timesteps'] = True\n",
    "\n",
    "training_metadata['training_cutoff'] = int(electricity_df[training_metadata['time_idx']].max() - max_prediction_length)\n",
    "# training_metadata['training_cutoff'] = int(electricity_df[training_metadata['time_idx']].max())\n",
    "\n",
    "# upload metadata\n",
    "metadata_json_upload_s3(training_metadata, sagemaker_session, bucket, \n",
    "                                    dir_name = \"timeseries_data/electricity\",\n",
    "                                    metadata_filename=\"electricity_metadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c404fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "        'data-filename': \"electricity_training_data.parquet\",\n",
    "        'metadata-filename': \"electricity_metadata.json\",\n",
    "    \n",
    "        'max-prediction-length' : max_prediction_length,\n",
    "        'max-encoder-length' : max_encoder_length,\n",
    "#         'num-epochs' : 2,\n",
    "        'num-epochs' : 100,\n",
    "\n",
    "        'early-stopping-patience' : 5,\n",
    "        'multiprocessing-workers' : 5,\n",
    "\n",
    "\n",
    "        'dropout-rate' : 0.1,\n",
    "        'hidden-layer-size' : 160,\n",
    "        'learning-rate' : 0.001,\n",
    "        'minibatch-size' : 64,\n",
    "        'max-gradient-norm' : 0.01,\n",
    "        'num-heads' : 4\n",
    "    \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c42ecd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_spot_instances = True\n",
    "max_run=36000      # in seconds, after this, job will be terminated\n",
    "max_wait = 10 * max_run if use_spot_instances else None\n",
    "local_image_name = 'pytorch-tft-container-test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586e20e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-01 05:10:37 Starting - Starting the training job...\n",
      "2022-09-01 05:11:00 Starting - Insufficient capacity error from EC2 while launching instances, retrying!ProfilerReport-1662009037: InProgress\n",
      "......................................................"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.debugger import TensorBoardOutputConfig\n",
    "\n",
    "\n",
    "tensorboard_output_config = TensorBoardOutputConfig(\n",
    "    s3_output_path='s3://sagemaker-us-east-1-551329315830/tensorboard',\n",
    "    container_local_output_path='/lightning_logs'\n",
    ")\n",
    "\n",
    "spot_estimator  = PyTorch(entry_point='../TFT_docker/TFT.py',\n",
    "                            dependencies=['../TFT_docker/requirements.txt'],\n",
    "                            role=role,\n",
    "                            framework_version='1.7.1',\n",
    "                            py_version='py3',\n",
    "                            instance_count=1,\n",
    "#                             instance_type='local',\n",
    "                            instance_type='ml.p3.2xlarge',\n",
    "#                             instance_type='ml.p2.xlarge',\n",
    "                            base_job_name='tft-pytorch-spot-1',\n",
    "                            hyperparameters=hyperparameters,\n",
    "                            checkpoint_s3_uri=checkpoint_s3_path,\n",
    "                            debugger_hook_config=False,\n",
    "                            input_mode = 'File',\n",
    "                            use_spot_instances=use_spot_instances,\n",
    "                            max_run=max_run,\n",
    "                            max_wait=max_wait,\n",
    "                            tensorboard_output_config=tensorboard_output_config\n",
    "                           )\n",
    "\n",
    "spot_estimator.fit(\n",
    "                inputs,\n",
    "                logs = 'All'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d224f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_estimator.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74a192a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9f41a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdf6760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc9a112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b660426",
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97737017",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(electricity_df['categorical_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70035c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(electricity_df['id'] != electricity_df['categorical_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1975168d",
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0e2311",
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity_df.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
