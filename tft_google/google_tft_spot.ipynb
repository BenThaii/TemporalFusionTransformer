{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cd08a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b487cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker version: 2.103.0\n",
      "Checkpointing Path: s3://sagemaker-us-east-1-551329315830/checkpoints/checkpoint-f6a2e338\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import uuid\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "print('SageMaker version: ' + sagemaker.__version__)\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/DEMO-pytorch-cnn-cifar10'\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "checkpoint_suffix = str(uuid.uuid4())[:8]\n",
    "checkpoint_s3_path = 's3://{}/checkpoints/checkpoint-{}'.format(bucket, checkpoint_suffix)\n",
    "\n",
    "print('Checkpointing Path: {}'.format(checkpoint_s3_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c268fe3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tft/outputs/data/electricity/hourly_electricity.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-11e5e3f04648>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0melectricity_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tft/outputs/data/electricity/hourly_electricity.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0melectricity_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hours_from_start'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melectricity_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hours_from_start'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0melectricity_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'power_usage'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melectricity_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'power_usage'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0melectricity_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hour'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melectricity_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hour'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tft/outputs/data/electricity/hourly_electricity.csv'"
     ]
    }
   ],
   "source": [
    "electricity_df = pd.read_csv(\"tft/outputs/data/electricity/hourly_electricity.csv\")\n",
    "\n",
    "electricity_df['hours_from_start'] = electricity_df['hours_from_start'].astype(int)\n",
    "electricity_df['power_usage'] = electricity_df['power_usage'].astype(float)\n",
    "electricity_df['hour'] = electricity_df['hour'].astype(int)\n",
    "electricity_df['day_of_week'] = electricity_df['day_of_week'].astype(int)\n",
    "electricity_df['categorical_id'] = electricity_df['categorical_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "036323c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "def save_local_and_upload_s3(data_df, sagemaker_session, bucket, dir_name = \"timeseries_data\", data_filename = \"data\"):\n",
    "    #create data directory if not exist\n",
    "    if os.path.isdir(dir_name):\n",
    "        print(\"Checkpointing directory {} exists\".format(dir_name))\n",
    "    else:\n",
    "        print(\"Creating Checkpointing directory {}\".format(dir_name))\n",
    "        os.mkdir(dir_name)\n",
    "\n",
    "    data_df.to_parquet('{}/{}.parquet'.format(dir_name, data_filename))   \n",
    "    print(\"saved raw data to {}/{}.parquet\".format(dir_name, data_filename))\n",
    "    \n",
    "    return sagemaker_session.upload_data(path=dir_name, bucket=bucket, key_prefix='data/{}'.format(dir_name))\n",
    "\n",
    "\n",
    "\n",
    "def metadata_json_upload_s3(training_metadata, sagemaker_session, bucket, dir_name = \"timeseries_data\", metadata_filename = \"data_metadata\"):\n",
    "    #create data directory if not exist\n",
    "    if os.path.isdir(dir_name):\n",
    "        print(\"Checkpointing directory {} exists\".format(dir_name))\n",
    "    else:\n",
    "        print(\"Creating Checkpointing directory {}\".format(dir_name))\n",
    "        os.mkdir(dir_name)\n",
    "    \n",
    "    with open('{}/{}.json'.format(dir_name, metadata_filename), 'w') as fp:\n",
    "        json.dump(training_metadata, fp)\n",
    "        print(\"saved metadata to {}/{}.json\".format(dir_name, metadata_filename))\n",
    "    \n",
    "    return sagemaker_session.upload_data(path=dir_name, bucket=bucket, key_prefix='data/{}'.format(dir_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "399c62e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_prediction_length = 24\n",
    "# max_encoder_length = 24 * 7\n",
    "# num_epochs = 100\n",
    "# early_stopping_patience = 5\n",
    "# multiprocessing_workers = 5\n",
    "\n",
    "\n",
    "# dropout_rate = 0.1\n",
    "# hidden_layer_size = 160\n",
    "# learning_rate = 0.001\n",
    "# minibatch_size = 64\n",
    "# max_gradient_norm = 0.01\n",
    "# num_heads = 4\n",
    "# stack_size =  1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6545f54",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'electricity_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-bb263cd78b29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m inputs = save_local_and_upload_s3(electricity_df, sagemaker_session, bucket,\n\u001b[0m\u001b[1;32m      4\u001b[0m                                   \u001b[0mdir_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"timeseries_data/electricity\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                   data_filename=\"electricity_training_data\")\n",
      "\u001b[0;31mNameError\u001b[0m: name 'electricity_df' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "inputs = save_local_and_upload_s3(electricity_df, sagemaker_session, bucket,\n",
    "                                  dir_name = \"timeseries_data/electricity\",\n",
    "                                  data_filename=\"electricity_training_data\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8642fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prediction_length = 24\n",
    "max_encoder_length = 24 * 7\n",
    "\n",
    "\n",
    "training_metadata = {}\n",
    "training_metadata['time_idx'] = \"hours_from_start\"\n",
    "training_metadata['target'] = \"power_usage\"\n",
    "training_metadata['group_ids'] = [\"categorical_id\"]\n",
    "training_metadata['min_encoder_length'] = max_encoder_length      # keep encoder length long (as it is in the validation set)\n",
    "training_metadata['max_encoder_length'] = max_encoder_length\n",
    "training_metadata['min_prediction_length'] = 1      \n",
    "training_metadata['max_prediction_length'] = max_prediction_length\n",
    "training_metadata['static_categoricals'] = [\"categorical_id\"]\n",
    "training_metadata['static_reals'] = []\n",
    "training_metadata['time_varying_known_categoricals'] = []\n",
    "training_metadata['variable_groups'] = {}\n",
    "training_metadata['time_varying_known_reals'] = [\"hours_from_start\", \"day_of_week\", \"hour\"]\n",
    "training_metadata['time_varying_unknown_categoricals'] = []\n",
    "training_metadata['time_varying_unknown_reals'] = []\n",
    "training_metadata['target_normalizer'] = {\n",
    "                            \"normalized_groups\": [\"categorical_id\"],\n",
    "                            \"normalization_transformation\": 'softplus'\n",
    "                        }\n",
    "training_metadata['add_relative_time_idx'] = True\n",
    "training_metadata['add_target_scales'] = True\n",
    "training_metadata['add_encoder_length'] = True\n",
    "training_metadata['allow_missing_timesteps'] = True\n",
    "\n",
    "training_metadata['training_cutoff'] = int(electricity_df[training_metadata['time_idx']].max() - max_prediction_length)\n",
    "# training_metadata['training_cutoff'] = int(electricity_df[training_metadata['time_idx']].max())\n",
    "\n",
    "# upload metadata\n",
    "metadata_json_upload_s3(training_metadata, sagemaker_session, bucket, \n",
    "                                    dir_name = \"timeseries_data/electricity\",\n",
    "                                    metadata_filename=\"electricity_metadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eafab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "        'data-filename': \"electricity_training_data.parquet\",\n",
    "        'metadata-filename': \"electricity_metadata.json\",\n",
    "    \n",
    "        'max-prediction-length' : max_prediction_length,\n",
    "        'max-encoder-length' : max_encoder_length,\n",
    "#         'num-epochs' : 2,\n",
    "        'num-epochs' : 100,\n",
    "\n",
    "        'early-stopping-patience' : 5,\n",
    "        'multiprocessing-workers' : 5,\n",
    "\n",
    "\n",
    "        'dropout-rate' : 0.1,\n",
    "        'hidden-layer-size' : 160,\n",
    "        'learning-rate' : 0.001,\n",
    "        'minibatch-size' : 64,\n",
    "        'max-gradient-norm' : 0.01,\n",
    "        'num-heads' : 4\n",
    "    \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0866442",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_spot_instances = True\n",
    "max_run=36000      # in seconds, after this, job will be terminated\n",
    "max_wait = 10 * max_run if use_spot_instances else None\n",
    "local_image_name = 'pytorch-tft-container-test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7032fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.debugger import TensorBoardOutputConfig\n",
    "\n",
    "\n",
    "tensorboard_output_config = TensorBoardOutputConfig(\n",
    "    s3_output_path='s3://sagemaker-us-east-1-551329315830/tensorboard',\n",
    "    container_local_output_path='/lightning_logs'\n",
    ")\n",
    "\n",
    "spot_estimator  = PyTorch(entry_point='../TFT_docker/TFT.py',\n",
    "                            dependencies=['../TFT_docker/requirements.txt'],\n",
    "                            role=role,\n",
    "                            framework_version='1.7.1',\n",
    "                            py_version='py3',\n",
    "                            instance_count=1,\n",
    "#                             instance_type='local',\n",
    "                            instance_type='ml.p3.2xlarge',\n",
    "#                             instance_type='ml.p2.xlarge',\n",
    "                            base_job_name='tft-pytorch-spot-1',\n",
    "                            hyperparameters=hyperparameters,\n",
    "                            checkpoint_s3_uri=checkpoint_s3_path,\n",
    "                            debugger_hook_config=False,\n",
    "                            input_mode = 'File',\n",
    "                            use_spot_instances=use_spot_instances,\n",
    "                            max_run=max_run,\n",
    "                            max_wait=max_wait,\n",
    "                            tensorboard_output_config=tensorboard_output_config\n",
    "                           )\n",
    "\n",
    "spot_estimator.fit(\n",
    "                inputs,\n",
    "                logs = 'All'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d9462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc304da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fca563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f63473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceb5ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdd3e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d62a1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(electricity_df['categorical_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aee7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(electricity_df['id'] != electricity_df['categorical_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721f31f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14460e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity_df.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
