{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "462ec6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'551329315830.dkr.ecr.us-east-1.amazonaws.com/pytorch-tft-container-test:latest'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "client=boto3.client('sts')\n",
    "account=client.get_caller_identity()['Account']\n",
    "\n",
    "my_session=boto3.session.Session()\n",
    "region=my_session.region_name\n",
    "\n",
    "algorithm_name=\"pytorch-tft-container-test\"\n",
    "ecr_image='{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, algorithm_name)\n",
    "\n",
    "ecr_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc935a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\r\n",
      "Configure a credential helper to remove this warning. See\r\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\r\n",
      "\r\n",
      "Login Succeeded\r\n"
     ]
    }
   ],
   "source": [
    "! aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-east-1.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "342aef12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker version: 2.103.0\n",
      "Checkpointing Path: s3://sagemaker-us-east-1-551329315830/checkpoints/checkpoint-bdc3a2df\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import uuid\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "print('SageMaker version: ' + sagemaker.__version__)\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/DEMO-pytorch-cnn-cifar10'\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "checkpoint_suffix = str(uuid.uuid4())[:8]\n",
    "checkpoint_s3_path = 's3://{}/checkpoints/checkpoint-{}'.format(bucket, checkpoint_suffix)\n",
    "\n",
    "print('Checkpointing Path: {}'.format(checkpoint_s3_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aed4bd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpointing directory timeseries_data exists\n",
      "saved raw data to timeseries_data/stallion_data.parquet\n",
      "Checkpointing directory timeseries_data exists\n",
      "saved metadata to timeseries_data/stallion_metadata.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-551329315830/data/timeseries_data'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils_timeseries import download_process_and_return_raw_data, save_local_and_upload_s3, metadata_json_upload_s3\n",
    "import sagemaker\n",
    "import uuid\n",
    "\n",
    "max_prediction_length = 6\n",
    "max_encoder_length = 24\n",
    "special_days = [\n",
    "        \"easter_day\",\n",
    "        \"good_friday\",\n",
    "        \"new_year\",\n",
    "        \"christmas\",\n",
    "        \"labor_day\",\n",
    "        \"independence_day\",\n",
    "        \"revolution_day_memorial\",\n",
    "        \"regional_games\",\n",
    "        \"fifa_u_17_world_cup\",\n",
    "        \"football_gold_cup\",\n",
    "        \"beer_capital\",\n",
    "        \"music_fest\",\n",
    "    ]\n",
    "\n",
    "training_metadata = {}\n",
    "training_metadata['time_idx'] = \"time_idx\"\n",
    "training_metadata['target'] = \"volume\"\n",
    "training_metadata['group_ids'] = [\"agency\", \"sku\"]\n",
    "training_metadata['min_encoder_length'] = max_encoder_length // 2      # keep encoder length long (as it is in the validation set)\n",
    "training_metadata['max_encoder_length'] = max_encoder_length\n",
    "training_metadata['min_prediction_length'] = 1      \n",
    "training_metadata['max_prediction_length'] = max_prediction_length\n",
    "training_metadata['static_categoricals'] = [\"agency\", \"sku\"]\n",
    "training_metadata['static_reals'] = [\"avg_population_2017\", \"avg_yearly_household_income_2017\"]\n",
    "training_metadata['time_varying_known_categoricals'] = [\"special_days\", \"month\"]\n",
    "training_metadata['variable_groups'] = {\"special_days\": special_days}\n",
    "training_metadata['time_varying_known_reals'] = [\"time_idx\", \"price_regular\", \"discount_in_percent\"]\n",
    "training_metadata['time_varying_unknown_categoricals'] = []\n",
    "training_metadata['time_varying_unknown_reals'] = [\n",
    "        \"volume\",\n",
    "        \"log_volume\",\n",
    "        \"industry_volume\",\n",
    "        \"soda_volume\",\n",
    "        \"avg_max_temp\",\n",
    "        \"avg_volume_by_agency\",\n",
    "        \"avg_volume_by_sku\",\n",
    "    ]\n",
    "training_metadata['target_normalizer'] = {\n",
    "                            \"normalized_groups\": [\"agency\", \"sku\"],\n",
    "                            \"normalization_transformation\": 'softplus'\n",
    "                        }\n",
    "training_metadata['add_relative_time_idx'] = True\n",
    "training_metadata['add_target_scales'] = True\n",
    "training_metadata['add_encoder_length'] = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "# obtain & upload training data\n",
    "training_data = download_process_and_return_raw_data()\n",
    "inputs = save_local_and_upload_s3(training_data, sagemaker_session, bucket, data_filename=\"stallion_data\")\n",
    "\n",
    "# upload metadata\n",
    "training_metadata['training_cutoff'] = int(training_data[\"time_idx\"].max() - max_prediction_length)\n",
    "metadata_json_upload_s3(training_metadata, sagemaker_session, bucket, metadata_filename=\"stallion_metadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8c0962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_spot_instances = False\n",
    "max_run=6000      # in seconds, after this, job will be terminated\n",
    "max_wait = 10 * max_run if use_spot_instances else None\n",
    "local_image_name = 'pytorch-tft-container-test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18fd6338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-22 10:05:33 Starting - Starting the training job...ProfilerReport-1661162732: InProgress\n",
      "...\n",
      "2022-08-22 10:06:20 Starting - Preparing the instances for training......\n",
      "2022-08-22 10:07:31 Downloading - Downloading input data......\n",
      "2022-08-22 10:08:28 Training - Downloading the training image...........................\n",
      "2022-08-22 10:12:49 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-08-22 10:12:52,570 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-08-22 10:12:52,599 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-08-22 10:12:52,611 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-08-22 10:12:53,139 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting pytorch-forecasting\n",
      "  Downloading pytorch_forecasting-0.9.0-py3-none-any.whl (112 kB)\u001b[0m\n",
      "\u001b[34mCollecting fastparquet\n",
      "  Downloading fastparquet-0.8.0.tar.gz (400 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (4.0.0)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard\n",
      "  Downloading tensorboard-2.10.0-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[34mCollecting pytorch-lightning<2.0.0,>=1.2.4\n",
      "  Downloading pytorch_lightning-1.5.10-py3-none-any.whl (527 kB)\u001b[0m\n",
      "\u001b[34mCollecting statsmodels\n",
      "  Downloading statsmodels-0.12.2-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from pytorch-forecasting->-r requirements.txt (line 1)) (1.5.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch<2.0,>=1.7 in /opt/conda/lib/python3.6/site-packages (from pytorch-forecasting->-r requirements.txt (line 1)) (1.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib in /opt/conda/lib/python3.6/site-packages (from pytorch-forecasting->-r requirements.txt (line 1)) (3.3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas<2.0.0,>=1.1.0 in /opt/conda/lib/python3.6/site-packages (from pytorch-forecasting->-r requirements.txt (line 1)) (1.1.5)\u001b[0m\n",
      "\u001b[34mCollecting optuna<3.0.0,>=2.3.0\n",
      "  Downloading optuna-2.10.1-py3-none-any.whl (308 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn<0.25,>=0.23 in /opt/conda/lib/python3.6/site-packages (from pytorch-forecasting->-r requirements.txt (line 1)) (0.24.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from optuna<3.0.0,>=2.3.0->pytorch-forecasting->-r requirements.txt (line 1)) (20.9)\u001b[0m\n",
      "\u001b[34mCollecting alembic\u001b[0m\n",
      "\u001b[34m  Downloading alembic-1.7.7-py3-none-any.whl (210 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from optuna<3.0.0,>=2.3.0->pytorch-forecasting->-r requirements.txt (line 1)) (4.51.0)\u001b[0m\n",
      "\u001b[34mCollecting colorlog\n",
      "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: PyYAML in /opt/conda/lib/python3.6/site-packages (from optuna<3.0.0,>=2.3.0->pytorch-forecasting->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[34mCollecting cmaes>=0.8.2\n",
      "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\u001b[0m\n",
      "\u001b[34mCollecting sqlalchemy>=1.1.0\n",
      "  Downloading SQLAlchemy-1.4.40-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\u001b[0m\n",
      "\u001b[34mCollecting cliff\n",
      "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from optuna<3.0.0,>=2.3.0->pytorch-forecasting->-r requirements.txt (line 1)) (1.19.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->optuna<3.0.0,>=2.3.0->pytorch-forecasting->-r requirements.txt (line 1)) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.6/site-packages (from pandas<2.0.0,>=1.1.0->pytorch-forecasting->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas<2.0.0,>=1.1.0->pytorch-forecasting->-r requirements.txt (line 1)) (2021.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas<2.0.0,>=1.1.0->pytorch-forecasting->-r requirements.txt (line 1)) (1.16.0)\u001b[0m\n",
      "\u001b[34mCollecting torchmetrics>=0.4.1\n",
      "  Downloading torchmetrics-0.8.2-py3-none-any.whl (409 kB)\u001b[0m\n",
      "\u001b[34mCollecting setuptools==59.5.0\n",
      "  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.6/site-packages (from pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting->-r requirements.txt (line 1)) (0.18.2)\u001b[0m\n",
      "\u001b[34mCollecting pyDeprecate==0.3.1\n",
      "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting->-r requirements.txt (line 1)) (3.10.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.6/site-packages (from pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting->-r requirements.txt (line 1)) (2021.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 4)) (0.35.1)\u001b[0m\n",
      "\u001b[34mCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.11.0-py2.py3-none-any.whl (167 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 4)) (3.17.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 4)) (2.25.1)\u001b[0m\n",
      "\u001b[34mCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.47.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 4)) (2.0.1)\u001b[0m\n",
      "\u001b[34mCollecting absl-py>=0.4\n",
      "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\u001b[0m\n",
      "\u001b[34mCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiohttp\u001b[0m\n",
      "\u001b[34m  Downloading aiohttp-3.8.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 4)) (4.7.2)\u001b[0m\n",
      "\u001b[34mCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\u001b[0m\n",
      "\u001b[34mCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mCollecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->-r requirements.txt (line 4)) (3.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 4)) (0.4.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 4)) (1.25.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 4)) (3.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 4)) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 4)) (2020.12.5)\u001b[0m\n",
      "\u001b[34mCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn<0.25,>=0.23->pytorch-forecasting->-r requirements.txt (line 1)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn<0.25,>=0.23->pytorch-forecasting->-r requirements.txt (line 1)) (2.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.6/site-packages (from sqlalchemy>=1.1.0->optuna<3.0.0,>=2.3.0->pytorch-forecasting->-r requirements.txt (line 1)) (1.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from torch<2.0,>=1.7->pytorch-forecasting->-r requirements.txt (line 1)) (0.8)\u001b[0m\n",
      "\u001b[34mCollecting cramjam>=2.3.0\n",
      "  Downloading cramjam-2.5.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.6 MB)\u001b[0m\n",
      "\u001b[34mCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.2.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (159 kB)\u001b[0m\n",
      "\u001b[34mCollecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.6/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting->-r requirements.txt (line 1)) (21.2.0)\u001b[0m\n",
      "\u001b[34mCollecting charset-normalizer<3.0,>=2.0\n",
      "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\u001b[0m\n",
      "\u001b[34mCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (270 kB)\u001b[0m\n",
      "\u001b[34mCollecting idna-ssl>=1.0\n",
      "  Downloading idna-ssl-1.1.0.tar.gz (3.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting asynctest==0.13.0\u001b[0m\n",
      "\u001b[34m  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\u001b[0m\n",
      "\u001b[34mCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.2.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (191 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting Mako\n",
      "  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\u001b[0m\n",
      "\u001b[34mCollecting importlib-resources\n",
      "  Downloading importlib_resources-5.4.0-py3-none-any.whl (28 kB)\u001b[0m\n",
      "\u001b[34mCollecting PrettyTable>=0.7.2\n",
      "  Downloading prettytable-2.5.0-py3-none-any.whl (24 kB)\u001b[0m\n",
      "\u001b[34mCollecting cmd2>=1.0.0\n",
      "  Downloading cmd2-2.4.2-py3-none-any.whl (147 kB)\u001b[0m\n",
      "\u001b[34mCollecting stevedore>=2.0.1\n",
      "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\u001b[0m\n",
      "\u001b[34mCollecting pbr!=2.1.0,>=2.0.0\n",
      "  Downloading pbr-5.10.0-py2.py3-none-any.whl (112 kB)\u001b[0m\n",
      "\u001b[34mCollecting autopage>=0.4.0\n",
      "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyperclip>=1.6\n",
      "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wcwidth>=0.1.7 in /opt/conda/lib/python3.6/site-packages (from cmd2>=1.0.0->cliff->optuna<3.0.0,>=2.3.0->pytorch-forecasting->-r requirements.txt (line 1)) (0.2.5)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mRequirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.6/site-packages (from Mako->alembic->optuna<3.0.0,>=2.3.0->pytorch-forecasting->-r requirements.txt (line 1)) (2.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->pytorch-forecasting->-r requirements.txt (line 1)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib->pytorch-forecasting->-r requirements.txt (line 1)) (0.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.6/site-packages (from matplotlib->pytorch-forecasting->-r requirements.txt (line 1)) (8.2.0)\u001b[0m\n",
      "\u001b[34mCollecting patsy>=0.5\n",
      "  Downloading patsy-0.5.2-py2.py3-none-any.whl (233 kB)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: fastparquet, idna-ssl, pyperclip\n",
      "  Building wheel for fastparquet (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for fastparquet (setup.py): finished with status 'done'\n",
      "  Created wheel for fastparquet: filename=fastparquet-0.8.0-cp36-cp36m-linux_x86_64.whl size=1256936 sha256=acce5b84cafd8efc1d34084d35f17fa2a3b1d53d99d17566df9ff57f7f4dce0d\n",
      "  Stored in directory: /root/.cache/pip/wheels/6a/6a/4f/0fd8e8bcbc4b5b751186e363b5b03975d8643eee2975eed2ca\n",
      "  Building wheel for idna-ssl (setup.py): started\n",
      "  Building wheel for idna-ssl (setup.py): finished with status 'done'\n",
      "  Created wheel for idna-ssl: filename=idna_ssl-1.1.0-py3-none-any.whl size=3161 sha256=230e21aaaed3193563de44012de2bf889d9101cb3a18d3e870d154b49f72ed85\n",
      "  Stored in directory: /root/.cache/pip/wheels/6a/f5/9c/f8331a854f7a8739cf0e74c13854e4dd7b1af11b04fe1dde13\n",
      "  Building wheel for pyperclip (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for pyperclip (setup.py): finished with status 'done'\n",
      "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11106 sha256=aecad7c1a4797222c5df3c2e473a1af49ac9dab8751b583b7a930629ea7f51dd\n",
      "  Stored in directory: /root/.cache/pip/wheels/95/38/95/e30a7f0b44cb90642de3469f211a3218f93f871789b4f4b46c\u001b[0m\n",
      "\u001b[34mSuccessfully built fastparquet idna-ssl pyperclip\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pyasn1-modules, oauthlib, multidict, frozenlist, cachetools, yarl, requests-oauthlib, pyperclip, pbr, importlib-metadata, idna-ssl, google-auth, charset-normalizer, asynctest, async-timeout, aiosignal, tensorboard-plugin-wit, tensorboard-data-server, stevedore, sqlalchemy, setuptools, pyDeprecate, PrettyTable, markdown, Mako, importlib-resources, grpcio, google-auth-oauthlib, cmd2, autopage, aiohttp, absl-py, torchmetrics, tensorboard, patsy, colorlog, cmaes, cliff, alembic, statsmodels, pytorch-lightning, optuna, cramjam, pytorch-forecasting, fastparquet\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 4.0.1\n",
      "    Uninstalling importlib-metadata-4.0.1:\n",
      "      Successfully uninstalled importlib-metadata-4.0.1\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 49.6.0.post20210108\n",
      "    Uninstalling setuptools-49.6.0.post20210108:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled setuptools-49.6.0.post20210108\u001b[0m\n",
      "\u001b[34mSuccessfully installed Mako-1.1.6 PrettyTable-2.5.0 absl-py-1.2.0 aiohttp-3.8.1 aiosignal-1.2.0 alembic-1.7.7 async-timeout-4.0.2 asynctest-0.13.0 autopage-0.5.1 cachetools-4.2.4 charset-normalizer-2.1.1 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.2 colorlog-6.6.0 cramjam-2.5.0 fastparquet-0.8.0 frozenlist-1.2.0 google-auth-2.11.0 google-auth-oauthlib-0.4.6 grpcio-1.47.0 idna-ssl-1.1.0 importlib-metadata-4.8.3 importlib-resources-5.4.0 markdown-3.3.7 multidict-5.2.0 oauthlib-3.2.0 optuna-2.10.1 patsy-0.5.2 pbr-5.10.0 pyDeprecate-0.3.1 pyasn1-modules-0.2.8 pyperclip-1.8.2 pytorch-forecasting-0.9.0 pytorch-lightning-1.5.10 requests-oauthlib-1.3.1 setuptools-59.5.0 sqlalchemy-1.4.40 statsmodels-0.12.2 stevedore-3.5.0 tensorboard-2.10.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 torchmetrics-0.8.2 yarl-1.7.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2022-08-22 10:13:47,353 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"data-filename\": \"stallion_data.parquet\",\n",
      "        \"epochs\": 100,\n",
      "        \"metadata-filename\": \"stallion_metadata.json\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"tft-pytorch-spot-1-2022-08-22-10-05-32-622\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-551329315830/tft-pytorch-spot-1-2022-08-22-10-05-32-622/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"TFT\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p2.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p2.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"TFT.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"data-filename\":\"stallion_data.parquet\",\"epochs\":100,\"metadata-filename\":\"stallion_metadata.json\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=TFT.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p2.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p2.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=TFT\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-551329315830/tft-pytorch-spot-1-2022-08-22-10-05-32-622/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"data-filename\":\"stallion_data.parquet\",\"epochs\":100,\"metadata-filename\":\"stallion_metadata.json\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tft-pytorch-spot-1-2022-08-22-10-05-32-622\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-551329315830/tft-pytorch-spot-1-2022-08-22-10-05-32-622/source/sourcedir.tar.gz\",\"module_name\":\"TFT\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p2.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p2.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"TFT.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--data-filename\",\"stallion_data.parquet\",\"--epochs\",\"100\",\"--metadata-filename\",\"stallion_metadata.json\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_DATA-FILENAME=stallion_data.parquet\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=100\u001b[0m\n",
      "\u001b[34mSM_HP_METADATA-FILENAME=stallion_metadata.json\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 TFT.py --data-filename stallion_data.parquet --epochs 100 --metadata-filename stallion_metadata.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mDistributed training - False\u001b[0m\n",
      "\u001b[34mCheckpointing directory /opt/ml/checkpoints exists\u001b[0m\n",
      "\u001b[34mDevice Type: cuda\u001b[0m\n",
      "\u001b[34mLoad Time Series dataset from S3\u001b[0m\n",
      "\u001b[34mcreating dataloader\u001b[0m\n",
      "\u001b[34mget GPU information\u001b[0m\n",
      "\u001b[34mGPU count: 1\u001b[0m\n",
      "\u001b[34mcreate model trainer\u001b[0m\n",
      "\u001b[34mcreate model from dataset\u001b[0m\n",
      "\u001b[34mNumber of parameters in network: 29.7k\u001b[0m\n",
      "\u001b[34mtraining model\u001b[0m\n",
      "\u001b[34m#015Validation sanity check: 0it [00:00, ?it/s]#015Validation sanity check:   0%|          | 0/1 [00:00<?, ?it/s]#015Validation sanity check: 100%|██████████| 1/1 [00:03<00:00,  3.36s/it]#015                                                                      #015#015Training: 0it [00:00, ?it/s]#015Training:   0%|          | 0/31 [00:00<?, ?it/s]#015Epoch 0:   0%|          | 0/31 [00:00<?, ?it/s] #015Epoch 0:   3%|▎         | 1/31 [00:01<00:41,  1.38s/it]#015Epoch 0:   3%|▎         | 1/31 [00:01<00:41,  1.38s/it, loss=135, v_num=0, train_loss_step=135.0]#015Epoch 0:   6%|▋         | 2/31 [00:01<00:26,  1.08it/s, loss=135, v_num=0, train_loss_step=135.0]#015Epoch 0:   6%|▋         | 2/31 [00:01<00:26,  1.08it/s, loss=151, v_num=0, train_loss_step=167.0]#015Epoch 0:  10%|▉         | 3/31 [00:02<00:21,  1.29it/s, loss=151, v_num=0, train_loss_step=167.0]#015Epoch 0:  10%|▉         | 3/31 [00:02<00:21,  1.29it/s, loss=150, v_num=0, train_loss_step=148.0]#015Epoch 0:  13%|█▎        | 4/31 [00:02<00:18,  1.44it/s, loss=150, v_num=0, train_loss_step=148.0]#015Epoch 0:  13%|█▎        | 4/31 [00:02<00:18,  1.44it/s, loss=150, v_num=0, train_loss_step=151.0]#015Epoch 0:  16%|█▌        | 5/31 [00:03<00:16,  1.54it/s, loss=150, v_num=0, train_loss_step=151.0]#015Epoch 0:  16%|█▌        | 5/31 [00:03<00:16,  1.54it/s, loss=148, v_num=0, train_loss_step=140.0]#015Epoch 0:  19%|█▉        | 6/31 [00:03<00:15,  1.59it/s, loss=148, v_num=0, train_loss_step=140.0]#015Epoch 0:  19%|█▉        | 6/31 [00:03<00:15,  1.59it/s, loss=147, v_num=0, train_loss_step=140.0]#015Epoch 0:  23%|██▎       | 7/31 [00:04<00:14,  1.61it/s, loss=147, v_num=0, train_loss_step=140.0]#015Epoch 0:  23%|██▎       | 7/31 [00:04<00:14,  1.61it/s, loss=149, v_num=0, train_loss_step=163.0]#015Epoch 0:  26%|██▌       | 8/31 [00:04<00:13,  1.66it/s, loss=149, v_num=0, train_loss_step=163.0]#015Epoch 0:  26%|██▌       | 8/31 [00:04<00:13,  1.66it/s, loss=144, v_num=0, train_loss_step=105.0]#015Epoch 0:  29%|██▉       | 9/31 [00:05<00:13,  1.69it/s, loss=144, v_num=0, train_loss_step=105.0]#015Epoch 0:  29%|██▉       | 9/31 [00:05<00:13,  1.69it/s, loss=144, v_num=0, train_loss_step=151.0]#015Epoch 0:  32%|███▏      | 10/31 [00:05<00:12,  1.70it/s, loss=144, v_num=0, train_loss_step=151.0]#015Epoch 0:  32%|███▏      | 10/31 [00:05<00:12,  1.70it/s, loss=141, v_num=0, train_loss_step=108.0]#015Epoch 0:  35%|███▌      | 11/31 [00:06<00:12,  1.63it/s, loss=141, v_num=0, train_loss_step=108.0]#015Epoch 0:  35%|███▌      | 11/31 [00:06<00:12,  1.63it/s, loss=142, v_num=0, train_loss_step=152.0]#015Epoch 0:  39%|███▊      | 12/31 [00:07<00:11,  1.66it/s, loss=142, v_num=0, train_loss_step=152.0]#015Epoch 0:  39%|███▊      | 12/31 [00:07<00:11,  1.66it/s, loss=137, v_num=0, train_loss_step=89.90]#015Epoch 0:  42%|████▏     | 13/31 [00:07<00:10,  1.67it/s, loss=137, v_num=0, train_loss_step=89.90]#015Epoch 0:  42%|████▏     | 13/31 [00:07<00:10,  1.67it/s, loss=137, v_num=0, train_loss_step=132.0]#015Epoch 0:  45%|████▌     | 14/31 [00:08<00:10,  1.68it/s, loss=137, v_num=0, train_loss_step=132.0]#015Epoch 0:  45%|████▌     | 14/31 [00:08<00:10,  1.68it/s, loss=136, v_num=0, train_loss_step=122.0]#015Epoch 0:  48%|████▊     | 15/31 [00:08<00:09,  1.70it/s, loss=136, v_num=0, train_loss_step=122.0]#015Epoch 0:  48%|████▊     | 15/31 [00:08<00:09,  1.70it/s, loss=133, v_num=0, train_loss_step=93.10]#015Epoch 0:  52%|█████▏    | 16/31 [00:09<00:08,  1.70it/s, loss=133, v_num=0, train_loss_step=93.10]#015Epoch 0:  52%|█████▏    | 16/31 [00:09<00:08,  1.70it/s, loss=132, v_num=0, train_loss_step=118.0]#015Epoch 0:  55%|█████▍    | 17/31 [00:09<00:08,  1.72it/s, loss=132, v_num=0, train_loss_step=118.0]#015Epoch 0:  55%|█████▍    | 17/31 [00:09<00:08,  1.72it/s, loss=131, v_num=0, train_loss_step=112.0]#015Epoch 0:  58%|█████▊    | 18/31 [00:10<00:07,  1.73it/s, loss=131, v_num=0, train_loss_step=112.0]#015Epoch 0:  58%|█████▊    | 18/31 [00:10<00:07,  1.73it/s, loss=128, v_num=0, train_loss_step=73.50]#015Epoch 0:  61%|██████▏   | 19/31 [00:10<00:06,  1.75it/s, loss=128, v_num=0, train_loss_step=73.50]#015Epoch 0:  61%|██████▏   | 19/31 [00:10<00:06,  1.75it/s, loss=127, v_num=0, train_loss_step=109.0]#015Epoch 0:  65%|██████▍   | 20/31 [00:11<00:06,  1.76it/s, loss=127, v_num=0, train_loss_step=109.0]#015Epoch 0:  65%|██████▍   | 20/31 [00:11<00:06,  1.76it/s, loss=125, v_num=0, train_loss_step=101.0]#015Epoch 0:  68%|██████▊   | 21/31 [00:12<00:05,  1.72it/s, loss=125, v_num=0, train_loss_step=101.0]#015Epoch 0:  68%|██████▊   | 21/31 [00:12<00:05,  1.72it/s, loss=126, v_num=0, train_loss_step=139.0]#015Epoch 0:  71%|███████   | 22/31 [00:12<00:05,  1.73it/s, loss=126, v_num=0, train_loss_step=139.0]#015Epoch 0:  71%|███████   | 22/31 [00:12<00:05,  1.73it/s, loss=121, v_num=0, train_loss_step=78.10]#015Epoch 0:  74%|███████▍  | 23/31 [00:13<00:04,  1.74it/s, loss=121, v_num=0, train_loss_step=78.10]#015Epoch 0:  74%|███████▍  | 23/31 [00:13<00:04,  1.74it/s, loss=120, v_num=0, train_loss_step=116.0]#015Epoch 0:  77%|███████▋  | 24/31 [00:13<00:03,  1.75it/s, loss=120, v_num=0, train_loss_step=116.0]#015Epoch 0:  77%|███████▋  | 24/31 [00:13<00:03,  1.75it/s, loss=116, v_num=0, train_loss_step=78.20]#015Epoch 0:  81%|████████  | 25/31 [00:14<00:03,  1.76it/s, loss=116, v_num=0, train_loss_step=78.20]#015Epoch 0:  81%|████████  | 25/31 [00:14<00:03,  1.76it/s, loss=113, v_num=0, train_loss_step=89.00]#015Epoch 0:  84%|████████▍ | 26/31 [00:14<00:02,  1.77it/s, loss=113, v_num=0, train_loss_step=89.00]#015Epoch 0:  84%|████████▍ | 26/31 [00:14<00:02,  1.77it/s, loss=113, v_num=0, train_loss_step=127.0]#015Epoch 0:  87%|████████▋ | 27/31 [00:15<00:02,  1.78it/s, loss=113, v_num=0, train_loss_step=127.0]#015Epoch 0:  87%|████████▋ | 27/31 [00:15<00:02,  1.78it/s, loss=109, v_num=0, train_loss_step=84.70]#015Epoch 0:  90%|█████████ | 28/31 [00:15<00:01,  1.79it/s, loss=109, v_num=0, train_loss_step=84.70]#015Epoch 0:  90%|█████████ | 28/31 [00:15<00:01,  1.79it/s, loss=107, v_num=0, train_loss_step=66.20]#015Epoch 0:  94%|█████████▎| 29/31 [00:16<00:01,  1.79it/s, loss=107, v_num=0, train_loss_step=66.20]#015Epoch 0:  94%|█████████▎| 29/31 [00:16<00:01,  1.79it/s, loss=104, v_num=0, train_loss_step=98.90]#015Epoch 0:  97%|█████████▋| 30/31 [00:16<00:00,  1.80it/s, loss=104, v_num=0, train_loss_step=98.90]#015Epoch 0:  97%|█████████▋| 30/31 [00:16<00:00,  1.80it/s, loss=103, v_num=0, train_loss_step=85.20]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 1/1 [00:01<00:00,  1.07s/it]#033[A#015Epoch 0: 100%|██████████| 31/31 [00:18<00:00,  1.65it/s, loss=103, v_num=0, train_loss_step=85.20, val_loss=125.0]\u001b[0m\n",
      "\u001b[34m#015                                                         #033[A#015Epoch 0: 100%|██████████| 31/31 [00:20<00:00,  1.54it/s, loss=103, v_num=0, train_loss_step=85.20, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 0:   0%|          | 0/31 [00:00<?, ?it/s, loss=103, v_num=0, train_loss_step=85.20, val_loss=125.0, train_loss_epoch=116.0]         #015Epoch 1:   0%|          | 0/31 [00:00<?, ?it/s, loss=103, v_num=0, train_loss_step=85.20, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:   3%|▎         | 1/31 [00:01<00:35,  1.17s/it, loss=103, v_num=0, train_loss_step=85.20, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:   3%|▎         | 1/31 [00:01<00:35,  1.17s/it, loss=99.3, v_num=0, train_loss_step=73.90, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:   6%|▋         | 2/31 [00:01<00:25,  1.15it/s, loss=99.3, v_num=0, train_loss_step=73.90, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:   6%|▋         | 2/31 [00:01<00:25,  1.15it/s, loss=99.1, v_num=0, train_loss_step=86.40, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  10%|▉         | 3/31 [00:02<00:20,  1.33it/s, loss=99.1, v_num=0, train_loss_step=86.40, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  10%|▉         | 3/31 [00:02<00:20,  1.33it/s, loss=96.8, v_num=0, train_loss_step=85.70, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  13%|█▎        | 4/31 [00:02<00:18,  1.43it/s, loss=96.8, v_num=0, train_loss_step=85.70, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  13%|█▎        | 4/31 [00:02<00:18,  1.43it/s, loss=94.5, v_num=0, train_loss_step=76.40, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  16%|█▌        | 5/31 [00:03<00:17,  1.50it/s, loss=94.5, v_num=0, train_loss_step=76.40, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  16%|█▌        | 5/31 [00:03<00:17,  1.50it/s, loss=92.7, v_num=0, train_loss_step=56.40, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  19%|█▉        | 6/31 [00:03<00:16,  1.56it/s, loss=92.7, v_num=0, train_loss_step=56.40, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  19%|█▉        | 6/31 [00:03<00:16,  1.56it/s, loss=89.8, v_num=0, train_loss_step=60.00, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  23%|██▎       | 7/31 [00:04<00:14,  1.61it/s, loss=89.8, v_num=0, train_loss_step=60.00, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  23%|██▎       | 7/31 [00:04<00:14,  1.61it/s, loss=88.3, v_num=0, train_loss_step=81.50, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  26%|██▌       | 8/31 [00:04<00:13,  1.65it/s, loss=88.3, v_num=0, train_loss_step=81.50, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  26%|██▌       | 8/31 [00:04<00:13,  1.65it/s, loss=88.9, v_num=0, train_loss_step=85.10, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  29%|██▉       | 9/31 [00:05<00:13,  1.69it/s, loss=88.9, v_num=0, train_loss_step=85.10, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  29%|██▉       | 9/31 [00:05<00:13,  1.69it/s, loss=85.8, v_num=0, train_loss_step=47.80, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  32%|███▏      | 10/31 [00:05<00:12,  1.71it/s, loss=85.8, v_num=0, train_loss_step=47.80, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  32%|███▏      | 10/31 [00:05<00:12,  1.71it/s, loss=84.4, v_num=0, train_loss_step=72.90, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  35%|███▌      | 11/31 [00:06<00:12,  1.65it/s, loss=84.4, v_num=0, train_loss_step=72.90, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  35%|███▌      | 11/31 [00:06<00:12,  1.65it/s, loss=80.7, v_num=0, train_loss_step=64.30, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  39%|███▊      | 12/31 [00:07<00:11,  1.66it/s, loss=80.7, v_num=0, train_loss_step=64.30, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  39%|███▊      | 12/31 [00:07<00:11,  1.66it/s, loss=80.9, v_num=0, train_loss_step=82.60, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  42%|████▏     | 13/31 [00:07<00:10,  1.68it/s, loss=80.9, v_num=0, train_loss_step=82.60, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  42%|████▏     | 13/31 [00:07<00:10,  1.68it/s, loss=78.5, v_num=0, train_loss_step=67.50, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  45%|████▌     | 14/31 [00:08<00:09,  1.71it/s, loss=78.5, v_num=0, train_loss_step=67.50, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  45%|████▌     | 14/31 [00:08<00:09,  1.71it/s, loss=77.8, v_num=0, train_loss_step=64.00, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  48%|████▊     | 15/31 [00:08<00:09,  1.72it/s, loss=77.8, v_num=0, train_loss_step=64.00, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  48%|████▊     | 15/31 [00:08<00:09,  1.72it/s, loss=77, v_num=0, train_loss_step=73.90, val_loss=125.0, train_loss_epoch=116.0]  #015Epoch 1:  52%|█████▏    | 16/31 [00:09<00:08,  1.74it/s, loss=77, v_num=0, train_loss_step=73.90, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  52%|█████▏    | 16/31 [00:09<00:08,  1.74it/s, loss=74.8, v_num=0, train_loss_step=82.70, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  55%|█████▍    | 17/31 [00:09<00:07,  1.75it/s, loss=74.8, v_num=0, train_loss_step=82.70, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  55%|█████▍    | 17/31 [00:09<00:07,  1.75it/s, loss=75, v_num=0, train_loss_step=89.00, val_loss=125.0, train_loss_epoch=116.0]  #015Epoch 1:  58%|█████▊    | 18/31 [00:10<00:07,  1.75it/s, loss=75, v_num=0, train_loss_step=89.00, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  58%|█████▊    | 18/31 [00:10<00:07,  1.75it/s, loss=75.5, v_num=0, train_loss_step=74.90, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  61%|██████▏   | 19/31 [00:10<00:06,  1.76it/s, loss=75.5, v_num=0, train_loss_step=74.90, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  61%|██████▏   | 19/31 [00:10<00:06,  1.76it/s, loss=75, v_num=0, train_loss_step=89.00, val_loss=125.0, train_loss_epoch=116.0]  #015Epoch 1:  65%|██████▍   | 20/31 [00:11<00:06,  1.77it/s, loss=75, v_num=0, train_loss_step=89.00, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  65%|██████▍   | 20/31 [00:11<00:06,  1.77it/s, loss=74.3, v_num=0, train_loss_step=72.00, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  68%|██████▊   | 21/31 [00:12<00:05,  1.72it/s, loss=74.3, v_num=0, train_loss_step=72.00, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  68%|██████▊   | 21/31 [00:12<00:05,  1.72it/s, loss=73.9, v_num=0, train_loss_step=66.00, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  71%|███████   | 22/31 [00:12<00:05,  1.73it/s, loss=73.9, v_num=0, train_loss_step=66.00, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  71%|███████   | 22/31 [00:12<00:05,  1.73it/s, loss=74, v_num=0, train_loss_step=87.60, val_loss=125.0, train_loss_epoch=116.0]  #015Epoch 1:  74%|███████▍  | 23/31 [00:13<00:04,  1.73it/s, loss=74, v_num=0, train_loss_step=87.60, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  74%|███████▍  | 23/31 [00:13<00:04,  1.73it/s, loss=72.6, v_num=0, train_loss_step=58.60, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  77%|███████▋  | 24/31 [00:13<00:04,  1.74it/s, loss=72.6, v_num=0, train_loss_step=58.60, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  77%|███████▋  | 24/31 [00:13<00:04,  1.74it/s, loss=71, v_num=0, train_loss_step=43.70, val_loss=125.0, train_loss_epoch=116.0]  #015Epoch 1:  81%|████████  | 25/31 [00:14<00:03,  1.75it/s, loss=71, v_num=0, train_loss_step=43.70, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  81%|████████  | 25/31 [00:14<00:03,  1.75it/s, loss=72.4, v_num=0, train_loss_step=84.60, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  84%|████████▍ | 26/31 [00:14<00:02,  1.76it/s, loss=72.4, v_num=0, train_loss_step=84.60, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  84%|████████▍ | 26/31 [00:14<00:02,  1.76it/s, loss=73.9, v_num=0, train_loss_step=91.20, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  87%|████████▋ | 27/31 [00:15<00:02,  1.77it/s, loss=73.9, v_num=0, train_loss_step=91.20, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  87%|████████▋ | 27/31 [00:15<00:02,  1.77it/s, loss=72.9, v_num=0, train_loss_step=60.20, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  90%|█████████ | 28/31 [00:15<00:01,  1.78it/s, loss=72.9, v_num=0, train_loss_step=60.20, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  90%|█████████ | 28/31 [00:15<00:01,  1.78it/s, loss=72.5, v_num=0, train_loss_step=77.40, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  94%|█████████▎| 29/31 [00:16<00:01,  1.78it/s, loss=72.5, v_num=0, train_loss_step=77.40, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  94%|█████████▎| 29/31 [00:16<00:01,  1.78it/s, loss=74, v_num=0, train_loss_step=77.20, val_loss=125.0, train_loss_epoch=116.0]  #015Epoch 1:  97%|█████████▋| 30/31 [00:16<00:00,  1.79it/s, loss=74, v_num=0, train_loss_step=77.20, val_loss=125.0, train_loss_epoch=116.0]#015Epoch 1:  97%|█████████▋| 30/31 [00:16<00:00,  1.79it/s, loss=73.9, v_num=0, train_loss_step=71.70, val_loss=125.0, train_loss_epoch=116.0]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]#033[A#015Epoch 1: 100%|██████████| 31/31 [00:18<00:00,  1.65it/s, loss=73.9, v_num=0, train_loss_step=71.70, val_loss=104.0, train_loss_epoch=116.0]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015                                                         #033[A#015Epoch 1: 100%|██████████| 31/31 [00:20<00:00,  1.54it/s, loss=73.9, v_num=0, train_loss_step=71.70, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 1:   0%|          | 0/31 [00:00<?, ?it/s, loss=73.9, v_num=0, train_loss_step=71.70, val_loss=104.0, train_loss_epoch=73.50]         #015Epoch 2:   0%|          | 0/31 [00:00<?, ?it/s, loss=73.9, v_num=0, train_loss_step=71.70, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:   3%|▎         | 1/31 [00:01<00:32,  1.07s/it, loss=73.9, v_num=0, train_loss_step=71.70, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:   3%|▎         | 1/31 [00:01<00:32,  1.07s/it, loss=74.8, v_num=0, train_loss_step=83.00, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:   6%|▋         | 2/31 [00:01<00:22,  1.29it/s, loss=74.8, v_num=0, train_loss_step=83.00, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:   6%|▋         | 2/31 [00:01<00:22,  1.29it/s, loss=74.3, v_num=0, train_loss_step=72.40, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  10%|▉         | 3/31 [00:02<00:19,  1.47it/s, loss=74.3, v_num=0, train_loss_step=72.40, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  10%|▉         | 3/31 [00:02<00:19,  1.47it/s, loss=74.3, v_num=0, train_loss_step=67.10, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  13%|█▎        | 4/31 [00:02<00:17,  1.55it/s, loss=74.3, v_num=0, train_loss_step=67.10, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  13%|█▎        | 4/31 [00:02<00:17,  1.55it/s, loss=75.2, v_num=0, train_loss_step=81.70, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  16%|█▌        | 5/31 [00:03<00:16,  1.60it/s, loss=75.2, v_num=0, train_loss_step=81.70, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  16%|█▌        | 5/31 [00:03<00:16,  1.60it/s, loss=75.2, v_num=0, train_loss_step=74.80, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  19%|█▉        | 6/31 [00:03<00:15,  1.63it/s, loss=75.2, v_num=0, train_loss_step=74.80, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  19%|█▉        | 6/31 [00:03<00:15,  1.63it/s, loss=73.7, v_num=0, train_loss_step=50.80, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  23%|██▎       | 7/31 [00:04<00:14,  1.67it/s, loss=73.7, v_num=0, train_loss_step=50.80, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  23%|██▎       | 7/31 [00:04<00:14,  1.67it/s, loss=73.4, v_num=0, train_loss_step=83.20, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  26%|██▌       | 8/31 [00:04<00:13,  1.69it/s, loss=73.4, v_num=0, train_loss_step=83.20, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  26%|██▌       | 8/31 [00:04<00:13,  1.69it/s, loss=73, v_num=0, train_loss_step=68.20, val_loss=104.0, train_loss_epoch=73.50]  #015Epoch 2:  29%|██▉       | 9/31 [00:05<00:12,  1.73it/s, loss=73, v_num=0, train_loss_step=68.20, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  29%|██▉       | 9/31 [00:05<00:12,  1.73it/s, loss=71.3, v_num=0, train_loss_step=53.70, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  32%|███▏      | 10/31 [00:05<00:11,  1.75it/s, loss=71.3, v_num=0, train_loss_step=53.70, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  32%|███▏      | 10/31 [00:05<00:11,  1.75it/s, loss=70.6, v_num=0, train_loss_step=57.70, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  35%|███▌      | 11/31 [00:06<00:11,  1.69it/s, loss=70.6, v_num=0, train_loss_step=57.70, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  35%|███▌      | 11/31 [00:06<00:11,  1.69it/s, loss=71.3, v_num=0, train_loss_step=81.60, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  39%|███▊      | 12/31 [00:07<00:11,  1.71it/s, loss=71.3, v_num=0, train_loss_step=81.60, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  39%|███▊      | 12/31 [00:07<00:11,  1.71it/s, loss=70.2, v_num=0, train_loss_step=65.30, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  42%|████▏     | 13/31 [00:07<00:10,  1.73it/s, loss=70.2, v_num=0, train_loss_step=65.30, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  42%|████▏     | 13/31 [00:07<00:10,  1.73it/s, loss=70, v_num=0, train_loss_step=54.80, val_loss=104.0, train_loss_epoch=73.50]  #015Epoch 2:  45%|████▌     | 14/31 [00:08<00:09,  1.74it/s, loss=70, v_num=0, train_loss_step=54.80, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  45%|████▌     | 14/31 [00:08<00:09,  1.74it/s, loss=71.3, v_num=0, train_loss_step=68.60, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  48%|████▊     | 15/31 [00:08<00:09,  1.76it/s, loss=71.3, v_num=0, train_loss_step=68.60, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  48%|████▊     | 15/31 [00:08<00:09,  1.76it/s, loss=70.9, v_num=0, train_loss_step=77.40, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  52%|█████▏    | 16/31 [00:09<00:08,  1.77it/s, loss=70.9, v_num=0, train_loss_step=77.40, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  52%|█████▏    | 16/31 [00:09<00:08,  1.77it/s, loss=69, v_num=0, train_loss_step=52.30, val_loss=104.0, train_loss_epoch=73.50]  #015Epoch 2:  55%|█████▍    | 17/31 [00:09<00:07,  1.76it/s, loss=69, v_num=0, train_loss_step=52.30, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  55%|█████▍    | 17/31 [00:09<00:07,  1.76it/s, loss=69.5, v_num=0, train_loss_step=71.70, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  58%|█████▊    | 18/31 [00:10<00:07,  1.77it/s, loss=69.5, v_num=0, train_loss_step=71.70, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  58%|█████▊    | 18/31 [00:10<00:07,  1.77it/s, loss=68.9, v_num=0, train_loss_step=65.50, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  61%|██████▏   | 19/31 [00:10<00:06,  1.76it/s, loss=68.9, v_num=0, train_loss_step=65.50, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  61%|██████▏   | 19/31 [00:10<00:06,  1.76it/s, loss=67.7, v_num=0, train_loss_step=52.40, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  65%|██████▍   | 20/31 [00:11<00:06,  1.76it/s, loss=67.7, v_num=0, train_loss_step=52.40, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  65%|██████▍   | 20/31 [00:11<00:06,  1.76it/s, loss=67, v_num=0, train_loss_step=58.50, val_loss=104.0, train_loss_epoch=73.50]  #015Epoch 2:  68%|██████▊   | 21/31 [00:12<00:05,  1.72it/s, loss=67, v_num=0, train_loss_step=58.50, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  68%|██████▊   | 21/31 [00:12<00:05,  1.72it/s, loss=66.1, v_num=0, train_loss_step=63.80, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  71%|███████   | 22/31 [00:12<00:05,  1.71it/s, loss=66.1, v_num=0, train_loss_step=63.80, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  71%|███████   | 22/31 [00:12<00:05,  1.71it/s, loss=65.6, v_num=0, train_loss_step=63.00, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  74%|███████▍  | 23/31 [00:13<00:04,  1.71it/s, loss=65.6, v_num=0, train_loss_step=63.00, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  74%|███████▍  | 23/31 [00:13<00:04,  1.71it/s, loss=65.8, v_num=0, train_loss_step=71.20, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  77%|███████▋  | 24/31 [00:14<00:04,  1.71it/s, loss=65.8, v_num=0, train_loss_step=71.20, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  77%|███████▋  | 24/31 [00:14<00:04,  1.71it/s, loss=64.3, v_num=0, train_loss_step=50.50, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  81%|████████  | 25/31 [00:14<00:03,  1.72it/s, loss=64.3, v_num=0, train_loss_step=50.50, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  81%|████████  | 25/31 [00:14<00:03,  1.72it/s, loss=63.9, v_num=0, train_loss_step=67.10, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  84%|████████▍ | 26/31 [00:15<00:02,  1.73it/s, loss=63.9, v_num=0, train_loss_step=67.10, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  84%|████████▍ | 26/31 [00:15<00:02,  1.73it/s, loss=64.5, v_num=0, train_loss_step=63.30, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  87%|████████▋ | 27/31 [00:15<00:02,  1.74it/s, loss=64.5, v_num=0, train_loss_step=63.30, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  87%|████████▋ | 27/31 [00:15<00:02,  1.74it/s, loss=63, v_num=0, train_loss_step=52.30, val_loss=104.0, train_loss_epoch=73.50]  #015Epoch 2:  90%|█████████ | 28/31 [00:16<00:01,  1.75it/s, loss=63, v_num=0, train_loss_step=52.30, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  90%|█████████ | 28/31 [00:16<00:01,  1.75it/s, loss=61.8, v_num=0, train_loss_step=44.60, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  94%|█████████▎| 29/31 [00:16<00:01,  1.75it/s, loss=61.8, v_num=0, train_loss_step=44.60, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  94%|█████████▎| 29/31 [00:16<00:01,  1.75it/s, loss=62.7, v_num=0, train_loss_step=72.30, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  97%|█████████▋| 30/31 [00:17<00:00,  1.75it/s, loss=62.7, v_num=0, train_loss_step=72.30, val_loss=104.0, train_loss_epoch=73.50]#015Epoch 2:  97%|█████████▋| 30/31 [00:17<00:00,  1.75it/s, loss=63, v_num=0, train_loss_step=63.60, val_loss=104.0, train_loss_epoch=73.50]  \u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]#033[A#015Epoch 2: 100%|██████████| 31/31 [00:19<00:00,  1.62it/s, loss=63, v_num=0, train_loss_step=63.60, val_loss=99.00, train_loss_epoch=73.50]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015                                                         #033[A#015Epoch 2: 100%|██████████| 31/31 [00:20<00:00,  1.53it/s, loss=63, v_num=0, train_loss_step=63.60, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 2:   0%|          | 0/31 [00:00<?, ?it/s, loss=63, v_num=0, train_loss_step=63.60, val_loss=99.00, train_loss_epoch=65.10]         #015Epoch 3:   0%|          | 0/31 [00:00<?, ?it/s, loss=63, v_num=0, train_loss_step=63.60, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:   3%|▎         | 1/31 [00:01<00:30,  1.03s/it, loss=63, v_num=0, train_loss_step=63.60, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:   3%|▎         | 1/31 [00:01<00:30,  1.03s/it, loss=61.9, v_num=0, train_loss_step=60.70, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:   6%|▋         | 2/31 [00:01<00:22,  1.29it/s, loss=61.9, v_num=0, train_loss_step=60.70, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:   6%|▋         | 2/31 [00:01<00:22,  1.29it/s, loss=61.4, v_num=0, train_loss_step=53.40, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  10%|▉         | 3/31 [00:02<00:19,  1.47it/s, loss=61.4, v_num=0, train_loss_step=53.40, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  10%|▉         | 3/31 [00:02<00:19,  1.47it/s, loss=62.4, v_num=0, train_loss_step=75.30, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  13%|█▎        | 4/31 [00:02<00:17,  1.57it/s, loss=62.4, v_num=0, train_loss_step=75.30, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  13%|█▎        | 4/31 [00:02<00:17,  1.57it/s, loss=61.6, v_num=0, train_loss_step=53.50, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  16%|█▌        | 5/31 [00:03<00:15,  1.65it/s, loss=61.6, v_num=0, train_loss_step=53.50, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  16%|█▌        | 5/31 [00:03<00:15,  1.65it/s, loss=61, v_num=0, train_loss_step=65.70, val_loss=99.00, train_loss_epoch=65.10]  #015Epoch 3:  19%|█▉        | 6/31 [00:03<00:14,  1.70it/s, loss=61, v_num=0, train_loss_step=65.70, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  19%|█▉        | 6/31 [00:03<00:14,  1.70it/s, loss=61.5, v_num=0, train_loss_step=60.50, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  23%|██▎       | 7/31 [00:03<00:13,  1.75it/s, loss=61.5, v_num=0, train_loss_step=60.50, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  23%|██▎       | 7/31 [00:04<00:13,  1.75it/s, loss=60.9, v_num=0, train_loss_step=59.90, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  26%|██▌       | 8/31 [00:04<00:12,  1.78it/s, loss=60.9, v_num=0, train_loss_step=59.90, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  26%|██▌       | 8/31 [00:04<00:12,  1.78it/s, loss=60.4, v_num=0, train_loss_step=56.20, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  29%|██▉       | 9/31 [00:04<00:12,  1.81it/s, loss=60.4, v_num=0, train_loss_step=56.20, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  29%|██▉       | 9/31 [00:04<00:12,  1.81it/s, loss=60.5, v_num=0, train_loss_step=53.90, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  32%|███▏      | 10/31 [00:05<00:11,  1.81it/s, loss=60.5, v_num=0, train_loss_step=53.90, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  32%|███▏      | 10/31 [00:05<00:11,  1.81it/s, loss=60.8, v_num=0, train_loss_step=64.60, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  35%|███▌      | 11/31 [00:06<00:11,  1.72it/s, loss=60.8, v_num=0, train_loss_step=64.60, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  35%|███▌      | 11/31 [00:06<00:11,  1.72it/s, loss=60.7, v_num=0, train_loss_step=62.70, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  39%|███▊      | 12/31 [00:06<00:10,  1.73it/s, loss=60.7, v_num=0, train_loss_step=62.70, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  39%|███▊      | 12/31 [00:06<00:10,  1.73it/s, loss=60.7, v_num=0, train_loss_step=62.50, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  42%|████▏     | 13/31 [00:07<00:10,  1.74it/s, loss=60.7, v_num=0, train_loss_step=62.50, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  42%|████▏     | 13/31 [00:07<00:10,  1.74it/s, loss=61.1, v_num=0, train_loss_step=79.60, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  45%|████▌     | 14/31 [00:08<00:09,  1.74it/s, loss=61.1, v_num=0, train_loss_step=79.60, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  45%|████▌     | 14/31 [00:08<00:09,  1.74it/s, loss=62.1, v_num=0, train_loss_step=70.10, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  48%|████▊     | 15/31 [00:08<00:09,  1.75it/s, loss=62.1, v_num=0, train_loss_step=70.10, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  48%|████▊     | 15/31 [00:08<00:09,  1.75it/s, loss=61.2, v_num=0, train_loss_step=49.70, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  52%|█████▏    | 16/31 [00:09<00:08,  1.77it/s, loss=61.2, v_num=0, train_loss_step=49.70, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  52%|█████▏    | 16/31 [00:09<00:08,  1.77it/s, loss=61, v_num=0, train_loss_step=59.00, val_loss=99.00, train_loss_epoch=65.10]  #015Epoch 3:  55%|█████▍    | 17/31 [00:09<00:07,  1.78it/s, loss=61, v_num=0, train_loss_step=59.00, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  55%|█████▍    | 17/31 [00:09<00:07,  1.78it/s, loss=61.6, v_num=0, train_loss_step=64.70, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  58%|█████▊    | 18/31 [00:10<00:07,  1.79it/s, loss=61.6, v_num=0, train_loss_step=64.70, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  58%|█████▊    | 18/31 [00:10<00:07,  1.79it/s, loss=62.9, v_num=0, train_loss_step=69.80, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  61%|██████▏   | 19/31 [00:10<00:06,  1.80it/s, loss=62.9, v_num=0, train_loss_step=69.80, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  61%|██████▏   | 19/31 [00:10<00:06,  1.80it/s, loss=61.4, v_num=0, train_loss_step=43.40, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  65%|██████▍   | 20/31 [00:11<00:06,  1.81it/s, loss=61.4, v_num=0, train_loss_step=43.40, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  65%|██████▍   | 20/31 [00:11<00:06,  1.81it/s, loss=60.7, v_num=0, train_loss_step=48.00, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  68%|██████▊   | 21/31 [00:11<00:05,  1.77it/s, loss=60.7, v_num=0, train_loss_step=48.00, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  68%|██████▊   | 21/31 [00:11<00:05,  1.77it/s, loss=60.7, v_num=0, train_loss_step=61.50, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  71%|███████   | 22/31 [00:12<00:05,  1.78it/s, loss=60.7, v_num=0, train_loss_step=61.50, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  71%|███████   | 22/31 [00:12<00:05,  1.78it/s, loss=61.5, v_num=0, train_loss_step=68.70, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  74%|███████▍  | 23/31 [00:12<00:04,  1.78it/s, loss=61.5, v_num=0, train_loss_step=68.70, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  74%|███████▍  | 23/31 [00:12<00:04,  1.78it/s, loss=61.6, v_num=0, train_loss_step=77.30, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  77%|███████▋  | 24/31 [00:13<00:03,  1.79it/s, loss=61.6, v_num=0, train_loss_step=77.30, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  77%|███████▋  | 24/31 [00:13<00:03,  1.79it/s, loss=61.4, v_num=0, train_loss_step=49.10, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  81%|████████  | 25/31 [00:14<00:03,  1.78it/s, loss=61.4, v_num=0, train_loss_step=49.10, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  81%|████████  | 25/31 [00:14<00:03,  1.78it/s, loss=61, v_num=0, train_loss_step=57.90, val_loss=99.00, train_loss_epoch=65.10]  #015Epoch 3:  84%|████████▍ | 26/31 [00:14<00:02,  1.79it/s, loss=61, v_num=0, train_loss_step=57.90, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  84%|████████▍ | 26/31 [00:14<00:02,  1.79it/s, loss=61.8, v_num=0, train_loss_step=77.30, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  87%|████████▋ | 27/31 [00:15<00:02,  1.80it/s, loss=61.8, v_num=0, train_loss_step=77.30, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  87%|████████▋ | 27/31 [00:15<00:02,  1.80it/s, loss=62.4, v_num=0, train_loss_step=72.30, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  90%|█████████ | 28/31 [00:15<00:01,  1.81it/s, loss=62.4, v_num=0, train_loss_step=72.30, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  90%|█████████ | 28/31 [00:15<00:01,  1.81it/s, loss=62.8, v_num=0, train_loss_step=62.80, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  94%|█████████▎| 29/31 [00:15<00:01,  1.82it/s, loss=62.8, v_num=0, train_loss_step=62.80, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  94%|█████████▎| 29/31 [00:15<00:01,  1.82it/s, loss=63.4, v_num=0, train_loss_step=66.00, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  97%|█████████▋| 30/31 [00:16<00:00,  1.82it/s, loss=63.4, v_num=0, train_loss_step=66.00, val_loss=99.00, train_loss_epoch=65.10]#015Epoch 3:  97%|█████████▋| 30/31 [00:16<00:00,  1.82it/s, loss=62.5, v_num=0, train_loss_step=47.20, val_loss=99.00, train_loss_epoch=65.10]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]#033[A#015Epoch 3: 100%|██████████| 31/31 [00:18<00:00,  1.66it/s, loss=62.5, v_num=0, train_loss_step=47.20, val_loss=94.50, train_loss_epoch=65.10]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015                                                         #033[A#015Epoch 3: 100%|██████████| 31/31 [00:19<00:00,  1.56it/s, loss=62.5, v_num=0, train_loss_step=47.20, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 3:   0%|          | 0/31 [00:00<?, ?it/s, loss=62.5, v_num=0, train_loss_step=47.20, val_loss=94.50, train_loss_epoch=61.80]         #015Epoch 4:   0%|          | 0/31 [00:00<?, ?it/s, loss=62.5, v_num=0, train_loss_step=47.20, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:   3%|▎         | 1/31 [00:01<00:32,  1.07s/it, loss=62.5, v_num=0, train_loss_step=47.20, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:   3%|▎         | 1/31 [00:01<00:32,  1.07s/it, loss=62.3, v_num=0, train_loss_step=58.30, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:   6%|▋         | 2/31 [00:01<00:23,  1.25it/s, loss=62.3, v_num=0, train_loss_step=58.30, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:   6%|▋         | 2/31 [00:01<00:23,  1.25it/s, loss=62.3, v_num=0, train_loss_step=63.70, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  10%|▉         | 3/31 [00:02<00:19,  1.43it/s, loss=62.3, v_num=0, train_loss_step=63.70, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  10%|▉         | 3/31 [00:02<00:19,  1.43it/s, loss=61.2, v_num=0, train_loss_step=56.00, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  13%|█▎        | 4/31 [00:02<00:17,  1.51it/s, loss=61.2, v_num=0, train_loss_step=56.00, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  13%|█▎        | 4/31 [00:02<00:17,  1.51it/s, loss=60.4, v_num=0, train_loss_step=55.90, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  16%|█▌        | 5/31 [00:03<00:16,  1.59it/s, loss=60.4, v_num=0, train_loss_step=55.90, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  16%|█▌        | 5/31 [00:03<00:16,  1.59it/s, loss=61.2, v_num=0, train_loss_step=65.90, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  19%|█▉        | 6/31 [00:03<00:15,  1.63it/s, loss=61.2, v_num=0, train_loss_step=65.90, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  19%|█▉        | 6/31 [00:03<00:15,  1.63it/s, loss=61.8, v_num=0, train_loss_step=69.20, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  23%|██▎       | 7/31 [00:04<00:14,  1.67it/s, loss=61.8, v_num=0, train_loss_step=69.20, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  23%|██▎       | 7/31 [00:04<00:14,  1.67it/s, loss=60.9, v_num=0, train_loss_step=46.90, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  26%|██▌       | 8/31 [00:04<00:13,  1.72it/s, loss=60.9, v_num=0, train_loss_step=46.90, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  26%|██▌       | 8/31 [00:04<00:13,  1.72it/s, loss=60.7, v_num=0, train_loss_step=67.10, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  29%|██▉       | 9/31 [00:05<00:12,  1.74it/s, loss=60.7, v_num=0, train_loss_step=67.10, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  29%|██▉       | 9/31 [00:05<00:12,  1.74it/s, loss=61.5, v_num=0, train_loss_step=58.10, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  32%|███▏      | 10/31 [00:05<00:12,  1.74it/s, loss=61.5, v_num=0, train_loss_step=58.10, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  32%|███▏      | 10/31 [00:05<00:12,  1.74it/s, loss=62.2, v_num=0, train_loss_step=61.90, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  35%|███▌      | 11/31 [00:06<00:11,  1.67it/s, loss=62.2, v_num=0, train_loss_step=61.90, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  35%|███▌      | 11/31 [00:06<00:12,  1.67it/s, loss=62.1, v_num=0, train_loss_step=59.40, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  39%|███▊      | 12/31 [00:07<00:11,  1.68it/s, loss=62.1, v_num=0, train_loss_step=59.40, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  39%|███▊      | 12/31 [00:07<00:11,  1.68it/s, loss=61.3, v_num=0, train_loss_step=53.40, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  42%|████▏     | 13/31 [00:07<00:10,  1.69it/s, loss=61.3, v_num=0, train_loss_step=53.40, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  42%|████▏     | 13/31 [00:07<00:10,  1.69it/s, loss=60.4, v_num=0, train_loss_step=59.10, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  45%|████▌     | 14/31 [00:08<00:09,  1.70it/s, loss=60.4, v_num=0, train_loss_step=59.10, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  45%|████▌     | 14/31 [00:08<00:09,  1.70it/s, loss=60.8, v_num=0, train_loss_step=57.70, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  48%|████▊     | 15/31 [00:08<00:09,  1.72it/s, loss=60.8, v_num=0, train_loss_step=57.70, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  48%|████▊     | 15/31 [00:08<00:09,  1.72it/s, loss=60.9, v_num=0, train_loss_step=59.90, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  52%|█████▏    | 16/31 [00:09<00:08,  1.74it/s, loss=60.9, v_num=0, train_loss_step=59.90, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  52%|█████▏    | 16/31 [00:09<00:08,  1.74it/s, loss=60.1, v_num=0, train_loss_step=60.20, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  55%|█████▍    | 17/31 [00:09<00:07,  1.75it/s, loss=60.1, v_num=0, train_loss_step=60.20, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  55%|█████▍    | 17/31 [00:09<00:07,  1.75it/s, loss=60, v_num=0, train_loss_step=70.30, val_loss=94.50, train_loss_epoch=61.80]  #015Epoch 4:  58%|█████▊    | 18/31 [00:10<00:07,  1.76it/s, loss=60, v_num=0, train_loss_step=70.30, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  58%|█████▊    | 18/31 [00:10<00:07,  1.76it/s, loss=60, v_num=0, train_loss_step=63.90, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  61%|██████▏   | 19/31 [00:10<00:06,  1.77it/s, loss=60, v_num=0, train_loss_step=63.90, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  61%|██████▏   | 19/31 [00:10<00:06,  1.77it/s, loss=59.2, v_num=0, train_loss_step=48.90, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  65%|██████▍   | 20/31 [00:11<00:06,  1.77it/s, loss=59.2, v_num=0, train_loss_step=48.90, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  65%|██████▍   | 20/31 [00:11<00:06,  1.77it/s, loss=59.4, v_num=0, train_loss_step=51.20, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  68%|██████▊   | 21/31 [00:12<00:05,  1.73it/s, loss=59.4, v_num=0, train_loss_step=51.20, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  68%|██████▊   | 21/31 [00:12<00:05,  1.73it/s, loss=59.2, v_num=0, train_loss_step=55.60, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  71%|███████   | 22/31 [00:12<00:05,  1.74it/s, loss=59.2, v_num=0, train_loss_step=55.60, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  71%|███████   | 22/31 [00:12<00:05,  1.74it/s, loss=59, v_num=0, train_loss_step=59.90, val_loss=94.50, train_loss_epoch=61.80]  #015Epoch 4:  74%|███████▍  | 23/31 [00:13<00:04,  1.75it/s, loss=59, v_num=0, train_loss_step=59.90, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  74%|███████▍  | 23/31 [00:13<00:04,  1.75it/s, loss=59.6, v_num=0, train_loss_step=67.80, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  77%|███████▋  | 24/31 [00:13<00:03,  1.75it/s, loss=59.6, v_num=0, train_loss_step=67.80, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  77%|███████▋  | 24/31 [00:13<00:03,  1.75it/s, loss=59.5, v_num=0, train_loss_step=53.00, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  81%|████████  | 25/31 [00:14<00:03,  1.76it/s, loss=59.5, v_num=0, train_loss_step=53.00, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  81%|████████  | 25/31 [00:14<00:03,  1.76it/s, loss=60.1, v_num=0, train_loss_step=78.10, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  84%|████████▍ | 26/31 [00:14<00:02,  1.76it/s, loss=60.1, v_num=0, train_loss_step=78.10, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  84%|████████▍ | 26/31 [00:14<00:02,  1.76it/s, loss=59.4, v_num=0, train_loss_step=54.80, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  87%|████████▋ | 27/31 [00:15<00:02,  1.77it/s, loss=59.4, v_num=0, train_loss_step=54.80, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  87%|████████▋ | 27/31 [00:15<00:02,  1.77it/s, loss=60.1, v_num=0, train_loss_step=61.10, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  90%|█████████ | 28/31 [00:15<00:01,  1.78it/s, loss=60.1, v_num=0, train_loss_step=61.10, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  90%|█████████ | 28/31 [00:15<00:01,  1.78it/s, loss=59.4, v_num=0, train_loss_step=53.40, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  94%|█████████▎| 29/31 [00:16<00:01,  1.79it/s, loss=59.4, v_num=0, train_loss_step=53.40, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  94%|█████████▎| 29/31 [00:16<00:01,  1.79it/s, loss=59.2, v_num=0, train_loss_step=55.30, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  97%|█████████▋| 30/31 [00:16<00:00,  1.79it/s, loss=59.2, v_num=0, train_loss_step=55.30, val_loss=94.50, train_loss_epoch=61.80]#015Epoch 4:  97%|█████████▋| 30/31 [00:16<00:00,  1.79it/s, loss=58.9, v_num=0, train_loss_step=55.90, val_loss=94.50, train_loss_epoch=61.80]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]#033[A#015Epoch 4: 100%|██████████| 31/31 [00:18<00:00,  1.65it/s, loss=58.9, v_num=0, train_loss_step=55.90, val_loss=85.10, train_loss_epoch=61.80]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015                                                         #033[A#015Epoch 4: 100%|██████████| 31/31 [00:19<00:00,  1.56it/s, loss=58.9, v_num=0, train_loss_step=55.90, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 4:   0%|          | 0/31 [00:00<?, ?it/s, loss=58.9, v_num=0, train_loss_step=55.90, val_loss=85.10, train_loss_epoch=59.40]         #015Epoch 5:   0%|          | 0/31 [00:00<?, ?it/s, loss=58.9, v_num=0, train_loss_step=55.90, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:   3%|▎         | 1/31 [00:00<00:29,  1.01it/s, loss=58.9, v_num=0, train_loss_step=55.90, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:   3%|▎         | 1/31 [00:00<00:29,  1.01it/s, loss=60.2, v_num=0, train_loss_step=84.30, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:   6%|▋         | 2/31 [00:01<00:22,  1.31it/s, loss=60.2, v_num=0, train_loss_step=84.30, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:   6%|▋         | 2/31 [00:01<00:22,  1.31it/s, loss=60.4, v_num=0, train_loss_step=57.60, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  10%|▉         | 3/31 [00:02<00:19,  1.44it/s, loss=60.4, v_num=0, train_loss_step=57.60, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  10%|▉         | 3/31 [00:02<00:19,  1.44it/s, loss=60.3, v_num=0, train_loss_step=57.40, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  13%|█▎        | 4/31 [00:02<00:17,  1.55it/s, loss=60.3, v_num=0, train_loss_step=57.40, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  13%|█▎        | 4/31 [00:02<00:17,  1.55it/s, loss=61.1, v_num=0, train_loss_step=73.50, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  16%|█▌        | 5/31 [00:03<00:15,  1.63it/s, loss=61.1, v_num=0, train_loss_step=73.50, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  16%|█▌        | 5/31 [00:03<00:15,  1.63it/s, loss=60.8, v_num=0, train_loss_step=53.40, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  19%|█▉        | 6/31 [00:03<00:14,  1.67it/s, loss=60.8, v_num=0, train_loss_step=53.40, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  19%|█▉        | 6/31 [00:03<00:14,  1.67it/s, loss=60.2, v_num=0, train_loss_step=49.60, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  23%|██▎       | 7/31 [00:04<00:13,  1.72it/s, loss=60.2, v_num=0, train_loss_step=49.60, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  23%|██▎       | 7/31 [00:04<00:13,  1.72it/s, loss=58.9, v_num=0, train_loss_step=43.50, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  26%|██▌       | 8/31 [00:04<00:13,  1.75it/s, loss=58.9, v_num=0, train_loss_step=43.50, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  26%|██▌       | 8/31 [00:04<00:13,  1.75it/s, loss=58.8, v_num=0, train_loss_step=61.20, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  29%|██▉       | 9/31 [00:05<00:12,  1.75it/s, loss=58.8, v_num=0, train_loss_step=61.20, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  29%|██▉       | 9/31 [00:05<00:12,  1.75it/s, loss=58.7, v_num=0, train_loss_step=47.40, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  32%|███▏      | 10/31 [00:05<00:11,  1.77it/s, loss=58.7, v_num=0, train_loss_step=47.40, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  32%|███▏      | 10/31 [00:05<00:11,  1.77it/s, loss=58.8, v_num=0, train_loss_step=52.50, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  35%|███▌      | 11/31 [00:06<00:11,  1.71it/s, loss=58.8, v_num=0, train_loss_step=52.50, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  35%|███▌      | 11/31 [00:06<00:11,  1.70it/s, loss=59, v_num=0, train_loss_step=61.00, val_loss=85.10, train_loss_epoch=59.40]  #015Epoch 5:  39%|███▊      | 12/31 [00:06<00:11,  1.72it/s, loss=59, v_num=0, train_loss_step=61.00, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  39%|███▊      | 12/31 [00:06<00:11,  1.72it/s, loss=59.7, v_num=0, train_loss_step=72.40, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  42%|████▏     | 13/31 [00:07<00:10,  1.71it/s, loss=59.7, v_num=0, train_loss_step=72.40, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  42%|████▏     | 13/31 [00:07<00:10,  1.71it/s, loss=60.1, v_num=0, train_loss_step=76.30, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  45%|████▌     | 14/31 [00:08<00:09,  1.72it/s, loss=60.1, v_num=0, train_loss_step=76.30, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  45%|████▌     | 14/31 [00:08<00:09,  1.72it/s, loss=60.6, v_num=0, train_loss_step=63.20, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  48%|████▊     | 15/31 [00:08<00:09,  1.73it/s, loss=60.6, v_num=0, train_loss_step=63.20, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  48%|████▊     | 15/31 [00:08<00:09,  1.73it/s, loss=59.3, v_num=0, train_loss_step=51.60, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  52%|█████▏    | 16/31 [00:09<00:08,  1.74it/s, loss=59.3, v_num=0, train_loss_step=51.60, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  52%|█████▏    | 16/31 [00:09<00:08,  1.74it/s, loss=59.6, v_num=0, train_loss_step=62.10, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  55%|█████▍    | 17/31 [00:09<00:08,  1.74it/s, loss=59.6, v_num=0, train_loss_step=62.10, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  55%|█████▍    | 17/31 [00:09<00:08,  1.74it/s, loss=59.4, v_num=0, train_loss_step=57.10, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  58%|█████▊    | 18/31 [00:10<00:07,  1.73it/s, loss=59.4, v_num=0, train_loss_step=57.10, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  58%|█████▊    | 18/31 [00:10<00:07,  1.73it/s, loss=60.2, v_num=0, train_loss_step=69.30, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  61%|██████▏   | 19/31 [00:10<00:06,  1.74it/s, loss=60.2, v_num=0, train_loss_step=69.30, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  61%|██████▏   | 19/31 [00:10<00:06,  1.74it/s, loss=59.7, v_num=0, train_loss_step=45.20, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  65%|██████▍   | 20/31 [00:11<00:06,  1.73it/s, loss=59.7, v_num=0, train_loss_step=45.20, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  65%|██████▍   | 20/31 [00:11<00:06,  1.73it/s, loss=60.4, v_num=0, train_loss_step=70.00, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  68%|██████▊   | 21/31 [00:12<00:05,  1.67it/s, loss=60.4, v_num=0, train_loss_step=70.00, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  68%|██████▊   | 21/31 [00:12<00:05,  1.67it/s, loss=58.7, v_num=0, train_loss_step=50.10, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  71%|███████   | 22/31 [00:13<00:05,  1.68it/s, loss=58.7, v_num=0, train_loss_step=50.10, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  71%|███████   | 22/31 [00:13<00:05,  1.68it/s, loss=58.1, v_num=0, train_loss_step=46.00, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  74%|███████▍  | 23/31 [00:13<00:04,  1.69it/s, loss=58.1, v_num=0, train_loss_step=46.00, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  74%|███████▍  | 23/31 [00:13<00:04,  1.69it/s, loss=57.8, v_num=0, train_loss_step=50.90, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  77%|███████▋  | 24/31 [00:14<00:04,  1.70it/s, loss=57.8, v_num=0, train_loss_step=50.90, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  77%|███████▋  | 24/31 [00:14<00:04,  1.70it/s, loss=57, v_num=0, train_loss_step=57.50, val_loss=85.10, train_loss_epoch=59.40]  #015Epoch 5:  81%|████████  | 25/31 [00:14<00:03,  1.71it/s, loss=57, v_num=0, train_loss_step=57.50, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  81%|████████  | 25/31 [00:14<00:03,  1.71it/s, loss=57.2, v_num=0, train_loss_step=56.30, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  84%|████████▍ | 26/31 [00:15<00:02,  1.71it/s, loss=57.2, v_num=0, train_loss_step=56.30, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  84%|████████▍ | 26/31 [00:15<00:02,  1.71it/s, loss=56.9, v_num=0, train_loss_step=45.30, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  87%|████████▋ | 27/31 [00:15<00:02,  1.72it/s, loss=56.9, v_num=0, train_loss_step=45.30, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  87%|████████▋ | 27/31 [00:15<00:02,  1.72it/s, loss=57.5, v_num=0, train_loss_step=54.90, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  90%|█████████ | 28/31 [00:16<00:01,  1.73it/s, loss=57.5, v_num=0, train_loss_step=54.90, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  90%|█████████ | 28/31 [00:16<00:01,  1.73it/s, loss=56.9, v_num=0, train_loss_step=48.10, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  94%|█████████▎| 29/31 [00:16<00:01,  1.74it/s, loss=56.9, v_num=0, train_loss_step=48.10, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  94%|█████████▎| 29/31 [00:16<00:01,  1.74it/s, loss=57.5, v_num=0, train_loss_step=59.40, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  97%|█████████▋| 30/31 [00:17<00:00,  1.74it/s, loss=57.5, v_num=0, train_loss_step=59.40, val_loss=85.10, train_loss_epoch=59.40]#015Epoch 5:  97%|█████████▋| 30/31 [00:17<00:00,  1.74it/s, loss=57.4, v_num=0, train_loss_step=51.60, val_loss=85.10, train_loss_epoch=59.40]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]#033[A#015Epoch 5: 100%|██████████| 31/31 [00:19<00:00,  1.60it/s, loss=57.4, v_num=0, train_loss_step=51.60, val_loss=81.90, train_loss_epoch=59.40]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015                                                         #033[A#015Epoch 5: 100%|██████████| 31/31 [00:20<00:00,  1.50it/s, loss=57.4, v_num=0, train_loss_step=51.60, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 5:   0%|          | 0/31 [00:00<?, ?it/s, loss=57.4, v_num=0, train_loss_step=51.60, val_loss=81.90, train_loss_epoch=57.60]         #015Epoch 6:   0%|          | 0/31 [00:00<?, ?it/s, loss=57.4, v_num=0, train_loss_step=51.60, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:   3%|▎         | 1/31 [00:01<00:31,  1.04s/it, loss=57.4, v_num=0, train_loss_step=51.60, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:   3%|▎         | 1/31 [00:01<00:31,  1.04s/it, loss=57.2, v_num=0, train_loss_step=56.10, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:   6%|▋         | 2/31 [00:01<00:22,  1.28it/s, loss=57.2, v_num=0, train_loss_step=56.10, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:   6%|▋         | 2/31 [00:01<00:22,  1.28it/s, loss=56.4, v_num=0, train_loss_step=57.80, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  10%|▉         | 3/31 [00:02<00:19,  1.40it/s, loss=56.4, v_num=0, train_loss_step=57.80, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  10%|▉         | 3/31 [00:02<00:19,  1.40it/s, loss=55.2, v_num=0, train_loss_step=51.40, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  13%|█▎        | 4/31 [00:02<00:18,  1.50it/s, loss=55.2, v_num=0, train_loss_step=51.40, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  13%|█▎        | 4/31 [00:02<00:18,  1.50it/s, loss=54.2, v_num=0, train_loss_step=42.80, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  16%|█▌        | 5/31 [00:03<00:16,  1.57it/s, loss=54.2, v_num=0, train_loss_step=42.80, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  16%|█▌        | 5/31 [00:03<00:16,  1.57it/s, loss=54.4, v_num=0, train_loss_step=55.90, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  19%|█▉        | 6/31 [00:03<00:15,  1.61it/s, loss=54.4, v_num=0, train_loss_step=55.90, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  19%|█▉        | 6/31 [00:03<00:15,  1.61it/s, loss=54.4, v_num=0, train_loss_step=63.00, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  23%|██▎       | 7/31 [00:04<00:14,  1.66it/s, loss=54.4, v_num=0, train_loss_step=63.00, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  23%|██▎       | 7/31 [00:04<00:14,  1.66it/s, loss=54.7, v_num=0, train_loss_step=61.40, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  26%|██▌       | 8/31 [00:04<00:13,  1.67it/s, loss=54.7, v_num=0, train_loss_step=61.40, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  26%|██▌       | 8/31 [00:04<00:13,  1.67it/s, loss=53.7, v_num=0, train_loss_step=50.80, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  29%|██▉       | 9/31 [00:05<00:13,  1.67it/s, loss=53.7, v_num=0, train_loss_step=50.80, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  29%|██▉       | 9/31 [00:05<00:13,  1.67it/s, loss=53.9, v_num=0, train_loss_step=48.50, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  32%|███▏      | 10/31 [00:05<00:12,  1.70it/s, loss=53.9, v_num=0, train_loss_step=48.50, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  32%|███▏      | 10/31 [00:05<00:12,  1.70it/s, loss=54.1, v_num=0, train_loss_step=73.10, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  35%|███▌      | 11/31 [00:06<00:12,  1.62it/s, loss=54.1, v_num=0, train_loss_step=73.10, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  35%|███▌      | 11/31 [00:06<00:12,  1.62it/s, loss=55, v_num=0, train_loss_step=68.30, val_loss=81.90, train_loss_epoch=57.60]  #015Epoch 6:  39%|███▊      | 12/31 [00:07<00:11,  1.64it/s, loss=55, v_num=0, train_loss_step=68.30, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  39%|███▊      | 12/31 [00:07<00:11,  1.64it/s, loss=55.9, v_num=0, train_loss_step=65.50, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  42%|████▏     | 13/31 [00:07<00:10,  1.66it/s, loss=55.9, v_num=0, train_loss_step=65.50, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  42%|████▏     | 13/31 [00:07<00:10,  1.66it/s, loss=55.8, v_num=0, train_loss_step=47.60, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  45%|████▌     | 14/31 [00:08<00:10,  1.68it/s, loss=55.8, v_num=0, train_loss_step=47.60, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  45%|████▌     | 14/31 [00:08<00:10,  1.68it/s, loss=56.1, v_num=0, train_loss_step=65.00, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  48%|████▊     | 15/31 [00:08<00:09,  1.69it/s, loss=56.1, v_num=0, train_loss_step=65.00, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  48%|████▊     | 15/31 [00:08<00:09,  1.69it/s, loss=56, v_num=0, train_loss_step=52.70, val_loss=81.90, train_loss_epoch=57.60]  #015Epoch 6:  52%|█████▏    | 16/31 [00:09<00:08,  1.71it/s, loss=56, v_num=0, train_loss_step=52.70, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  52%|█████▏    | 16/31 [00:09<00:08,  1.71it/s, loss=56.4, v_num=0, train_loss_step=54.40, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  55%|█████▍    | 17/31 [00:09<00:08,  1.72it/s, loss=56.4, v_num=0, train_loss_step=54.40, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  55%|█████▍    | 17/31 [00:09<00:08,  1.72it/s, loss=56.3, v_num=0, train_loss_step=53.30, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  58%|█████▊    | 18/31 [00:10<00:07,  1.73it/s, loss=56.3, v_num=0, train_loss_step=53.30, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  58%|█████▊    | 18/31 [00:10<00:07,  1.73it/s, loss=56.3, v_num=0, train_loss_step=47.20, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  61%|██████▏   | 19/31 [00:10<00:06,  1.74it/s, loss=56.3, v_num=0, train_loss_step=47.20, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  61%|██████▏   | 19/31 [00:10<00:06,  1.74it/s, loss=56.3, v_num=0, train_loss_step=59.60, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  65%|██████▍   | 20/31 [00:11<00:06,  1.75it/s, loss=56.3, v_num=0, train_loss_step=59.60, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  65%|██████▍   | 20/31 [00:11<00:06,  1.75it/s, loss=55.9, v_num=0, train_loss_step=43.00, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  68%|██████▊   | 21/31 [00:12<00:05,  1.71it/s, loss=55.9, v_num=0, train_loss_step=43.00, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  68%|██████▊   | 21/31 [00:12<00:05,  1.71it/s, loss=55.6, v_num=0, train_loss_step=50.40, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  71%|███████   | 22/31 [00:12<00:05,  1.72it/s, loss=55.6, v_num=0, train_loss_step=50.40, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  71%|███████   | 22/31 [00:12<00:05,  1.72it/s, loss=54.9, v_num=0, train_loss_step=44.90, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  74%|███████▍  | 23/31 [00:13<00:04,  1.73it/s, loss=54.9, v_num=0, train_loss_step=44.90, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  74%|███████▍  | 23/31 [00:13<00:04,  1.73it/s, loss=55, v_num=0, train_loss_step=53.30, val_loss=81.90, train_loss_epoch=57.60]  #015Epoch 6:  77%|███████▋  | 24/31 [00:13<00:04,  1.74it/s, loss=55, v_num=0, train_loss_step=53.30, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  77%|███████▋  | 24/31 [00:13<00:04,  1.74it/s, loss=55.7, v_num=0, train_loss_step=56.20, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  81%|████████  | 25/31 [00:14<00:03,  1.75it/s, loss=55.7, v_num=0, train_loss_step=56.20, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  81%|████████  | 25/31 [00:14<00:03,  1.75it/s, loss=55.7, v_num=0, train_loss_step=55.50, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  84%|████████▍ | 26/31 [00:14<00:02,  1.76it/s, loss=55.7, v_num=0, train_loss_step=55.50, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  84%|████████▍ | 26/31 [00:14<00:02,  1.76it/s, loss=55.5, v_num=0, train_loss_step=58.50, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  87%|████████▋ | 27/31 [00:15<00:02,  1.77it/s, loss=55.5, v_num=0, train_loss_step=58.50, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  87%|████████▋ | 27/31 [00:15<00:02,  1.77it/s, loss=55.4, v_num=0, train_loss_step=59.70, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  90%|█████████ | 28/31 [00:15<00:01,  1.78it/s, loss=55.4, v_num=0, train_loss_step=59.70, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  90%|█████████ | 28/31 [00:15<00:01,  1.78it/s, loss=55.9, v_num=0, train_loss_step=61.80, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  94%|█████████▎| 29/31 [00:16<00:01,  1.79it/s, loss=55.9, v_num=0, train_loss_step=61.80, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  94%|█████████▎| 29/31 [00:16<00:01,  1.79it/s, loss=57, v_num=0, train_loss_step=69.50, val_loss=81.90, train_loss_epoch=57.60]  #015Epoch 6:  97%|█████████▋| 30/31 [00:16<00:00,  1.79it/s, loss=57, v_num=0, train_loss_step=69.50, val_loss=81.90, train_loss_epoch=57.60]#015Epoch 6:  97%|█████████▋| 30/31 [00:16<00:00,  1.79it/s, loss=56.6, v_num=0, train_loss_step=65.40, val_loss=81.90, train_loss_epoch=57.60]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]#033[A#015Epoch 6: 100%|██████████| 31/31 [00:18<00:00,  1.64it/s, loss=56.6, v_num=0, train_loss_step=65.40, val_loss=77.70, train_loss_epoch=57.60]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015                                                         #033[A#015Epoch 6: 100%|██████████| 31/31 [00:20<00:00,  1.55it/s, loss=56.6, v_num=0, train_loss_step=65.40, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 6:   0%|          | 0/31 [00:00<?, ?it/s, loss=56.6, v_num=0, train_loss_step=65.40, val_loss=77.70, train_loss_epoch=56.40]         #015Epoch 7:   0%|          | 0/31 [00:00<?, ?it/s, loss=56.6, v_num=0, train_loss_step=65.40, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:   3%|▎         | 1/31 [00:01<00:31,  1.04s/it, loss=56.6, v_num=0, train_loss_step=65.40, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:   3%|▎         | 1/31 [00:01<00:31,  1.04s/it, loss=56.3, v_num=0, train_loss_step=62.40, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:   6%|▋         | 2/31 [00:01<00:22,  1.30it/s, loss=56.3, v_num=0, train_loss_step=62.40, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:   6%|▋         | 2/31 [00:01<00:22,  1.30it/s, loss=56.3, v_num=0, train_loss_step=65.40, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  10%|▉         | 3/31 [00:02<00:19,  1.46it/s, loss=56.3, v_num=0, train_loss_step=65.40, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  10%|▉         | 3/31 [00:02<00:19,  1.46it/s, loss=56.2, v_num=0, train_loss_step=46.80, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  13%|█▎        | 4/31 [00:02<00:17,  1.58it/s, loss=56.2, v_num=0, train_loss_step=46.80, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  13%|█▎        | 4/31 [00:02<00:17,  1.58it/s, loss=55.3, v_num=0, train_loss_step=47.10, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  16%|█▌        | 5/31 [00:03<00:15,  1.64it/s, loss=55.3, v_num=0, train_loss_step=47.10, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  16%|█▌        | 5/31 [00:03<00:15,  1.64it/s, loss=56.6, v_num=0, train_loss_step=77.70, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  19%|█▉        | 6/31 [00:03<00:14,  1.69it/s, loss=56.6, v_num=0, train_loss_step=77.70, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  19%|█▉        | 6/31 [00:03<00:14,  1.68it/s, loss=56.8, v_num=0, train_loss_step=58.90, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  23%|██▎       | 7/31 [00:04<00:13,  1.73it/s, loss=56.8, v_num=0, train_loss_step=58.90, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  23%|██▎       | 7/31 [00:04<00:13,  1.73it/s, loss=57.2, v_num=0, train_loss_step=61.10, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  26%|██▌       | 8/31 [00:04<00:13,  1.77it/s, loss=57.2, v_num=0, train_loss_step=61.10, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  26%|██▌       | 8/31 [00:04<00:13,  1.76it/s, loss=57.5, v_num=0, train_loss_step=52.00, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  29%|██▉       | 9/31 [00:05<00:12,  1.79it/s, loss=57.5, v_num=0, train_loss_step=52.00, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  29%|██▉       | 9/31 [00:05<00:12,  1.79it/s, loss=57.4, v_num=0, train_loss_step=58.20, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  32%|███▏      | 10/31 [00:05<00:11,  1.82it/s, loss=57.4, v_num=0, train_loss_step=58.20, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  32%|███▏      | 10/31 [00:05<00:11,  1.82it/s, loss=57.3, v_num=0, train_loss_step=42.10, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  35%|███▌      | 11/31 [00:06<00:11,  1.74it/s, loss=57.3, v_num=0, train_loss_step=42.10, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  35%|███▌      | 11/31 [00:06<00:11,  1.74it/s, loss=57.4, v_num=0, train_loss_step=51.50, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  39%|███▊      | 12/31 [00:06<00:10,  1.75it/s, loss=57.4, v_num=0, train_loss_step=51.50, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  39%|███▊      | 12/31 [00:06<00:10,  1.75it/s, loss=58.1, v_num=0, train_loss_step=59.50, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  42%|████▏     | 13/31 [00:07<00:10,  1.76it/s, loss=58.1, v_num=0, train_loss_step=59.50, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  42%|████▏     | 13/31 [00:07<00:10,  1.76it/s, loss=58.2, v_num=0, train_loss_step=54.00, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  45%|████▌     | 14/31 [00:07<00:09,  1.77it/s, loss=58.2, v_num=0, train_loss_step=54.00, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  45%|████▌     | 14/31 [00:07<00:09,  1.77it/s, loss=58, v_num=0, train_loss_step=53.30, val_loss=77.70, train_loss_epoch=56.40]  #015Epoch 7:  48%|████▊     | 15/31 [00:08<00:08,  1.78it/s, loss=58, v_num=0, train_loss_step=53.30, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  48%|████▊     | 15/31 [00:08<00:08,  1.78it/s, loss=57.6, v_num=0, train_loss_step=47.40, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  52%|█████▏    | 16/31 [00:08<00:08,  1.80it/s, loss=57.6, v_num=0, train_loss_step=47.40, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  52%|█████▏    | 16/31 [00:08<00:08,  1.80it/s, loss=58.6, v_num=0, train_loss_step=78.20, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  55%|█████▍    | 17/31 [00:09<00:07,  1.80it/s, loss=58.6, v_num=0, train_loss_step=78.20, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  55%|█████▍    | 17/31 [00:09<00:07,  1.80it/s, loss=58.7, v_num=0, train_loss_step=62.00, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  58%|█████▊    | 18/31 [00:09<00:07,  1.80it/s, loss=58.7, v_num=0, train_loss_step=62.00, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  58%|█████▊    | 18/31 [00:09<00:07,  1.80it/s, loss=58.3, v_num=0, train_loss_step=53.50, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  61%|██████▏   | 19/31 [00:10<00:06,  1.81it/s, loss=58.3, v_num=0, train_loss_step=53.50, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  61%|██████▏   | 19/31 [00:10<00:06,  1.81it/s, loss=58.4, v_num=0, train_loss_step=72.40, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  65%|██████▍   | 20/31 [00:10<00:06,  1.82it/s, loss=58.4, v_num=0, train_loss_step=72.40, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  65%|██████▍   | 20/31 [00:10<00:06,  1.82it/s, loss=57.2, v_num=0, train_loss_step=40.50, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  68%|██████▊   | 21/31 [00:11<00:05,  1.77it/s, loss=57.2, v_num=0, train_loss_step=40.50, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  68%|██████▊   | 21/31 [00:11<00:05,  1.77it/s, loss=56.6, v_num=0, train_loss_step=51.30, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  71%|███████   | 22/31 [00:12<00:05,  1.78it/s, loss=56.6, v_num=0, train_loss_step=51.30, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  71%|███████   | 22/31 [00:12<00:05,  1.78it/s, loss=55.9, v_num=0, train_loss_step=50.00, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  74%|███████▍  | 23/31 [00:12<00:04,  1.79it/s, loss=55.9, v_num=0, train_loss_step=50.00, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  74%|███████▍  | 23/31 [00:12<00:04,  1.79it/s, loss=56.4, v_num=0, train_loss_step=56.40, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  77%|███████▋  | 24/31 [00:13<00:03,  1.79it/s, loss=56.4, v_num=0, train_loss_step=56.40, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  77%|███████▋  | 24/31 [00:13<00:03,  1.79it/s, loss=57.4, v_num=0, train_loss_step=68.60, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  81%|████████  | 25/31 [00:13<00:03,  1.80it/s, loss=57.4, v_num=0, train_loss_step=68.60, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  81%|████████  | 25/31 [00:13<00:03,  1.80it/s, loss=56, v_num=0, train_loss_step=49.50, val_loss=77.70, train_loss_epoch=56.40]  #015Epoch 7:  84%|████████▍ | 26/31 [00:14<00:02,  1.81it/s, loss=56, v_num=0, train_loss_step=49.50, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  84%|████████▍ | 26/31 [00:14<00:02,  1.81it/s, loss=55.6, v_num=0, train_loss_step=50.70, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  87%|████████▋ | 27/31 [00:14<00:02,  1.82it/s, loss=55.6, v_num=0, train_loss_step=50.70, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  87%|████████▋ | 27/31 [00:14<00:02,  1.82it/s, loss=55.2, v_num=0, train_loss_step=52.90, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  90%|█████████ | 28/31 [00:15<00:01,  1.83it/s, loss=55.2, v_num=0, train_loss_step=52.90, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  90%|█████████ | 28/31 [00:15<00:01,  1.83it/s, loss=55.5, v_num=0, train_loss_step=58.80, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  94%|█████████▎| 29/31 [00:15<00:01,  1.83it/s, loss=55.5, v_num=0, train_loss_step=58.80, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  94%|█████████▎| 29/31 [00:15<00:01,  1.83it/s, loss=55.4, v_num=0, train_loss_step=55.30, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  97%|█████████▋| 30/31 [00:16<00:00,  1.83it/s, loss=55.4, v_num=0, train_loss_step=55.30, val_loss=77.70, train_loss_epoch=56.40]#015Epoch 7:  97%|█████████▋| 30/31 [00:16<00:00,  1.83it/s, loss=55.8, v_num=0, train_loss_step=50.40, val_loss=77.70, train_loss_epoch=56.40]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]#033[A#015Epoch 7: 100%|██████████| 31/31 [00:18<00:00,  1.68it/s, loss=55.8, v_num=0, train_loss_step=50.40, val_loss=76.40, train_loss_epoch=56.40]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015                                                         #033[A#015Epoch 7: 100%|██████████| 31/31 [00:19<00:00,  1.57it/s, loss=55.8, v_num=0, train_loss_step=50.40, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 7:   0%|          | 0/31 [00:00<?, ?it/s, loss=55.8, v_num=0, train_loss_step=50.40, val_loss=76.40, train_loss_epoch=56.30]         #015Epoch 8:   0%|          | 0/31 [00:00<?, ?it/s, loss=55.8, v_num=0, train_loss_step=50.40, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:   3%|▎         | 1/31 [00:01<00:32,  1.09s/it, loss=55.8, v_num=0, train_loss_step=50.40, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:   3%|▎         | 1/31 [00:01<00:32,  1.09s/it, loss=55.6, v_num=0, train_loss_step=47.10, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:   6%|▋         | 2/31 [00:01<00:24,  1.19it/s, loss=55.6, v_num=0, train_loss_step=47.10, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:   6%|▋         | 2/31 [00:01<00:24,  1.19it/s, loss=56, v_num=0, train_loss_step=67.90, val_loss=76.40, train_loss_epoch=56.30]  #015Epoch 8:  10%|▉         | 3/31 [00:02<00:20,  1.37it/s, loss=56, v_num=0, train_loss_step=67.90, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  10%|▉         | 3/31 [00:02<00:20,  1.37it/s, loss=55.9, v_num=0, train_loss_step=51.10, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  13%|█▎        | 4/31 [00:02<00:18,  1.49it/s, loss=55.9, v_num=0, train_loss_step=51.10, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  13%|█▎        | 4/31 [00:02<00:18,  1.49it/s, loss=56.5, v_num=0, train_loss_step=65.50, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  16%|█▌        | 5/31 [00:03<00:16,  1.58it/s, loss=56.5, v_num=0, train_loss_step=65.50, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  16%|█▌        | 5/31 [00:03<00:16,  1.57it/s, loss=57.1, v_num=0, train_loss_step=59.70, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  19%|█▉        | 6/31 [00:03<00:15,  1.62it/s, loss=57.1, v_num=0, train_loss_step=59.70, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  19%|█▉        | 6/31 [00:03<00:15,  1.62it/s, loss=56.4, v_num=0, train_loss_step=64.60, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  23%|██▎       | 7/31 [00:04<00:14,  1.68it/s, loss=56.4, v_num=0, train_loss_step=64.60, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  23%|██▎       | 7/31 [00:04<00:14,  1.67it/s, loss=56.9, v_num=0, train_loss_step=72.60, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  26%|██▌       | 8/31 [00:04<00:13,  1.71it/s, loss=56.9, v_num=0, train_loss_step=72.60, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  26%|██▌       | 8/31 [00:04<00:13,  1.70it/s, loss=57, v_num=0, train_loss_step=54.20, val_loss=76.40, train_loss_epoch=56.30]  #015Epoch 8:  29%|██▉       | 9/31 [00:05<00:12,  1.73it/s, loss=57, v_num=0, train_loss_step=54.20, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  29%|██▉       | 9/31 [00:05<00:12,  1.73it/s, loss=56.5, v_num=0, train_loss_step=63.00, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  32%|███▏      | 10/31 [00:05<00:12,  1.74it/s, loss=56.5, v_num=0, train_loss_step=63.00, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  32%|███▏      | 10/31 [00:05<00:12,  1.74it/s, loss=57, v_num=0, train_loss_step=50.80, val_loss=76.40, train_loss_epoch=56.30]  #015Epoch 8:  35%|███▌      | 11/31 [00:06<00:12,  1.65it/s, loss=57, v_num=0, train_loss_step=50.80, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  35%|███▌      | 11/31 [00:06<00:12,  1.65it/s, loss=57, v_num=0, train_loss_step=51.90, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  39%|███▊      | 12/31 [00:07<00:11,  1.66it/s, loss=57, v_num=0, train_loss_step=51.90, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  39%|███▊      | 12/31 [00:07<00:11,  1.66it/s, loss=57.2, v_num=0, train_loss_step=52.10, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  42%|████▏     | 13/31 [00:07<00:10,  1.68it/s, loss=57.2, v_num=0, train_loss_step=52.10, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  42%|████▏     | 13/31 [00:07<00:10,  1.68it/s, loss=56.5, v_num=0, train_loss_step=44.10, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  45%|████▌     | 14/31 [00:08<00:10,  1.69it/s, loss=56.5, v_num=0, train_loss_step=44.10, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  45%|████▌     | 14/31 [00:08<00:10,  1.69it/s, loss=55.2, v_num=0, train_loss_step=41.60, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  48%|████▊     | 15/31 [00:08<00:09,  1.68it/s, loss=55.2, v_num=0, train_loss_step=41.60, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  48%|████▊     | 15/31 [00:08<00:09,  1.68it/s, loss=55.3, v_num=0, train_loss_step=52.40, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  52%|█████▏    | 16/31 [00:09<00:08,  1.69it/s, loss=55.3, v_num=0, train_loss_step=52.40, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  52%|█████▏    | 16/31 [00:09<00:08,  1.69it/s, loss=54.9, v_num=0, train_loss_step=42.20, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  55%|█████▍    | 17/31 [00:10<00:08,  1.69it/s, loss=54.9, v_num=0, train_loss_step=42.20, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  55%|█████▍    | 17/31 [00:10<00:08,  1.69it/s, loss=54.5, v_num=0, train_loss_step=45.40, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  58%|█████▊    | 18/31 [00:10<00:07,  1.67it/s, loss=54.5, v_num=0, train_loss_step=45.40, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  58%|█████▊    | 18/31 [00:10<00:07,  1.67it/s, loss=54.2, v_num=0, train_loss_step=51.80, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  61%|██████▏   | 19/31 [00:11<00:07,  1.67it/s, loss=54.2, v_num=0, train_loss_step=51.80, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  61%|██████▏   | 19/31 [00:11<00:07,  1.67it/s, loss=53.6, v_num=0, train_loss_step=43.70, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  65%|██████▍   | 20/31 [00:11<00:06,  1.68it/s, loss=53.6, v_num=0, train_loss_step=43.70, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  65%|██████▍   | 20/31 [00:11<00:06,  1.68it/s, loss=54.2, v_num=0, train_loss_step=62.10, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  68%|██████▊   | 21/31 [00:12<00:06,  1.65it/s, loss=54.2, v_num=0, train_loss_step=62.10, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  68%|██████▊   | 21/31 [00:12<00:06,  1.65it/s, loss=55, v_num=0, train_loss_step=63.30, val_loss=76.40, train_loss_epoch=56.30]  #015Epoch 8:  71%|███████   | 22/31 [00:13<00:05,  1.66it/s, loss=55, v_num=0, train_loss_step=63.30, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  71%|███████   | 22/31 [00:13<00:05,  1.66it/s, loss=54.3, v_num=0, train_loss_step=54.30, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  74%|███████▍  | 23/31 [00:13<00:04,  1.67it/s, loss=54.3, v_num=0, train_loss_step=54.30, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  74%|███████▍  | 23/31 [00:13<00:04,  1.67it/s, loss=55.9, v_num=0, train_loss_step=83.10, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  77%|███████▋  | 24/31 [00:14<00:04,  1.68it/s, loss=55.9, v_num=0, train_loss_step=83.10, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  77%|███████▋  | 24/31 [00:14<00:04,  1.68it/s, loss=55.1, v_num=0, train_loss_step=49.90, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  81%|████████  | 25/31 [00:14<00:03,  1.69it/s, loss=55.1, v_num=0, train_loss_step=49.90, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  81%|████████  | 25/31 [00:14<00:03,  1.69it/s, loss=54.5, v_num=0, train_loss_step=47.50, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  84%|████████▍ | 26/31 [00:15<00:02,  1.70it/s, loss=54.5, v_num=0, train_loss_step=47.50, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  84%|████████▍ | 26/31 [00:15<00:02,  1.70it/s, loss=54, v_num=0, train_loss_step=54.50, val_loss=76.40, train_loss_epoch=56.30]  #015Epoch 8:  87%|████████▋ | 27/31 [00:15<00:02,  1.72it/s, loss=54, v_num=0, train_loss_step=54.50, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  87%|████████▋ | 27/31 [00:15<00:02,  1.72it/s, loss=52.3, v_num=0, train_loss_step=37.40, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  90%|█████████ | 28/31 [00:16<00:01,  1.73it/s, loss=52.3, v_num=0, train_loss_step=37.40, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  90%|█████████ | 28/31 [00:16<00:01,  1.73it/s, loss=52.4, v_num=0, train_loss_step=56.20, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  94%|█████████▎| 29/31 [00:16<00:01,  1.73it/s, loss=52.4, v_num=0, train_loss_step=56.20, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  94%|█████████▎| 29/31 [00:16<00:01,  1.73it/s, loss=52, v_num=0, train_loss_step=56.30, val_loss=76.40, train_loss_epoch=56.30]  #015Epoch 8:  97%|█████████▋| 30/31 [00:17<00:00,  1.74it/s, loss=52, v_num=0, train_loss_step=56.30, val_loss=76.40, train_loss_epoch=56.30]#015Epoch 8:  97%|█████████▋| 30/31 [00:17<00:00,  1.74it/s, loss=52.2, v_num=0, train_loss_step=54.00, val_loss=76.40, train_loss_epoch=56.30]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]#033[A#015Epoch 8: 100%|██████████| 31/31 [00:19<00:00,  1.60it/s, loss=52.2, v_num=0, train_loss_step=54.00, val_loss=77.40, train_loss_epoch=56.30]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015                                                         #033[A#015Epoch 8: 100%|██████████| 31/31 [00:20<00:00,  1.52it/s, loss=52.2, v_num=0, train_loss_step=54.00, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 8:   0%|          | 0/31 [00:00<?, ?it/s, loss=52.2, v_num=0, train_loss_step=54.00, val_loss=77.40, train_loss_epoch=54.70]         #015Epoch 9:   0%|          | 0/31 [00:00<?, ?it/s, loss=52.2, v_num=0, train_loss_step=54.00, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:   3%|▎         | 1/31 [00:01<00:34,  1.14s/it, loss=52.2, v_num=0, train_loss_step=54.00, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:   3%|▎         | 1/31 [00:01<00:34,  1.14s/it, loss=52.9, v_num=0, train_loss_step=66.50, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:   6%|▋         | 2/31 [00:01<00:23,  1.23it/s, loss=52.9, v_num=0, train_loss_step=66.50, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:   6%|▋         | 2/31 [00:01<00:23,  1.23it/s, loss=52.7, v_num=0, train_loss_step=47.90, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  10%|▉         | 3/31 [00:02<00:19,  1.40it/s, loss=52.7, v_num=0, train_loss_step=47.90, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  10%|▉         | 3/31 [00:02<00:19,  1.40it/s, loss=53.1, v_num=0, train_loss_step=53.00, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  13%|█▎        | 4/31 [00:02<00:17,  1.51it/s, loss=53.1, v_num=0, train_loss_step=53.00, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  13%|█▎        | 4/31 [00:02<00:17,  1.51it/s, loss=53.8, v_num=0, train_loss_step=54.50, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  16%|█▌        | 5/31 [00:03<00:16,  1.60it/s, loss=53.8, v_num=0, train_loss_step=54.50, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  16%|█▌        | 5/31 [00:03<00:16,  1.60it/s, loss=54.8, v_num=0, train_loss_step=72.40, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  19%|█▉        | 6/31 [00:03<00:15,  1.63it/s, loss=54.8, v_num=0, train_loss_step=72.40, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  19%|█▉        | 6/31 [00:03<00:15,  1.63it/s, loss=56.1, v_num=0, train_loss_step=67.80, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  23%|██▎       | 7/31 [00:04<00:14,  1.67it/s, loss=56.1, v_num=0, train_loss_step=67.80, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  23%|██▎       | 7/31 [00:04<00:14,  1.67it/s, loss=55.6, v_num=0, train_loss_step=35.60, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  26%|██▌       | 8/31 [00:04<00:13,  1.70it/s, loss=55.6, v_num=0, train_loss_step=35.60, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  26%|██▌       | 8/31 [00:04<00:13,  1.70it/s, loss=55.8, v_num=0, train_loss_step=57.00, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  29%|██▉       | 9/31 [00:05<00:12,  1.71it/s, loss=55.8, v_num=0, train_loss_step=57.00, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  29%|██▉       | 9/31 [00:05<00:12,  1.71it/s, loss=57.3, v_num=0, train_loss_step=71.90, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  32%|███▏      | 10/31 [00:05<00:12,  1.73it/s, loss=57.3, v_num=0, train_loss_step=71.90, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  32%|███▏      | 10/31 [00:05<00:12,  1.73it/s, loss=57, v_num=0, train_loss_step=56.60, val_loss=77.40, train_loss_epoch=54.70]  #015Epoch 9:  35%|███▌      | 11/31 [00:06<00:12,  1.66it/s, loss=57, v_num=0, train_loss_step=56.60, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  35%|███▌      | 11/31 [00:06<00:12,  1.66it/s, loss=56, v_num=0, train_loss_step=43.60, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  39%|███▊      | 12/31 [00:07<00:11,  1.68it/s, loss=56, v_num=0, train_loss_step=43.60, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  39%|███▊      | 12/31 [00:07<00:11,  1.68it/s, loss=55.9, v_num=0, train_loss_step=51.80, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  42%|████▏     | 13/31 [00:07<00:10,  1.70it/s, loss=55.9, v_num=0, train_loss_step=51.80, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  42%|████▏     | 13/31 [00:07<00:10,  1.70it/s, loss=53.6, v_num=0, train_loss_step=38.40, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  45%|████▌     | 14/31 [00:08<00:09,  1.72it/s, loss=53.6, v_num=0, train_loss_step=38.40, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  45%|████▌     | 14/31 [00:08<00:09,  1.72it/s, loss=54.1, v_num=0, train_loss_step=59.50, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  48%|████▊     | 15/31 [00:08<00:09,  1.74it/s, loss=54.1, v_num=0, train_loss_step=59.50, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  48%|████▊     | 15/31 [00:08<00:09,  1.73it/s, loss=54, v_num=0, train_loss_step=45.20, val_loss=77.40, train_loss_epoch=54.70]  #015Epoch 9:  52%|█████▏    | 16/31 [00:09<00:08,  1.75it/s, loss=54, v_num=0, train_loss_step=45.20, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  52%|█████▏    | 16/31 [00:09<00:08,  1.75it/s, loss=53.7, v_num=0, train_loss_step=47.80, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  55%|█████▍    | 17/31 [00:09<00:07,  1.77it/s, loss=53.7, v_num=0, train_loss_step=47.80, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  55%|█████▍    | 17/31 [00:09<00:07,  1.77it/s, loss=53.7, v_num=0, train_loss_step=38.80, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  58%|█████▊    | 18/31 [00:10<00:07,  1.78it/s, loss=53.7, v_num=0, train_loss_step=38.80, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  58%|█████▊    | 18/31 [00:10<00:07,  1.78it/s, loss=53.5, v_num=0, train_loss_step=51.10, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  61%|██████▏   | 19/31 [00:10<00:06,  1.79it/s, loss=53.5, v_num=0, train_loss_step=51.10, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  61%|██████▏   | 19/31 [00:10<00:06,  1.79it/s, loss=53.3, v_num=0, train_loss_step=53.00, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  65%|██████▍   | 20/31 [00:11<00:06,  1.81it/s, loss=53.3, v_num=0, train_loss_step=53.00, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  65%|██████▍   | 20/31 [00:11<00:06,  1.81it/s, loss=53, v_num=0, train_loss_step=47.30, val_loss=77.40, train_loss_epoch=54.70]  #015Epoch 9:  68%|██████▊   | 21/31 [00:11<00:05,  1.76it/s, loss=53, v_num=0, train_loss_step=47.30, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  68%|██████▊   | 21/31 [00:11<00:05,  1.76it/s, loss=52.6, v_num=0, train_loss_step=59.70, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  71%|███████   | 22/31 [00:12<00:05,  1.77it/s, loss=52.6, v_num=0, train_loss_step=59.70, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  71%|███████   | 22/31 [00:12<00:05,  1.77it/s, loss=53, v_num=0, train_loss_step=55.30, val_loss=77.40, train_loss_epoch=54.70]  #015Epoch 9:  74%|███████▍  | 23/31 [00:12<00:04,  1.78it/s, loss=53, v_num=0, train_loss_step=55.30, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  74%|███████▍  | 23/31 [00:12<00:04,  1.78it/s, loss=53.4, v_num=0, train_loss_step=61.20, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  77%|███████▋  | 24/31 [00:13<00:03,  1.79it/s, loss=53.4, v_num=0, train_loss_step=61.20, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  77%|███████▋  | 24/31 [00:13<00:03,  1.79it/s, loss=53.2, v_num=0, train_loss_step=49.40, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  81%|████████  | 25/31 [00:13<00:03,  1.80it/s, loss=53.2, v_num=0, train_loss_step=49.40, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  81%|████████  | 25/31 [00:13<00:03,  1.80it/s, loss=52.5, v_num=0, train_loss_step=59.30, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  84%|████████▍ | 26/31 [00:14<00:02,  1.80it/s, loss=52.5, v_num=0, train_loss_step=59.30, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  84%|████████▍ | 26/31 [00:14<00:02,  1.80it/s, loss=52.2, v_num=0, train_loss_step=61.60, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  87%|████████▋ | 27/31 [00:14<00:02,  1.81it/s, loss=52.2, v_num=0, train_loss_step=61.60, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  87%|████████▋ | 27/31 [00:14<00:02,  1.81it/s, loss=53.1, v_num=0, train_loss_step=53.70, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  90%|█████████ | 28/31 [00:15<00:01,  1.81it/s, loss=53.1, v_num=0, train_loss_step=53.70, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  90%|█████████ | 28/31 [00:15<00:01,  1.81it/s, loss=52.9, v_num=0, train_loss_step=53.40, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  94%|█████████▎| 29/31 [00:15<00:01,  1.82it/s, loss=52.9, v_num=0, train_loss_step=53.40, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  94%|█████████▎| 29/31 [00:15<00:01,  1.82it/s, loss=51.9, v_num=0, train_loss_step=50.80, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  97%|█████████▋| 30/31 [00:16<00:00,  1.82it/s, loss=51.9, v_num=0, train_loss_step=50.80, val_loss=77.40, train_loss_epoch=54.70]#015Epoch 9:  97%|█████████▋| 30/31 [00:16<00:00,  1.82it/s, loss=51.9, v_num=0, train_loss_step=58.30, val_loss=77.40, train_loss_epoch=54.70]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 1/1 [00:00<00:00,  1.00it/s]#033[A#015Epoch 9: 100%|██████████| 31/31 [00:18<00:00,  1.67it/s, loss=51.9, v_num=0, train_loss_step=58.30, val_loss=78.80, train_loss_epoch=54.70]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015                                                         #033[A#015Epoch 9: 100%|██████████| 31/31 [00:19<00:00,  1.57it/s, loss=51.9, v_num=0, train_loss_step=58.30, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 9:   0%|          | 0/31 [00:00<?, ?it/s, loss=51.9, v_num=0, train_loss_step=58.30, val_loss=78.80, train_loss_epoch=54.10]         #015Epoch 10:   0%|          | 0/31 [00:00<?, ?it/s, loss=51.9, v_num=0, train_loss_step=58.30, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:   3%|▎         | 1/31 [00:01<00:30,  1.03s/it, loss=51.9, v_num=0, train_loss_step=58.30, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:   3%|▎         | 1/31 [00:01<00:30,  1.03s/it, loss=52.8, v_num=0, train_loss_step=61.30, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:   6%|▋         | 2/31 [00:01<00:26,  1.10it/s, loss=52.8, v_num=0, train_loss_step=61.30, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:   6%|▋         | 2/31 [00:01<00:26,  1.10it/s, loss=53.5, v_num=0, train_loss_step=65.20, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  10%|▉         | 3/31 [00:02<00:21,  1.32it/s, loss=53.5, v_num=0, train_loss_step=65.20, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  10%|▉         | 3/31 [00:02<00:21,  1.31it/s, loss=54.8, v_num=0, train_loss_step=63.80, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  13%|█▎        | 4/31 [00:02<00:19,  1.41it/s, loss=54.8, v_num=0, train_loss_step=63.80, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  13%|█▎        | 4/31 [00:02<00:19,  1.41it/s, loss=54.1, v_num=0, train_loss_step=45.10, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  16%|█▌        | 5/31 [00:03<00:17,  1.50it/s, loss=54.1, v_num=0, train_loss_step=45.10, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  16%|█▌        | 5/31 [00:03<00:17,  1.50it/s, loss=53.9, v_num=0, train_loss_step=42.60, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  19%|█▉        | 6/31 [00:03<00:16,  1.55it/s, loss=53.9, v_num=0, train_loss_step=42.60, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  19%|█▉        | 6/31 [00:03<00:16,  1.55it/s, loss=54.1, v_num=0, train_loss_step=51.80, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  23%|██▎       | 7/31 [00:04<00:15,  1.59it/s, loss=54.1, v_num=0, train_loss_step=51.80, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  23%|██▎       | 7/31 [00:04<00:15,  1.59it/s, loss=54.8, v_num=0, train_loss_step=53.00, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  26%|██▌       | 8/31 [00:04<00:14,  1.62it/s, loss=54.8, v_num=0, train_loss_step=53.00, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  26%|██▌       | 8/31 [00:04<00:14,  1.62it/s, loss=54.8, v_num=0, train_loss_step=51.20, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  29%|██▉       | 9/31 [00:05<00:13,  1.65it/s, loss=54.8, v_num=0, train_loss_step=51.20, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  29%|██▉       | 9/31 [00:05<00:13,  1.65it/s, loss=54.4, v_num=0, train_loss_step=43.90, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  32%|███▏      | 10/31 [00:06<00:12,  1.66it/s, loss=54.4, v_num=0, train_loss_step=43.90, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  32%|███▏      | 10/31 [00:06<00:12,  1.66it/s, loss=54.5, v_num=0, train_loss_step=49.80, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  35%|███▌      | 11/31 [00:06<00:12,  1.62it/s, loss=54.5, v_num=0, train_loss_step=49.80, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  35%|███▌      | 11/31 [00:06<00:12,  1.62it/s, loss=54.5, v_num=0, train_loss_step=59.30, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  39%|███▊      | 12/31 [00:07<00:11,  1.64it/s, loss=54.5, v_num=0, train_loss_step=59.30, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  39%|███▊      | 12/31 [00:07<00:11,  1.64it/s, loss=54.1, v_num=0, train_loss_step=48.20, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  42%|████▏     | 13/31 [00:07<00:10,  1.66it/s, loss=54.1, v_num=0, train_loss_step=48.20, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  42%|████▏     | 13/31 [00:07<00:10,  1.66it/s, loss=54, v_num=0, train_loss_step=59.10, val_loss=78.80, train_loss_epoch=54.10]  #015Epoch 10:  45%|████▌     | 14/31 [00:08<00:10,  1.68it/s, loss=54, v_num=0, train_loss_step=59.10, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  45%|████▌     | 14/31 [00:08<00:10,  1.68it/s, loss=54.4, v_num=0, train_loss_step=55.70, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  48%|████▊     | 15/31 [00:08<00:09,  1.70it/s, loss=54.4, v_num=0, train_loss_step=55.70, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  48%|████▊     | 15/31 [00:08<00:09,  1.70it/s, loss=54.2, v_num=0, train_loss_step=56.70, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  52%|█████▏    | 16/31 [00:09<00:08,  1.72it/s, loss=54.2, v_num=0, train_loss_step=56.70, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  52%|█████▏    | 16/31 [00:09<00:08,  1.72it/s, loss=53.9, v_num=0, train_loss_step=55.60, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  55%|█████▍    | 17/31 [00:09<00:08,  1.73it/s, loss=53.9, v_num=0, train_loss_step=55.60, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  55%|█████▍    | 17/31 [00:09<00:08,  1.73it/s, loss=54.1, v_num=0, train_loss_step=57.80, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  58%|█████▊    | 18/31 [00:10<00:07,  1.73it/s, loss=54.1, v_num=0, train_loss_step=57.80, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  58%|█████▊    | 18/31 [00:10<00:07,  1.73it/s, loss=54, v_num=0, train_loss_step=51.20, val_loss=78.80, train_loss_epoch=54.10]  #015Epoch 10:  61%|██████▏   | 19/31 [00:11<00:06,  1.73it/s, loss=54, v_num=0, train_loss_step=51.20, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  61%|██████▏   | 19/31 [00:11<00:06,  1.73it/s, loss=54.6, v_num=0, train_loss_step=63.20, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  65%|██████▍   | 20/31 [00:11<00:06,  1.73it/s, loss=54.6, v_num=0, train_loss_step=63.20, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  65%|██████▍   | 20/31 [00:11<00:06,  1.73it/s, loss=54.4, v_num=0, train_loss_step=53.10, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  68%|██████▊   | 21/31 [00:12<00:05,  1.70it/s, loss=54.4, v_num=0, train_loss_step=53.10, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  68%|██████▊   | 21/31 [00:12<00:05,  1.70it/s, loss=53.3, v_num=0, train_loss_step=40.60, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  71%|███████   | 22/31 [00:12<00:05,  1.70it/s, loss=53.3, v_num=0, train_loss_step=40.60, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  71%|███████   | 22/31 [00:12<00:05,  1.70it/s, loss=52.5, v_num=0, train_loss_step=47.90, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  74%|███████▍  | 23/31 [00:13<00:04,  1.72it/s, loss=52.5, v_num=0, train_loss_step=47.90, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  74%|███████▍  | 23/31 [00:13<00:04,  1.72it/s, loss=52.7, v_num=0, train_loss_step=67.70, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  77%|███████▋  | 24/31 [00:13<00:04,  1.72it/s, loss=52.7, v_num=0, train_loss_step=67.70, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  77%|███████▋  | 24/31 [00:13<00:04,  1.72it/s, loss=52.7, v_num=0, train_loss_step=44.80, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  81%|████████  | 25/31 [00:14<00:03,  1.73it/s, loss=52.7, v_num=0, train_loss_step=44.80, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  81%|████████  | 25/31 [00:14<00:03,  1.73it/s, loss=53.7, v_num=0, train_loss_step=62.80, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  84%|████████▍ | 26/31 [00:14<00:02,  1.74it/s, loss=53.7, v_num=0, train_loss_step=62.80, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  84%|████████▍ | 26/31 [00:14<00:02,  1.74it/s, loss=54.3, v_num=0, train_loss_step=65.00, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  87%|████████▋ | 27/31 [00:15<00:02,  1.75it/s, loss=54.3, v_num=0, train_loss_step=65.00, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  87%|████████▋ | 27/31 [00:15<00:02,  1.75it/s, loss=54.6, v_num=0, train_loss_step=58.70, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  90%|█████████ | 28/31 [00:15<00:01,  1.76it/s, loss=54.6, v_num=0, train_loss_step=58.70, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  90%|█████████ | 28/31 [00:15<00:01,  1.76it/s, loss=54.6, v_num=0, train_loss_step=51.10, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  94%|█████████▎| 29/31 [00:16<00:01,  1.77it/s, loss=54.6, v_num=0, train_loss_step=51.10, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  94%|█████████▎| 29/31 [00:16<00:01,  1.77it/s, loss=55.6, v_num=0, train_loss_step=63.90, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  97%|█████████▋| 30/31 [00:16<00:00,  1.77it/s, loss=55.6, v_num=0, train_loss_step=63.90, val_loss=78.80, train_loss_epoch=54.10]#015Epoch 10:  97%|█████████▋| 30/31 [00:16<00:00,  1.77it/s, loss=55.3, v_num=0, train_loss_step=42.80, val_loss=78.80, train_loss_epoch=54.10]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 1/1 [00:00<00:00,  1.00it/s]#033[A#015Epoch 10: 100%|██████████| 31/31 [00:19<00:00,  1.63it/s, loss=55.3, v_num=0, train_loss_step=42.80, val_loss=76.40, train_loss_epoch=54.10]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015                                                         #033[A#015Epoch 10: 100%|██████████| 31/31 [00:20<00:00,  1.53it/s, loss=55.3, v_num=0, train_loss_step=42.80, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 10:   0%|          | 0/31 [00:00<?, ?it/s, loss=55.3, v_num=0, train_loss_step=42.80, val_loss=76.40, train_loss_epoch=54.40]         #015Epoch 11:   0%|          | 0/31 [00:00<?, ?it/s, loss=55.3, v_num=0, train_loss_step=42.80, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:   3%|▎         | 1/31 [00:01<00:34,  1.14s/it, loss=55.3, v_num=0, train_loss_step=42.80, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:   3%|▎         | 1/31 [00:01<00:34,  1.14s/it, loss=55.5, v_num=0, train_loss_step=63.30, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:   6%|▋         | 2/31 [00:01<00:28,  1.03it/s, loss=55.5, v_num=0, train_loss_step=63.30, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:   6%|▋         | 2/31 [00:01<00:28,  1.03it/s, loss=55.7, v_num=0, train_loss_step=52.60, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  10%|▉         | 3/31 [00:02<00:23,  1.21it/s, loss=55.7, v_num=0, train_loss_step=52.60, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  10%|▉         | 3/31 [00:02<00:23,  1.21it/s, loss=56.1, v_num=0, train_loss_step=66.60, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  13%|█▎        | 4/31 [00:03<00:20,  1.31it/s, loss=56.1, v_num=0, train_loss_step=66.60, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  13%|█▎        | 4/31 [00:03<00:20,  1.31it/s, loss=55.9, v_num=0, train_loss_step=53.00, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  16%|█▌        | 5/31 [00:03<00:18,  1.37it/s, loss=55.9, v_num=0, train_loss_step=53.00, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  16%|█▌        | 5/31 [00:03<00:18,  1.37it/s, loss=55.8, v_num=0, train_loss_step=54.30, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  19%|█▉        | 6/31 [00:04<00:17,  1.44it/s, loss=55.8, v_num=0, train_loss_step=54.30, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  19%|█▉        | 6/31 [00:04<00:17,  1.44it/s, loss=56, v_num=0, train_loss_step=59.00, val_loss=76.40, train_loss_epoch=54.40]  #015Epoch 11:  23%|██▎       | 7/31 [00:04<00:16,  1.50it/s, loss=56, v_num=0, train_loss_step=59.00, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  23%|██▎       | 7/31 [00:04<00:16,  1.50it/s, loss=56.2, v_num=0, train_loss_step=62.00, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  26%|██▌       | 8/31 [00:05<00:15,  1.53it/s, loss=56.2, v_num=0, train_loss_step=62.00, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  26%|██▌       | 8/31 [00:05<00:15,  1.53it/s, loss=56.5, v_num=0, train_loss_step=57.50, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  29%|██▉       | 9/31 [00:05<00:14,  1.55it/s, loss=56.5, v_num=0, train_loss_step=57.50, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  29%|██▉       | 9/31 [00:05<00:14,  1.55it/s, loss=56, v_num=0, train_loss_step=52.70, val_loss=76.40, train_loss_epoch=54.40]  #015Epoch 11:  32%|███▏      | 10/31 [00:06<00:13,  1.59it/s, loss=56, v_num=0, train_loss_step=52.70, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  32%|███▏      | 10/31 [00:06<00:13,  1.59it/s, loss=55.7, v_num=0, train_loss_step=46.50, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  35%|███▌      | 11/31 [00:07<00:13,  1.54it/s, loss=55.7, v_num=0, train_loss_step=46.50, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  35%|███▌      | 11/31 [00:07<00:13,  1.54it/s, loss=56.3, v_num=0, train_loss_step=53.30, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  39%|███▊      | 12/31 [00:07<00:12,  1.54it/s, loss=56.3, v_num=0, train_loss_step=53.30, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  39%|███▊      | 12/31 [00:07<00:12,  1.54it/s, loss=56.3, v_num=0, train_loss_step=47.80, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  42%|████▏     | 13/31 [00:08<00:11,  1.57it/s, loss=56.3, v_num=0, train_loss_step=47.80, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  42%|████▏     | 13/31 [00:08<00:11,  1.57it/s, loss=55, v_num=0, train_loss_step=41.80, val_loss=76.40, train_loss_epoch=54.40]  #015Epoch 11:  45%|████▌     | 14/31 [00:08<00:10,  1.58it/s, loss=55, v_num=0, train_loss_step=41.80, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  45%|████▌     | 14/31 [00:08<00:10,  1.58it/s, loss=56.5, v_num=0, train_loss_step=75.50, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  48%|████▊     | 15/31 [00:09<00:10,  1.58it/s, loss=56.5, v_num=0, train_loss_step=75.50, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  48%|████▊     | 15/31 [00:09<00:10,  1.58it/s, loss=55.9, v_num=0, train_loss_step=51.20, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  52%|█████▏    | 16/31 [00:10<00:09,  1.58it/s, loss=55.9, v_num=0, train_loss_step=51.20, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  52%|█████▏    | 16/31 [00:10<00:09,  1.58it/s, loss=55.2, v_num=0, train_loss_step=50.50, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  55%|█████▍    | 17/31 [00:10<00:08,  1.60it/s, loss=55.2, v_num=0, train_loss_step=50.50, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  55%|█████▍    | 17/31 [00:10<00:08,  1.60it/s, loss=54.9, v_num=0, train_loss_step=52.60, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  58%|█████▊    | 18/31 [00:11<00:08,  1.61it/s, loss=54.9, v_num=0, train_loss_step=52.60, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  58%|█████▊    | 18/31 [00:11<00:08,  1.61it/s, loss=54.5, v_num=0, train_loss_step=43.70, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  61%|██████▏   | 19/31 [00:11<00:07,  1.62it/s, loss=54.5, v_num=0, train_loss_step=43.70, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  61%|██████▏   | 19/31 [00:11<00:07,  1.62it/s, loss=53.6, v_num=0, train_loss_step=44.80, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  65%|██████▍   | 20/31 [00:12<00:06,  1.63it/s, loss=53.6, v_num=0, train_loss_step=44.80, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  65%|██████▍   | 20/31 [00:12<00:06,  1.63it/s, loss=53.5, v_num=0, train_loss_step=41.10, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  68%|██████▊   | 21/31 [00:13<00:06,  1.60it/s, loss=53.5, v_num=0, train_loss_step=41.10, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  68%|██████▊   | 21/31 [00:13<00:06,  1.60it/s, loss=52.6, v_num=0, train_loss_step=45.20, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  71%|███████   | 22/31 [00:13<00:05,  1.61it/s, loss=52.6, v_num=0, train_loss_step=45.20, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  71%|███████   | 22/31 [00:13<00:05,  1.61it/s, loss=53.2, v_num=0, train_loss_step=64.40, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  74%|███████▍  | 23/31 [00:14<00:04,  1.62it/s, loss=53.2, v_num=0, train_loss_step=64.40, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  74%|███████▍  | 23/31 [00:14<00:04,  1.62it/s, loss=52.3, v_num=0, train_loss_step=48.50, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  77%|███████▋  | 24/31 [00:14<00:04,  1.63it/s, loss=52.3, v_num=0, train_loss_step=48.50, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  77%|███████▋  | 24/31 [00:14<00:04,  1.63it/s, loss=52.1, v_num=0, train_loss_step=49.40, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  81%|████████  | 25/31 [00:15<00:03,  1.64it/s, loss=52.1, v_num=0, train_loss_step=49.40, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  81%|████████  | 25/31 [00:15<00:03,  1.64it/s, loss=51.8, v_num=0, train_loss_step=47.50, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  84%|████████▍ | 26/31 [00:15<00:03,  1.65it/s, loss=51.8, v_num=0, train_loss_step=47.50, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  84%|████████▍ | 26/31 [00:15<00:03,  1.65it/s, loss=50.6, v_num=0, train_loss_step=35.90, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  87%|████████▋ | 27/31 [00:16<00:02,  1.66it/s, loss=50.6, v_num=0, train_loss_step=35.90, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  87%|████████▋ | 27/31 [00:16<00:02,  1.66it/s, loss=50.4, v_num=0, train_loss_step=57.80, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  90%|█████████ | 28/31 [00:16<00:01,  1.67it/s, loss=50.4, v_num=0, train_loss_step=57.80, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  90%|█████████ | 28/31 [00:16<00:01,  1.67it/s, loss=50.8, v_num=0, train_loss_step=64.90, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  94%|█████████▎| 29/31 [00:17<00:01,  1.67it/s, loss=50.8, v_num=0, train_loss_step=64.90, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  94%|█████████▎| 29/31 [00:17<00:01,  1.67it/s, loss=50.5, v_num=0, train_loss_step=46.90, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  97%|█████████▋| 30/31 [00:17<00:00,  1.68it/s, loss=50.5, v_num=0, train_loss_step=46.90, val_loss=76.40, train_loss_epoch=54.40]#015Epoch 11:  97%|█████████▋| 30/31 [00:17<00:00,  1.68it/s, loss=50.5, v_num=0, train_loss_step=46.70, val_loss=76.40, train_loss_epoch=54.40]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]#033[A#015Epoch 11: 100%|██████████| 31/31 [00:20<00:00,  1.54it/s, loss=50.5, v_num=0, train_loss_step=46.70, val_loss=78.80, train_loss_epoch=54.40]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015                                                         #033[A#015Epoch 11: 100%|██████████| 31/31 [00:21<00:00,  1.47it/s, loss=50.5, v_num=0, train_loss_step=46.70, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 11:   0%|          | 0/31 [00:00<?, ?it/s, loss=50.5, v_num=0, train_loss_step=46.70, val_loss=78.80, train_loss_epoch=52.60]         #015Epoch 12:   0%|          | 0/31 [00:00<?, ?it/s, loss=50.5, v_num=0, train_loss_step=46.70, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:   3%|▎         | 1/31 [00:01<00:30,  1.03s/it, loss=50.5, v_num=0, train_loss_step=46.70, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:   3%|▎         | 1/31 [00:01<00:31,  1.03s/it, loss=50.4, v_num=0, train_loss_step=52.70, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:   6%|▋         | 2/31 [00:01<00:21,  1.32it/s, loss=50.4, v_num=0, train_loss_step=52.70, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:   6%|▋         | 2/31 [00:01<00:21,  1.32it/s, loss=50.4, v_num=0, train_loss_step=46.70, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  10%|▉         | 3/31 [00:02<00:18,  1.49it/s, loss=50.4, v_num=0, train_loss_step=46.70, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  10%|▉         | 3/31 [00:02<00:18,  1.49it/s, loss=52, v_num=0, train_loss_step=73.00, val_loss=78.80, train_loss_epoch=52.60]  #015Epoch 12:  13%|█▎        | 4/31 [00:02<00:17,  1.57it/s, loss=52, v_num=0, train_loss_step=73.00, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  13%|█▎        | 4/31 [00:02<00:17,  1.57it/s, loss=50.4, v_num=0, train_loss_step=43.80, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  16%|█▌        | 5/31 [00:03<00:15,  1.64it/s, loss=50.4, v_num=0, train_loss_step=43.80, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  16%|█▌        | 5/31 [00:03<00:15,  1.64it/s, loss=50.1, v_num=0, train_loss_step=46.40, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  19%|█▉        | 6/31 [00:03<00:15,  1.64it/s, loss=50.1, v_num=0, train_loss_step=46.40, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  19%|█▉        | 6/31 [00:03<00:15,  1.63it/s, loss=50.4, v_num=0, train_loss_step=55.30, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  23%|██▎       | 7/31 [00:04<00:14,  1.67it/s, loss=50.4, v_num=0, train_loss_step=55.30, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  23%|██▎       | 7/31 [00:04<00:14,  1.66it/s, loss=50.8, v_num=0, train_loss_step=61.20, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  26%|██▌       | 8/31 [00:04<00:13,  1.70it/s, loss=50.8, v_num=0, train_loss_step=61.20, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  26%|██▌       | 8/31 [00:04<00:13,  1.70it/s, loss=51.2, v_num=0, train_loss_step=51.60, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  29%|██▉       | 9/31 [00:05<00:12,  1.74it/s, loss=51.2, v_num=0, train_loss_step=51.60, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  29%|██▉       | 9/31 [00:05<00:12,  1.74it/s, loss=51.6, v_num=0, train_loss_step=52.40, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  32%|███▏      | 10/31 [00:05<00:11,  1.76it/s, loss=51.6, v_num=0, train_loss_step=52.40, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  32%|███▏      | 10/31 [00:05<00:11,  1.76it/s, loss=51.7, v_num=0, train_loss_step=43.10, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  35%|███▌      | 11/31 [00:06<00:12,  1.61it/s, loss=51.7, v_num=0, train_loss_step=43.10, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  35%|███▌      | 11/31 [00:06<00:12,  1.61it/s, loss=52.4, v_num=0, train_loss_step=59.80, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  39%|███▊      | 12/31 [00:07<00:11,  1.63it/s, loss=52.4, v_num=0, train_loss_step=59.80, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  39%|███▊      | 12/31 [00:07<00:11,  1.63it/s, loss=52, v_num=0, train_loss_step=56.90, val_loss=78.80, train_loss_epoch=52.60]  #015Epoch 12:  42%|████▏     | 13/31 [00:07<00:10,  1.65it/s, loss=52, v_num=0, train_loss_step=56.90, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  42%|████▏     | 13/31 [00:07<00:10,  1.65it/s, loss=51.9, v_num=0, train_loss_step=46.40, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  45%|████▌     | 14/31 [00:08<00:10,  1.67it/s, loss=51.9, v_num=0, train_loss_step=46.40, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  45%|████▌     | 14/31 [00:08<00:10,  1.67it/s, loss=52, v_num=0, train_loss_step=50.70, val_loss=78.80, train_loss_epoch=52.60]  #015Epoch 12:  48%|████▊     | 15/31 [00:08<00:09,  1.68it/s, loss=52, v_num=0, train_loss_step=50.70, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  48%|████▊     | 15/31 [00:08<00:09,  1.68it/s, loss=52.3, v_num=0, train_loss_step=53.80, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  52%|█████▏    | 16/31 [00:09<00:08,  1.70it/s, loss=52.3, v_num=0, train_loss_step=53.80, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  52%|█████▏    | 16/31 [00:09<00:08,  1.70it/s, loss=53.5, v_num=0, train_loss_step=59.40, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  55%|█████▍    | 17/31 [00:09<00:08,  1.71it/s, loss=53.5, v_num=0, train_loss_step=59.40, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  55%|█████▍    | 17/31 [00:09<00:08,  1.71it/s, loss=52.5, v_num=0, train_loss_step=37.70, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  58%|█████▊    | 18/31 [00:10<00:07,  1.71it/s, loss=52.5, v_num=0, train_loss_step=37.70, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  58%|█████▊    | 18/31 [00:10<00:07,  1.71it/s, loss=52.3, v_num=0, train_loss_step=61.80, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  61%|██████▏   | 19/31 [00:11<00:06,  1.72it/s, loss=52.3, v_num=0, train_loss_step=61.80, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  61%|██████▏   | 19/31 [00:11<00:06,  1.72it/s, loss=52.7, v_num=0, train_loss_step=55.10, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  65%|██████▍   | 20/31 [00:11<00:06,  1.73it/s, loss=52.7, v_num=0, train_loss_step=55.10, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  65%|██████▍   | 20/31 [00:11<00:06,  1.73it/s, loss=52.4, v_num=0, train_loss_step=40.30, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  68%|██████▊   | 21/31 [00:12<00:05,  1.69it/s, loss=52.4, v_num=0, train_loss_step=40.30, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  68%|██████▊   | 21/31 [00:12<00:05,  1.69it/s, loss=52.3, v_num=0, train_loss_step=50.50, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  71%|███████   | 22/31 [00:12<00:05,  1.71it/s, loss=52.3, v_num=0, train_loss_step=50.50, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  71%|███████   | 22/31 [00:12<00:05,  1.71it/s, loss=52.3, v_num=0, train_loss_step=45.30, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  74%|███████▍  | 23/31 [00:13<00:04,  1.72it/s, loss=52.3, v_num=0, train_loss_step=45.30, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  74%|███████▍  | 23/31 [00:13<00:04,  1.72it/s, loss=51.5, v_num=0, train_loss_step=58.40, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  77%|███████▋  | 24/31 [00:13<00:04,  1.73it/s, loss=51.5, v_num=0, train_loss_step=58.40, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  77%|███████▋  | 24/31 [00:13<00:04,  1.73it/s, loss=51.3, v_num=0, train_loss_step=40.30, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  81%|████████  | 25/31 [00:14<00:03,  1.73it/s, loss=51.3, v_num=0, train_loss_step=40.30, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  81%|████████  | 25/31 [00:14<00:03,  1.73it/s, loss=51, v_num=0, train_loss_step=40.20, val_loss=78.80, train_loss_epoch=52.60]  #015Epoch 12:  84%|████████▍ | 26/31 [00:14<00:02,  1.74it/s, loss=51, v_num=0, train_loss_step=40.20, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  84%|████████▍ | 26/31 [00:14<00:02,  1.74it/s, loss=50.2, v_num=0, train_loss_step=39.00, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  87%|████████▋ | 27/31 [00:15<00:02,  1.75it/s, loss=50.2, v_num=0, train_loss_step=39.00, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  87%|████████▋ | 27/31 [00:15<00:02,  1.75it/s, loss=49.7, v_num=0, train_loss_step=50.10, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  90%|█████████ | 28/31 [00:15<00:01,  1.76it/s, loss=49.7, v_num=0, train_loss_step=50.10, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  90%|█████████ | 28/31 [00:15<00:01,  1.76it/s, loss=49.5, v_num=0, train_loss_step=48.90, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  94%|█████████▎| 29/31 [00:16<00:01,  1.76it/s, loss=49.5, v_num=0, train_loss_step=48.90, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  94%|█████████▎| 29/31 [00:16<00:01,  1.76it/s, loss=49.7, v_num=0, train_loss_step=55.60, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  97%|█████████▋| 30/31 [00:16<00:00,  1.77it/s, loss=49.7, v_num=0, train_loss_step=55.60, val_loss=78.80, train_loss_epoch=52.60]#015Epoch 12:  97%|█████████▋| 30/31 [00:16<00:00,  1.77it/s, loss=49.6, v_num=0, train_loss_step=42.20, val_loss=78.80, train_loss_epoch=52.60]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 1/1 [00:00<00:00,  1.04it/s]#033[A#015Epoch 12: 100%|██████████| 31/31 [00:19<00:00,  1.62it/s, loss=49.6, v_num=0, train_loss_step=42.20, val_loss=74.50, train_loss_epoch=52.60]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015                                                         #033[A#015Epoch 12: 100%|██████████| 31/31 [00:20<00:00,  1.53it/s, loss=49.6, v_num=0, train_loss_step=42.20, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 12:   0%|          | 0/31 [00:00<?, ?it/s, loss=49.6, v_num=0, train_loss_step=42.20, val_loss=74.50, train_loss_epoch=50.60]         #015Epoch 13:   0%|          | 0/31 [00:00<?, ?it/s, loss=49.6, v_num=0, train_loss_step=42.20, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:   3%|▎         | 1/31 [00:01<00:33,  1.11s/it, loss=49.6, v_num=0, train_loss_step=42.20, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:   3%|▎         | 1/31 [00:01<00:33,  1.11s/it, loss=49.2, v_num=0, train_loss_step=51.30, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:   6%|▋         | 2/31 [00:01<00:24,  1.17it/s, loss=49.2, v_num=0, train_loss_step=51.30, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:   6%|▋         | 2/31 [00:01<00:24,  1.17it/s, loss=48.8, v_num=0, train_loss_step=49.40, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  10%|▉         | 3/31 [00:02<00:20,  1.36it/s, loss=48.8, v_num=0, train_loss_step=49.40, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  10%|▉         | 3/31 [00:02<00:20,  1.36it/s, loss=49.8, v_num=0, train_loss_step=65.00, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  13%|█▎        | 4/31 [00:02<00:18,  1.49it/s, loss=49.8, v_num=0, train_loss_step=65.00, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  13%|█▎        | 4/31 [00:02<00:18,  1.49it/s, loss=49.4, v_num=0, train_loss_step=43.20, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  16%|█▌        | 5/31 [00:03<00:16,  1.56it/s, loss=49.4, v_num=0, train_loss_step=43.20, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  16%|█▌        | 5/31 [00:03<00:16,  1.56it/s, loss=49.4, v_num=0, train_loss_step=53.80, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  19%|█▉        | 6/31 [00:03<00:15,  1.58it/s, loss=49.4, v_num=0, train_loss_step=53.80, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  19%|█▉        | 6/31 [00:03<00:15,  1.58it/s, loss=49, v_num=0, train_loss_step=51.50, val_loss=74.50, train_loss_epoch=50.60]  #015Epoch 13:  23%|██▎       | 7/31 [00:04<00:14,  1.62it/s, loss=49, v_num=0, train_loss_step=51.50, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  23%|██▎       | 7/31 [00:04<00:14,  1.62it/s, loss=49.4, v_num=0, train_loss_step=45.20, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  26%|██▌       | 8/31 [00:04<00:13,  1.65it/s, loss=49.4, v_num=0, train_loss_step=45.20, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  26%|██▌       | 8/31 [00:04<00:13,  1.65it/s, loss=49.2, v_num=0, train_loss_step=58.80, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  29%|██▉       | 9/31 [00:05<00:12,  1.69it/s, loss=49.2, v_num=0, train_loss_step=58.80, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  29%|██▉       | 9/31 [00:05<00:13,  1.69it/s, loss=49.5, v_num=0, train_loss_step=60.10, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  32%|███▏      | 10/31 [00:05<00:12,  1.72it/s, loss=49.5, v_num=0, train_loss_step=60.10, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  32%|███▏      | 10/31 [00:05<00:12,  1.72it/s, loss=50.3, v_num=0, train_loss_step=57.40, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  35%|███▌      | 11/31 [00:06<00:12,  1.65it/s, loss=50.3, v_num=0, train_loss_step=57.40, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  35%|███▌      | 11/31 [00:06<00:12,  1.65it/s, loss=51.1, v_num=0, train_loss_step=66.40, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  39%|███▊      | 12/31 [00:07<00:11,  1.61it/s, loss=51.1, v_num=0, train_loss_step=66.40, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  39%|███▊      | 12/31 [00:07<00:11,  1.61it/s, loss=51.3, v_num=0, train_loss_step=48.40, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  42%|████▏     | 13/31 [00:07<00:11,  1.63it/s, loss=51.3, v_num=0, train_loss_step=48.40, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  42%|████▏     | 13/31 [00:07<00:11,  1.63it/s, loss=51.1, v_num=0, train_loss_step=54.90, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  45%|████▌     | 14/31 [00:08<00:10,  1.65it/s, loss=51.1, v_num=0, train_loss_step=54.90, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  45%|████▌     | 14/31 [00:08<00:10,  1.65it/s, loss=51.1, v_num=0, train_loss_step=41.30, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  48%|████▊     | 15/31 [00:08<00:09,  1.67it/s, loss=51.1, v_num=0, train_loss_step=41.30, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  48%|████▊     | 15/31 [00:08<00:09,  1.67it/s, loss=51.9, v_num=0, train_loss_step=54.90, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  52%|█████▏    | 16/31 [00:09<00:08,  1.69it/s, loss=51.9, v_num=0, train_loss_step=54.90, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  52%|█████▏    | 16/31 [00:09<00:08,  1.69it/s, loss=52.3, v_num=0, train_loss_step=47.10, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  55%|█████▍    | 17/31 [00:09<00:08,  1.71it/s, loss=52.3, v_num=0, train_loss_step=47.10, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  55%|█████▍    | 17/31 [00:09<00:08,  1.71it/s, loss=52.7, v_num=0, train_loss_step=58.60, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  58%|█████▊    | 18/31 [00:10<00:07,  1.72it/s, loss=52.7, v_num=0, train_loss_step=58.60, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  58%|█████▊    | 18/31 [00:10<00:07,  1.72it/s, loss=53.6, v_num=0, train_loss_step=67.80, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  61%|██████▏   | 19/31 [00:10<00:06,  1.73it/s, loss=53.6, v_num=0, train_loss_step=67.80, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  61%|██████▏   | 19/31 [00:10<00:06,  1.73it/s, loss=53.3, v_num=0, train_loss_step=49.10, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  65%|██████▍   | 20/31 [00:11<00:06,  1.74it/s, loss=53.3, v_num=0, train_loss_step=49.10, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  65%|██████▍   | 20/31 [00:11<00:06,  1.74it/s, loss=53.4, v_num=0, train_loss_step=44.20, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  68%|██████▊   | 21/31 [00:12<00:05,  1.71it/s, loss=53.4, v_num=0, train_loss_step=44.20, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  68%|██████▊   | 21/31 [00:12<00:05,  1.71it/s, loss=53.5, v_num=0, train_loss_step=52.80, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  71%|███████   | 22/31 [00:12<00:05,  1.71it/s, loss=53.5, v_num=0, train_loss_step=52.80, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  71%|███████   | 22/31 [00:12<00:05,  1.71it/s, loss=53, v_num=0, train_loss_step=39.30, val_loss=74.50, train_loss_epoch=50.60]  #015Epoch 13:  74%|███████▍  | 23/31 [00:13<00:04,  1.72it/s, loss=53, v_num=0, train_loss_step=39.30, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  74%|███████▍  | 23/31 [00:13<00:04,  1.72it/s, loss=52.2, v_num=0, train_loss_step=48.10, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  77%|███████▋  | 24/31 [00:13<00:04,  1.73it/s, loss=52.2, v_num=0, train_loss_step=48.10, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  77%|███████▋  | 24/31 [00:13<00:04,  1.73it/s, loss=52.5, v_num=0, train_loss_step=49.60, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  81%|████████  | 25/31 [00:14<00:03,  1.74it/s, loss=52.5, v_num=0, train_loss_step=49.60, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  81%|████████  | 25/31 [00:14<00:03,  1.74it/s, loss=52.5, v_num=0, train_loss_step=53.50, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  84%|████████▍ | 26/31 [00:14<00:02,  1.75it/s, loss=52.5, v_num=0, train_loss_step=53.50, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  84%|████████▍ | 26/31 [00:14<00:02,  1.75it/s, loss=52.5, v_num=0, train_loss_step=52.70, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  87%|████████▋ | 27/31 [00:15<00:02,  1.75it/s, loss=52.5, v_num=0, train_loss_step=52.70, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  87%|████████▋ | 27/31 [00:15<00:02,  1.75it/s, loss=53.1, v_num=0, train_loss_step=55.90, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  90%|█████████ | 28/31 [00:15<00:01,  1.76it/s, loss=53.1, v_num=0, train_loss_step=55.90, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  90%|█████████ | 28/31 [00:15<00:01,  1.76it/s, loss=52.7, v_num=0, train_loss_step=52.50, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  94%|█████████▎| 29/31 [00:16<00:01,  1.77it/s, loss=52.7, v_num=0, train_loss_step=52.50, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  94%|█████████▎| 29/31 [00:16<00:01,  1.77it/s, loss=51.9, v_num=0, train_loss_step=43.40, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  97%|█████████▋| 30/31 [00:16<00:00,  1.78it/s, loss=51.9, v_num=0, train_loss_step=43.40, val_loss=74.50, train_loss_epoch=50.60]#015Epoch 13:  97%|█████████▋| 30/31 [00:16<00:00,  1.78it/s, loss=51.9, v_num=0, train_loss_step=57.70, val_loss=74.50, train_loss_epoch=50.60]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 1/1 [00:00<00:00,  1.04it/s]#033[A#015Epoch 13: 100%|██████████| 31/31 [00:19<00:00,  1.63it/s, loss=51.9, v_num=0, train_loss_step=57.70, val_loss=77.90, train_loss_epoch=50.60]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015                                                         #033[A#015Epoch 13: 100%|██████████| 31/31 [00:20<00:00,  1.54it/s, loss=51.9, v_num=0, train_loss_step=57.70, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 13:   0%|          | 0/31 [00:00<?, ?it/s, loss=51.9, v_num=0, train_loss_step=57.70, val_loss=77.90, train_loss_epoch=52.50]         #015Epoch 14:   0%|          | 0/31 [00:00<?, ?it/s, loss=51.9, v_num=0, train_loss_step=57.70, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:   3%|▎         | 1/31 [00:01<00:33,  1.11s/it, loss=51.9, v_num=0, train_loss_step=57.70, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:   3%|▎         | 1/31 [00:01<00:33,  1.11s/it, loss=51.6, v_num=0, train_loss_step=60.10, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:   6%|▋         | 2/31 [00:01<00:23,  1.21it/s, loss=51.6, v_num=0, train_loss_step=60.10, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:   6%|▋         | 2/31 [00:01<00:23,  1.21it/s, loss=51.5, v_num=0, train_loss_step=46.80, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  10%|▉         | 3/31 [00:02<00:19,  1.41it/s, loss=51.5, v_num=0, train_loss_step=46.80, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  10%|▉         | 3/31 [00:02<00:19,  1.41it/s, loss=51.8, v_num=0, train_loss_step=60.50, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  13%|█▎        | 4/31 [00:02<00:17,  1.52it/s, loss=51.8, v_num=0, train_loss_step=60.50, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  13%|█▎        | 4/31 [00:02<00:17,  1.52it/s, loss=52, v_num=0, train_loss_step=44.80, val_loss=77.90, train_loss_epoch=52.50]  #015Epoch 14:  16%|█▌        | 5/31 [00:03<00:16,  1.54it/s, loss=52, v_num=0, train_loss_step=44.80, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  16%|█▌        | 5/31 [00:03<00:16,  1.54it/s, loss=51.9, v_num=0, train_loss_step=53.00, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  19%|█▉        | 6/31 [00:03<00:15,  1.57it/s, loss=51.9, v_num=0, train_loss_step=53.00, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  19%|█▉        | 6/31 [00:03<00:15,  1.57it/s, loss=51.7, v_num=0, train_loss_step=42.90, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  23%|██▎       | 7/31 [00:04<00:14,  1.62it/s, loss=51.7, v_num=0, train_loss_step=42.90, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  23%|██▎       | 7/31 [00:04<00:14,  1.62it/s, loss=51.5, v_num=0, train_loss_step=55.60, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  26%|██▌       | 8/31 [00:04<00:14,  1.64it/s, loss=51.5, v_num=0, train_loss_step=55.60, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  26%|██▌       | 8/31 [00:04<00:14,  1.64it/s, loss=50.9, v_num=0, train_loss_step=54.60, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  29%|██▉       | 9/31 [00:05<00:13,  1.64it/s, loss=50.9, v_num=0, train_loss_step=54.60, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  29%|██▉       | 9/31 [00:05<00:13,  1.64it/s, loss=50.8, v_num=0, train_loss_step=48.80, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  32%|███▏      | 10/31 [00:06<00:12,  1.65it/s, loss=50.8, v_num=0, train_loss_step=48.80, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  32%|███▏      | 10/31 [00:06<00:12,  1.65it/s, loss=51.2, v_num=0, train_loss_step=50.60, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  35%|███▌      | 11/31 [00:07<00:12,  1.56it/s, loss=51.2, v_num=0, train_loss_step=50.60, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  35%|███▌      | 11/31 [00:07<00:12,  1.56it/s, loss=50.7, v_num=0, train_loss_step=42.70, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  39%|███▊      | 12/31 [00:07<00:12,  1.56it/s, loss=50.7, v_num=0, train_loss_step=42.70, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  39%|███▊      | 12/31 [00:07<00:12,  1.56it/s, loss=51.5, v_num=0, train_loss_step=55.80, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  42%|████▏     | 13/31 [00:08<00:11,  1.56it/s, loss=51.5, v_num=0, train_loss_step=55.80, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  42%|████▏     | 13/31 [00:08<00:11,  1.56it/s, loss=51.6, v_num=0, train_loss_step=49.60, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  45%|████▌     | 14/31 [00:08<00:10,  1.58it/s, loss=51.6, v_num=0, train_loss_step=49.60, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  45%|████▌     | 14/31 [00:08<00:10,  1.58it/s, loss=52.1, v_num=0, train_loss_step=59.50, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  48%|████▊     | 15/31 [00:09<00:10,  1.60it/s, loss=52.1, v_num=0, train_loss_step=59.50, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  48%|████▊     | 15/31 [00:09<00:10,  1.60it/s, loss=51.9, v_num=0, train_loss_step=50.90, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  52%|█████▏    | 16/31 [00:09<00:09,  1.62it/s, loss=51.9, v_num=0, train_loss_step=50.90, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  52%|█████▏    | 16/31 [00:09<00:09,  1.62it/s, loss=50.9, v_num=0, train_loss_step=32.40, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  55%|█████▍    | 17/31 [00:10<00:08,  1.64it/s, loss=50.9, v_num=0, train_loss_step=32.40, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  55%|█████▍    | 17/31 [00:10<00:08,  1.64it/s, loss=49.8, v_num=0, train_loss_step=34.10, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  58%|█████▊    | 18/31 [00:10<00:07,  1.65it/s, loss=49.8, v_num=0, train_loss_step=34.10, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  58%|█████▊    | 18/31 [00:10<00:07,  1.65it/s, loss=49.9, v_num=0, train_loss_step=55.20, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  61%|██████▏   | 19/31 [00:11<00:07,  1.67it/s, loss=49.9, v_num=0, train_loss_step=55.20, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  61%|██████▏   | 19/31 [00:11<00:07,  1.67it/s, loss=50.1, v_num=0, train_loss_step=47.10, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  65%|██████▍   | 20/31 [00:11<00:06,  1.68it/s, loss=50.1, v_num=0, train_loss_step=47.10, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  65%|██████▍   | 20/31 [00:11<00:06,  1.68it/s, loss=49.5, v_num=0, train_loss_step=45.40, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  68%|██████▊   | 21/31 [00:12<00:06,  1.62it/s, loss=49.5, v_num=0, train_loss_step=45.40, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  68%|██████▊   | 21/31 [00:12<00:06,  1.62it/s, loss=48.9, v_num=0, train_loss_step=47.40, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  71%|███████   | 22/31 [00:13<00:05,  1.64it/s, loss=48.9, v_num=0, train_loss_step=47.40, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  71%|███████   | 22/31 [00:13<00:05,  1.64it/s, loss=48.5, v_num=0, train_loss_step=38.50, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  74%|███████▍  | 23/31 [00:13<00:04,  1.64it/s, loss=48.5, v_num=0, train_loss_step=38.50, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  74%|███████▍  | 23/31 [00:13<00:04,  1.64it/s, loss=47.9, v_num=0, train_loss_step=49.60, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  77%|███████▋  | 24/31 [00:14<00:04,  1.65it/s, loss=47.9, v_num=0, train_loss_step=49.60, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  77%|███████▋  | 24/31 [00:14<00:04,  1.65it/s, loss=48.4, v_num=0, train_loss_step=53.90, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  81%|████████  | 25/31 [00:15<00:03,  1.66it/s, loss=48.4, v_num=0, train_loss_step=53.90, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  81%|████████  | 25/31 [00:15<00:03,  1.66it/s, loss=49.2, v_num=0, train_loss_step=69.00, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  84%|████████▍ | 26/31 [00:15<00:03,  1.67it/s, loss=49.2, v_num=0, train_loss_step=69.00, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  84%|████████▍ | 26/31 [00:15<00:03,  1.67it/s, loss=49.1, v_num=0, train_loss_step=42.10, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  87%|████████▋ | 27/31 [00:16<00:02,  1.68it/s, loss=49.1, v_num=0, train_loss_step=42.10, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  87%|████████▋ | 27/31 [00:16<00:02,  1.68it/s, loss=49, v_num=0, train_loss_step=53.50, val_loss=77.90, train_loss_epoch=52.50]  #015Epoch 14:  90%|█████████ | 28/31 [00:16<00:01,  1.69it/s, loss=49, v_num=0, train_loss_step=53.50, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  90%|█████████ | 28/31 [00:16<00:01,  1.69it/s, loss=48.6, v_num=0, train_loss_step=45.90, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  94%|█████████▎| 29/31 [00:17<00:01,  1.70it/s, loss=48.6, v_num=0, train_loss_step=45.90, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  94%|█████████▎| 29/31 [00:17<00:01,  1.70it/s, loss=49.5, v_num=0, train_loss_step=66.40, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  97%|█████████▋| 30/31 [00:17<00:00,  1.70it/s, loss=49.5, v_num=0, train_loss_step=66.40, val_loss=77.90, train_loss_epoch=52.50]#015Epoch 14:  97%|█████████▋| 30/31 [00:17<00:00,  1.70it/s, loss=49.1, v_num=0, train_loss_step=43.70, val_loss=77.90, train_loss_epoch=52.50]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 1/1 [00:00<00:00,  1.00it/s]#033[A#015Epoch 14: 100%|██████████| 31/31 [00:19<00:00,  1.57it/s, loss=49.1, v_num=0, train_loss_step=43.70, val_loss=79.40, train_loss_epoch=52.50]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015                                                         #033[A#015Epoch 14: 100%|██████████| 31/31 [00:20<00:00,  1.48it/s, loss=49.1, v_num=0, train_loss_step=43.70, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 14:   0%|          | 0/31 [00:00<?, ?it/s, loss=49.1, v_num=0, train_loss_step=43.70, val_loss=79.40, train_loss_epoch=50.00]         #015Epoch 15:   0%|          | 0/31 [00:00<?, ?it/s, loss=49.1, v_num=0, train_loss_step=43.70, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:   3%|▎         | 1/31 [00:01<00:34,  1.14s/it, loss=49.1, v_num=0, train_loss_step=43.70, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:   3%|▎         | 1/31 [00:01<00:34,  1.14s/it, loss=49.5, v_num=0, train_loss_step=49.60, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:   6%|▋         | 2/31 [00:01<00:23,  1.22it/s, loss=49.5, v_num=0, train_loss_step=49.60, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:   6%|▋         | 2/31 [00:01<00:23,  1.22it/s, loss=49.1, v_num=0, train_loss_step=47.40, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  10%|▉         | 3/31 [00:02<00:20,  1.37it/s, loss=49.1, v_num=0, train_loss_step=47.40, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  10%|▉         | 3/31 [00:02<00:20,  1.37it/s, loss=48.6, v_num=0, train_loss_step=40.00, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  13%|█▎        | 4/31 [00:02<00:18,  1.47it/s, loss=48.6, v_num=0, train_loss_step=40.00, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  13%|█▎        | 4/31 [00:02<00:18,  1.47it/s, loss=48.5, v_num=0, train_loss_step=58.60, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  16%|█▌        | 5/31 [00:03<00:16,  1.54it/s, loss=48.5, v_num=0, train_loss_step=58.60, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  16%|█▌        | 5/31 [00:03<00:16,  1.54it/s, loss=49.4, v_num=0, train_loss_step=69.10, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  19%|█▉        | 6/31 [00:03<00:15,  1.60it/s, loss=49.4, v_num=0, train_loss_step=69.10, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  19%|█▉        | 6/31 [00:03<00:15,  1.60it/s, loss=49.8, v_num=0, train_loss_step=39.80, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  23%|██▎       | 7/31 [00:04<00:14,  1.65it/s, loss=49.8, v_num=0, train_loss_step=39.80, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  23%|██▎       | 7/31 [00:04<00:14,  1.65it/s, loss=51, v_num=0, train_loss_step=57.70, val_loss=79.40, train_loss_epoch=50.00]  #015Epoch 15:  26%|██▌       | 8/31 [00:04<00:13,  1.69it/s, loss=51, v_num=0, train_loss_step=57.70, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  26%|██▌       | 8/31 [00:04<00:13,  1.69it/s, loss=51.5, v_num=0, train_loss_step=65.60, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  29%|██▉       | 9/31 [00:05<00:12,  1.73it/s, loss=51.5, v_num=0, train_loss_step=65.60, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  29%|██▉       | 9/31 [00:05<00:12,  1.73it/s, loss=51.5, v_num=0, train_loss_step=46.40, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  32%|███▏      | 10/31 [00:05<00:11,  1.76it/s, loss=51.5, v_num=0, train_loss_step=46.40, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  32%|███▏      | 10/31 [00:05<00:11,  1.76it/s, loss=51.9, v_num=0, train_loss_step=53.50, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  35%|███▌      | 11/31 [00:06<00:11,  1.70it/s, loss=51.9, v_num=0, train_loss_step=53.50, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  35%|███▌      | 11/31 [00:06<00:11,  1.70it/s, loss=51.4, v_num=0, train_loss_step=37.30, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  39%|███▊      | 12/31 [00:06<00:11,  1.72it/s, loss=51.4, v_num=0, train_loss_step=37.30, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  39%|███▊      | 12/31 [00:06<00:11,  1.72it/s, loss=51.6, v_num=0, train_loss_step=43.30, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  42%|████▏     | 13/31 [00:07<00:10,  1.73it/s, loss=51.6, v_num=0, train_loss_step=43.30, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  42%|████▏     | 13/31 [00:07<00:10,  1.73it/s, loss=51.8, v_num=0, train_loss_step=53.50, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  45%|████▌     | 14/31 [00:08<00:09,  1.74it/s, loss=51.8, v_num=0, train_loss_step=53.50, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  45%|████▌     | 14/31 [00:08<00:09,  1.74it/s, loss=51.7, v_num=0, train_loss_step=51.30, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  48%|████▊     | 15/31 [00:08<00:09,  1.76it/s, loss=51.7, v_num=0, train_loss_step=51.30, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  48%|████▊     | 15/31 [00:08<00:09,  1.76it/s, loss=50.4, v_num=0, train_loss_step=42.50, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  52%|█████▏    | 16/31 [00:09<00:08,  1.77it/s, loss=50.4, v_num=0, train_loss_step=42.50, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  52%|█████▏    | 16/31 [00:09<00:08,  1.77it/s, loss=50.6, v_num=0, train_loss_step=46.70, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  55%|█████▍    | 17/31 [00:09<00:07,  1.78it/s, loss=50.6, v_num=0, train_loss_step=46.70, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  55%|█████▍    | 17/31 [00:09<00:07,  1.78it/s, loss=50.5, v_num=0, train_loss_step=51.50, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  58%|█████▊    | 18/31 [00:10<00:07,  1.79it/s, loss=50.5, v_num=0, train_loss_step=51.50, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  58%|█████▊    | 18/31 [00:10<00:07,  1.79it/s, loss=50.6, v_num=0, train_loss_step=48.60, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  61%|██████▏   | 19/31 [00:10<00:06,  1.80it/s, loss=50.6, v_num=0, train_loss_step=48.60, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  61%|██████▏   | 19/31 [00:10<00:06,  1.80it/s, loss=49.5, v_num=0, train_loss_step=43.10, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  65%|██████▍   | 20/31 [00:11<00:06,  1.81it/s, loss=49.5, v_num=0, train_loss_step=43.10, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  65%|██████▍   | 20/31 [00:11<00:06,  1.81it/s, loss=50.1, v_num=0, train_loss_step=56.50, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  68%|██████▊   | 21/31 [00:11<00:05,  1.77it/s, loss=50.1, v_num=0, train_loss_step=56.50, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  68%|██████▊   | 21/31 [00:11<00:05,  1.76it/s, loss=50.5, v_num=0, train_loss_step=58.00, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  71%|███████   | 22/31 [00:12<00:05,  1.75it/s, loss=50.5, v_num=0, train_loss_step=58.00, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  71%|███████   | 22/31 [00:12<00:05,  1.75it/s, loss=50.4, v_num=0, train_loss_step=45.70, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  74%|███████▍  | 23/31 [00:13<00:04,  1.76it/s, loss=50.4, v_num=0, train_loss_step=45.70, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  74%|███████▍  | 23/31 [00:13<00:04,  1.76it/s, loss=51.1, v_num=0, train_loss_step=53.50, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  77%|███████▋  | 24/31 [00:13<00:03,  1.76it/s, loss=51.1, v_num=0, train_loss_step=53.50, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  77%|███████▋  | 24/31 [00:13<00:03,  1.76it/s, loss=51, v_num=0, train_loss_step=55.80, val_loss=79.40, train_loss_epoch=50.00]  #015Epoch 15:  81%|████████  | 25/31 [00:14<00:03,  1.76it/s, loss=51, v_num=0, train_loss_step=55.80, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  81%|████████  | 25/31 [00:14<00:03,  1.76it/s, loss=50, v_num=0, train_loss_step=49.80, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  84%|████████▍ | 26/31 [00:14<00:02,  1.76it/s, loss=50, v_num=0, train_loss_step=49.80, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  84%|████████▍ | 26/31 [00:14<00:02,  1.76it/s, loss=50.5, v_num=0, train_loss_step=49.70, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  87%|████████▋ | 27/31 [00:15<00:02,  1.77it/s, loss=50.5, v_num=0, train_loss_step=49.70, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  87%|████████▋ | 27/31 [00:15<00:02,  1.77it/s, loss=50.4, v_num=0, train_loss_step=54.70, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  90%|█████████ | 28/31 [00:15<00:01,  1.77it/s, loss=50.4, v_num=0, train_loss_step=54.70, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  90%|█████████ | 28/31 [00:15<00:01,  1.77it/s, loss=49.4, v_num=0, train_loss_step=46.20, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  94%|█████████▎| 29/31 [00:16<00:01,  1.77it/s, loss=49.4, v_num=0, train_loss_step=46.20, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  94%|█████████▎| 29/31 [00:16<00:01,  1.77it/s, loss=49.4, v_num=0, train_loss_step=47.40, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  97%|█████████▋| 30/31 [00:16<00:00,  1.77it/s, loss=49.4, v_num=0, train_loss_step=47.40, val_loss=79.40, train_loss_epoch=50.00]#015Epoch 15:  97%|█████████▋| 30/31 [00:16<00:00,  1.77it/s, loss=49.2, v_num=0, train_loss_step=49.20, val_loss=79.40, train_loss_epoch=50.00]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]#033[A#015Epoch 15: 100%|██████████| 31/31 [00:18<00:00,  1.63it/s, loss=49.2, v_num=0, train_loss_step=49.20, val_loss=78.70, train_loss_epoch=50.00]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015                                                         #033[A#015Epoch 15: 100%|██████████| 31/31 [00:20<00:00,  1.54it/s, loss=49.2, v_num=0, train_loss_step=49.20, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 15:   0%|          | 0/31 [00:00<?, ?it/s, loss=49.2, v_num=0, train_loss_step=49.20, val_loss=78.70, train_loss_epoch=50.40]         #015Epoch 16:   0%|          | 0/31 [00:00<?, ?it/s, loss=49.2, v_num=0, train_loss_step=49.20, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:   3%|▎         | 1/31 [00:01<00:32,  1.08s/it, loss=49.2, v_num=0, train_loss_step=49.20, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:   3%|▎         | 1/31 [00:01<00:32,  1.08s/it, loss=49.7, v_num=0, train_loss_step=47.00, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:   6%|▋         | 2/31 [00:01<00:23,  1.25it/s, loss=49.7, v_num=0, train_loss_step=47.00, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:   6%|▋         | 2/31 [00:01<00:23,  1.25it/s, loss=50.2, v_num=0, train_loss_step=52.90, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  10%|▉         | 3/31 [00:02<00:19,  1.43it/s, loss=50.2, v_num=0, train_loss_step=52.90, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  10%|▉         | 3/31 [00:02<00:19,  1.43it/s, loss=50.3, v_num=0, train_loss_step=55.40, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  13%|█▎        | 4/31 [00:02<00:17,  1.55it/s, loss=50.3, v_num=0, train_loss_step=55.40, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  13%|█▎        | 4/31 [00:02<00:17,  1.55it/s, loss=50.1, v_num=0, train_loss_step=47.00, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  16%|█▌        | 5/31 [00:03<00:16,  1.61it/s, loss=50.1, v_num=0, train_loss_step=47.00, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  16%|█▌        | 5/31 [00:03<00:16,  1.61it/s, loss=50.9, v_num=0, train_loss_step=59.40, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  19%|█▉        | 6/31 [00:03<00:15,  1.63it/s, loss=50.9, v_num=0, train_loss_step=59.40, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  19%|█▉        | 6/31 [00:03<00:15,  1.63it/s, loss=50.7, v_num=0, train_loss_step=43.10, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  23%|██▎       | 7/31 [00:04<00:14,  1.67it/s, loss=50.7, v_num=0, train_loss_step=43.10, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  23%|██▎       | 7/31 [00:04<00:14,  1.67it/s, loss=50.1, v_num=0, train_loss_step=38.40, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  26%|██▌       | 8/31 [00:04<00:13,  1.71it/s, loss=50.1, v_num=0, train_loss_step=38.40, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  26%|██▌       | 8/31 [00:04<00:13,  1.71it/s, loss=50.3, v_num=0, train_loss_step=53.40, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  29%|██▉       | 9/31 [00:05<00:12,  1.73it/s, loss=50.3, v_num=0, train_loss_step=53.40, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  29%|██▉       | 9/31 [00:05<00:12,  1.73it/s, loss=49.9, v_num=0, train_loss_step=35.30, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  32%|███▏      | 10/31 [00:05<00:12,  1.74it/s, loss=49.9, v_num=0, train_loss_step=35.30, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  32%|███▏      | 10/31 [00:05<00:12,  1.74it/s, loss=49, v_num=0, train_loss_step=37.70, val_loss=78.70, train_loss_epoch=50.40]  #015Epoch 16:  35%|███▌      | 11/31 [00:06<00:11,  1.68it/s, loss=49, v_num=0, train_loss_step=37.70, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  35%|███▌      | 11/31 [00:06<00:11,  1.68it/s, loss=48.4, v_num=0, train_loss_step=47.20, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  39%|███▊      | 12/31 [00:07<00:11,  1.70it/s, loss=48.4, v_num=0, train_loss_step=47.20, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  39%|███▊      | 12/31 [00:07<00:11,  1.69it/s, loss=49.2, v_num=0, train_loss_step=61.60, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  42%|████▏     | 13/31 [00:07<00:10,  1.72it/s, loss=49.2, v_num=0, train_loss_step=61.60, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  42%|████▏     | 13/31 [00:07<00:10,  1.72it/s, loss=49.4, v_num=0, train_loss_step=56.40, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  45%|████▌     | 14/31 [00:08<00:09,  1.73it/s, loss=49.4, v_num=0, train_loss_step=56.40, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  45%|████▌     | 14/31 [00:08<00:09,  1.73it/s, loss=49.3, v_num=0, train_loss_step=53.50, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  48%|████▊     | 15/31 [00:08<00:09,  1.75it/s, loss=49.3, v_num=0, train_loss_step=53.50, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  48%|████▊     | 15/31 [00:08<00:09,  1.75it/s, loss=48.9, v_num=0, train_loss_step=43.40, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  52%|█████▏    | 16/31 [00:09<00:08,  1.76it/s, loss=48.9, v_num=0, train_loss_step=43.40, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  52%|█████▏    | 16/31 [00:09<00:08,  1.76it/s, loss=48.7, v_num=0, train_loss_step=45.10, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  55%|█████▍    | 17/31 [00:09<00:07,  1.77it/s, loss=48.7, v_num=0, train_loss_step=45.10, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  55%|█████▍    | 17/31 [00:09<00:07,  1.76it/s, loss=48.5, v_num=0, train_loss_step=50.60, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  58%|█████▊    | 18/31 [00:10<00:07,  1.77it/s, loss=48.5, v_num=0, train_loss_step=50.60, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  58%|█████▊    | 18/31 [00:10<00:07,  1.77it/s, loss=49.1, v_num=0, train_loss_step=58.50, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  61%|██████▏   | 19/31 [00:10<00:06,  1.78it/s, loss=49.1, v_num=0, train_loss_step=58.50, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  61%|██████▏   | 19/31 [00:10<00:06,  1.78it/s, loss=49.7, v_num=0, train_loss_step=59.70, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  65%|██████▍   | 20/31 [00:11<00:06,  1.78it/s, loss=49.7, v_num=0, train_loss_step=59.70, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  65%|██████▍   | 20/31 [00:11<00:06,  1.78it/s, loss=50, v_num=0, train_loss_step=53.50, val_loss=78.70, train_loss_epoch=50.40]  #015Epoch 16:  68%|██████▊   | 21/31 [00:12<00:05,  1.74it/s, loss=50, v_num=0, train_loss_step=53.50, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  68%|██████▊   | 21/31 [00:12<00:05,  1.74it/s, loss=49.6, v_num=0, train_loss_step=39.60, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  71%|███████   | 22/31 [00:12<00:05,  1.75it/s, loss=49.6, v_num=0, train_loss_step=39.60, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  71%|███████   | 22/31 [00:12<00:05,  1.75it/s, loss=49.4, v_num=0, train_loss_step=50.10, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  74%|███████▍  | 23/31 [00:13<00:04,  1.75it/s, loss=49.4, v_num=0, train_loss_step=50.10, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  74%|███████▍  | 23/31 [00:13<00:04,  1.75it/s, loss=50, v_num=0, train_loss_step=65.90, val_loss=78.70, train_loss_epoch=50.40]  #015Epoch 16:  77%|███████▋  | 24/31 [00:13<00:03,  1.76it/s, loss=50, v_num=0, train_loss_step=65.90, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  77%|███████▋  | 24/31 [00:13<00:03,  1.76it/s, loss=50.1, v_num=0, train_loss_step=50.10, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  81%|████████  | 25/31 [00:14<00:03,  1.77it/s, loss=50.1, v_num=0, train_loss_step=50.10, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  81%|████████  | 25/31 [00:14<00:03,  1.77it/s, loss=49.4, v_num=0, train_loss_step=44.70, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  84%|████████▍ | 26/31 [00:14<00:02,  1.77it/s, loss=49.4, v_num=0, train_loss_step=44.70, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  84%|████████▍ | 26/31 [00:14<00:02,  1.77it/s, loss=49.5, v_num=0, train_loss_step=45.90, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  87%|████████▋ | 27/31 [00:15<00:02,  1.78it/s, loss=49.5, v_num=0, train_loss_step=45.90, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  87%|████████▋ | 27/31 [00:15<00:02,  1.78it/s, loss=49.8, v_num=0, train_loss_step=44.30, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  90%|█████████ | 28/31 [00:15<00:01,  1.79it/s, loss=49.8, v_num=0, train_loss_step=44.30, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  90%|█████████ | 28/31 [00:15<00:01,  1.79it/s, loss=49.7, v_num=0, train_loss_step=50.80, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  94%|█████████▎| 29/31 [00:16<00:01,  1.79it/s, loss=49.7, v_num=0, train_loss_step=50.80, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  94%|█████████▎| 29/31 [00:16<00:01,  1.79it/s, loss=50.5, v_num=0, train_loss_step=51.40, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  97%|█████████▋| 30/31 [00:16<00:00,  1.79it/s, loss=50.5, v_num=0, train_loss_step=51.40, val_loss=78.70, train_loss_epoch=50.40]#015Epoch 16:  97%|█████████▋| 30/31 [00:16<00:00,  1.79it/s, loss=51.7, v_num=0, train_loss_step=61.50, val_loss=78.70, train_loss_epoch=50.40]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 1/1 [00:01<00:00,  1.24s/it]#033[A#015Epoch 16: 100%|██████████| 31/31 [00:19<00:00,  1.61it/s, loss=51.7, v_num=0, train_loss_step=61.50, val_loss=78.10, train_loss_epoch=50.40]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015                                                         #033[A#015Epoch 16: 100%|██████████| 31/31 [00:20<00:00,  1.52it/s, loss=51.7, v_num=0, train_loss_step=61.50, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 16:   0%|          | 0/31 [00:00<?, ?it/s, loss=51.7, v_num=0, train_loss_step=61.50, val_loss=78.10, train_loss_epoch=50.10]         #015Epoch 17:   0%|          | 0/31 [00:00<?, ?it/s, loss=51.7, v_num=0, train_loss_step=61.50, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:   3%|▎         | 1/31 [00:01<00:33,  1.10s/it, loss=51.7, v_num=0, train_loss_step=61.50, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:   3%|▎         | 1/31 [00:01<00:33,  1.10s/it, loss=51.6, v_num=0, train_loss_step=46.10, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:   6%|▋         | 2/31 [00:01<00:25,  1.16it/s, loss=51.6, v_num=0, train_loss_step=46.10, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:   6%|▋         | 2/31 [00:01<00:25,  1.16it/s, loss=51.4, v_num=0, train_loss_step=57.70, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  10%|▉         | 3/31 [00:02<00:21,  1.31it/s, loss=51.4, v_num=0, train_loss_step=57.70, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  10%|▉         | 3/31 [00:02<00:21,  1.31it/s, loss=51, v_num=0, train_loss_step=48.10, val_loss=78.10, train_loss_epoch=50.10]  #015Epoch 17:  13%|█▎        | 4/31 [00:02<00:18,  1.43it/s, loss=51, v_num=0, train_loss_step=48.10, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  13%|█▎        | 4/31 [00:02<00:18,  1.43it/s, loss=51, v_num=0, train_loss_step=52.90, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  16%|█▌        | 5/31 [00:03<00:17,  1.48it/s, loss=51, v_num=0, train_loss_step=52.90, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  16%|█▌        | 5/31 [00:03<00:17,  1.48it/s, loss=51.3, v_num=0, train_loss_step=49.80, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  19%|█▉        | 6/31 [00:03<00:16,  1.51it/s, loss=51.3, v_num=0, train_loss_step=49.80, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  19%|█▉        | 6/31 [00:03<00:16,  1.51it/s, loss=51.5, v_num=0, train_loss_step=49.60, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  23%|██▎       | 7/31 [00:04<00:15,  1.55it/s, loss=51.5, v_num=0, train_loss_step=49.60, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  23%|██▎       | 7/31 [00:04<00:15,  1.55it/s, loss=51.7, v_num=0, train_loss_step=54.80, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  26%|██▌       | 8/31 [00:05<00:14,  1.56it/s, loss=51.7, v_num=0, train_loss_step=54.80, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  26%|██▌       | 8/31 [00:05<00:14,  1.56it/s, loss=51.2, v_num=0, train_loss_step=47.20, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  29%|██▉       | 9/31 [00:05<00:14,  1.56it/s, loss=51.2, v_num=0, train_loss_step=47.20, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  29%|██▉       | 9/31 [00:05<00:14,  1.56it/s, loss=51.2, v_num=0, train_loss_step=59.10, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  32%|███▏      | 10/31 [00:06<00:13,  1.57it/s, loss=51.2, v_num=0, train_loss_step=59.10, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  32%|███▏      | 10/31 [00:06<00:13,  1.57it/s, loss=50.5, v_num=0, train_loss_step=41.10, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  35%|███▌      | 11/31 [00:07<00:13,  1.52it/s, loss=50.5, v_num=0, train_loss_step=41.10, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  35%|███▌      | 11/31 [00:07<00:13,  1.52it/s, loss=50.9, v_num=0, train_loss_step=46.50, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  39%|███▊      | 12/31 [00:07<00:12,  1.54it/s, loss=50.9, v_num=0, train_loss_step=46.50, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  39%|███▊      | 12/31 [00:07<00:12,  1.54it/s, loss=50.3, v_num=0, train_loss_step=38.60, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  42%|████▏     | 13/31 [00:08<00:11,  1.57it/s, loss=50.3, v_num=0, train_loss_step=38.60, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  42%|████▏     | 13/31 [00:08<00:11,  1.57it/s, loss=49.2, v_num=0, train_loss_step=44.70, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  45%|████▌     | 14/31 [00:08<00:10,  1.59it/s, loss=49.2, v_num=0, train_loss_step=44.70, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  45%|████▌     | 14/31 [00:08<00:10,  1.59it/s, loss=49.5, v_num=0, train_loss_step=54.60, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  48%|████▊     | 15/31 [00:09<00:09,  1.61it/s, loss=49.5, v_num=0, train_loss_step=54.60, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  48%|████▊     | 15/31 [00:09<00:09,  1.61it/s, loss=49.9, v_num=0, train_loss_step=52.40, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  52%|█████▏    | 16/31 [00:09<00:09,  1.64it/s, loss=49.9, v_num=0, train_loss_step=52.40, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  52%|█████▏    | 16/31 [00:09<00:09,  1.64it/s, loss=49.7, v_num=0, train_loss_step=43.40, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  55%|█████▍    | 17/31 [00:10<00:08,  1.65it/s, loss=49.7, v_num=0, train_loss_step=43.40, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  55%|█████▍    | 17/31 [00:10<00:08,  1.65it/s, loss=50, v_num=0, train_loss_step=50.50, val_loss=78.10, train_loss_epoch=50.10]  #015Epoch 17:  58%|█████▊    | 18/31 [00:10<00:07,  1.67it/s, loss=50, v_num=0, train_loss_step=50.50, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  58%|█████▊    | 18/31 [00:10<00:07,  1.67it/s, loss=49.8, v_num=0, train_loss_step=45.10, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  61%|██████▏   | 19/31 [00:11<00:07,  1.69it/s, loss=49.8, v_num=0, train_loss_step=45.10, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  61%|██████▏   | 19/31 [00:11<00:07,  1.69it/s, loss=49.7, v_num=0, train_loss_step=50.10, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  65%|██████▍   | 20/31 [00:11<00:06,  1.70it/s, loss=49.7, v_num=0, train_loss_step=50.10, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  65%|██████▍   | 20/31 [00:11<00:06,  1.70it/s, loss=49.1, v_num=0, train_loss_step=49.50, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  68%|██████▊   | 21/31 [00:12<00:06,  1.66it/s, loss=49.1, v_num=0, train_loss_step=49.50, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  68%|██████▊   | 21/31 [00:12<00:06,  1.66it/s, loss=49.8, v_num=0, train_loss_step=60.40, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  71%|███████   | 22/31 [00:13<00:05,  1.67it/s, loss=49.8, v_num=0, train_loss_step=60.40, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  71%|███████   | 22/31 [00:13<00:05,  1.67it/s, loss=49.7, v_num=0, train_loss_step=54.80, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  74%|███████▍  | 23/31 [00:13<00:04,  1.68it/s, loss=49.7, v_num=0, train_loss_step=54.80, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  74%|███████▍  | 23/31 [00:13<00:04,  1.68it/s, loss=49.7, v_num=0, train_loss_step=48.90, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  77%|███████▋  | 24/31 [00:14<00:04,  1.69it/s, loss=49.7, v_num=0, train_loss_step=48.90, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  77%|███████▋  | 24/31 [00:14<00:04,  1.69it/s, loss=49.7, v_num=0, train_loss_step=53.00, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  81%|████████  | 25/31 [00:14<00:03,  1.70it/s, loss=49.7, v_num=0, train_loss_step=53.00, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  81%|████████  | 25/31 [00:14<00:03,  1.70it/s, loss=49.7, v_num=0, train_loss_step=49.50, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  84%|████████▍ | 26/31 [00:15<00:02,  1.71it/s, loss=49.7, v_num=0, train_loss_step=49.50, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  84%|████████▍ | 26/31 [00:15<00:02,  1.71it/s, loss=49.5, v_num=0, train_loss_step=46.30, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  87%|████████▋ | 27/31 [00:15<00:02,  1.72it/s, loss=49.5, v_num=0, train_loss_step=46.30, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  87%|████████▋ | 27/31 [00:15<00:02,  1.72it/s, loss=49.3, v_num=0, train_loss_step=49.40, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  90%|█████████ | 28/31 [00:16<00:01,  1.73it/s, loss=49.3, v_num=0, train_loss_step=49.40, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  90%|█████████ | 28/31 [00:16<00:01,  1.73it/s, loss=49.8, v_num=0, train_loss_step=58.30, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  94%|█████████▎| 29/31 [00:16<00:01,  1.73it/s, loss=49.8, v_num=0, train_loss_step=58.30, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  94%|█████████▎| 29/31 [00:16<00:01,  1.73it/s, loss=50.4, v_num=0, train_loss_step=71.70, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  97%|█████████▋| 30/31 [00:17<00:00,  1.73it/s, loss=50.4, v_num=0, train_loss_step=71.70, val_loss=78.10, train_loss_epoch=50.10]#015Epoch 17:  97%|█████████▋| 30/31 [00:17<00:00,  1.73it/s, loss=51.4, v_num=0, train_loss_step=59.40, val_loss=78.10, train_loss_epoch=50.10]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 1/1 [00:01<00:00,  1.25s/it]#033[A#015Epoch 17: 100%|██████████| 31/31 [00:19<00:00,  1.57it/s, loss=51.4, v_num=0, train_loss_step=59.40, val_loss=76.10, train_loss_epoch=50.10]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015                                                         #033[A#015Epoch 17: 100%|██████████| 31/31 [00:20<00:00,  1.49it/s, loss=51.4, v_num=0, train_loss_step=59.40, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 17:   0%|          | 0/31 [00:00<?, ?it/s, loss=51.4, v_num=0, train_loss_step=59.40, val_loss=76.10, train_loss_epoch=51.10]         #015Epoch 18:   0%|          | 0/31 [00:00<?, ?it/s, loss=51.4, v_num=0, train_loss_step=59.40, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:   3%|▎         | 1/31 [00:01<00:34,  1.14s/it, loss=51.4, v_num=0, train_loss_step=59.40, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:   3%|▎         | 1/31 [00:01<00:34,  1.14s/it, loss=51.2, v_num=0, train_loss_step=43.40, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:   6%|▋         | 2/31 [00:01<00:23,  1.22it/s, loss=51.2, v_num=0, train_loss_step=43.40, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:   6%|▋         | 2/31 [00:01<00:23,  1.22it/s, loss=51.8, v_num=0, train_loss_step=50.90, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  10%|▉         | 3/31 [00:02<00:20,  1.39it/s, loss=51.8, v_num=0, train_loss_step=50.90, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  10%|▉         | 3/31 [00:02<00:20,  1.39it/s, loss=52.7, v_num=0, train_loss_step=61.80, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  13%|█▎        | 4/31 [00:02<00:17,  1.50it/s, loss=52.7, v_num=0, train_loss_step=61.80, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  13%|█▎        | 4/31 [00:02<00:17,  1.50it/s, loss=52.9, v_num=0, train_loss_step=58.60, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  16%|█▌        | 5/31 [00:03<00:16,  1.58it/s, loss=52.9, v_num=0, train_loss_step=58.60, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  16%|█▌        | 5/31 [00:03<00:16,  1.58it/s, loss=52.7, v_num=0, train_loss_step=49.60, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  19%|█▉        | 6/31 [00:03<00:15,  1.63it/s, loss=52.7, v_num=0, train_loss_step=49.60, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  19%|█▉        | 6/31 [00:03<00:15,  1.63it/s, loss=52.4, v_num=0, train_loss_step=37.40, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  23%|██▎       | 7/31 [00:04<00:14,  1.68it/s, loss=52.4, v_num=0, train_loss_step=37.40, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  23%|██▎       | 7/31 [00:04<00:14,  1.68it/s, loss=52.7, v_num=0, train_loss_step=56.80, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  26%|██▌       | 8/31 [00:04<00:13,  1.71it/s, loss=52.7, v_num=0, train_loss_step=56.80, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  26%|██▌       | 8/31 [00:04<00:13,  1.71it/s, loss=52.7, v_num=0, train_loss_step=43.80, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  29%|██▉       | 9/31 [00:05<00:12,  1.75it/s, loss=52.7, v_num=0, train_loss_step=43.80, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  29%|██▉       | 9/31 [00:05<00:12,  1.75it/s, loss=52.5, v_num=0, train_loss_step=45.90, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  32%|███▏      | 10/31 [00:05<00:11,  1.77it/s, loss=52.5, v_num=0, train_loss_step=45.90, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  32%|███▏      | 10/31 [00:05<00:11,  1.77it/s, loss=52.9, v_num=0, train_loss_step=57.50, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  35%|███▌      | 11/31 [00:06<00:11,  1.69it/s, loss=52.9, v_num=0, train_loss_step=57.50, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  35%|███▌      | 11/31 [00:06<00:11,  1.69it/s, loss=51.7, v_num=0, train_loss_step=37.40, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  39%|███▊      | 12/31 [00:07<00:11,  1.70it/s, loss=51.7, v_num=0, train_loss_step=37.40, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  39%|███▊      | 12/31 [00:07<00:11,  1.70it/s, loss=51.7, v_num=0, train_loss_step=55.00, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  42%|████▏     | 13/31 [00:07<00:10,  1.73it/s, loss=51.7, v_num=0, train_loss_step=55.00, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  42%|████▏     | 13/31 [00:07<00:10,  1.73it/s, loss=51.3, v_num=0, train_loss_step=40.60, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  45%|████▌     | 14/31 [00:07<00:09,  1.75it/s, loss=51.3, v_num=0, train_loss_step=40.60, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  45%|████▌     | 14/31 [00:07<00:09,  1.75it/s, loss=50.8, v_num=0, train_loss_step=42.30, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  48%|████▊     | 15/31 [00:08<00:09,  1.77it/s, loss=50.8, v_num=0, train_loss_step=42.30, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  48%|████▊     | 15/31 [00:08<00:09,  1.77it/s, loss=50.1, v_num=0, train_loss_step=35.40, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  52%|█████▏    | 16/31 [00:08<00:08,  1.78it/s, loss=50.1, v_num=0, train_loss_step=35.40, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  52%|█████▏    | 16/31 [00:08<00:08,  1.78it/s, loss=50.1, v_num=0, train_loss_step=46.80, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  55%|█████▍    | 17/31 [00:09<00:07,  1.80it/s, loss=50.1, v_num=0, train_loss_step=46.80, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  55%|█████▍    | 17/31 [00:09<00:07,  1.80it/s, loss=49.4, v_num=0, train_loss_step=35.70, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  58%|█████▊    | 18/31 [00:09<00:07,  1.80it/s, loss=49.4, v_num=0, train_loss_step=35.70, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  58%|█████▊    | 18/31 [00:09<00:07,  1.80it/s, loss=48.7, v_num=0, train_loss_step=44.40, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  61%|██████▏   | 19/31 [00:10<00:06,  1.82it/s, loss=48.7, v_num=0, train_loss_step=44.40, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  61%|██████▏   | 19/31 [00:10<00:06,  1.82it/s, loss=47.7, v_num=0, train_loss_step=51.80, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  65%|██████▍   | 20/31 [00:10<00:06,  1.83it/s, loss=47.7, v_num=0, train_loss_step=51.80, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  65%|██████▍   | 20/31 [00:10<00:06,  1.83it/s, loss=47, v_num=0, train_loss_step=45.60, val_loss=76.10, train_loss_epoch=51.10]  #015Epoch 18:  68%|██████▊   | 21/31 [00:11<00:05,  1.78it/s, loss=47, v_num=0, train_loss_step=45.60, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  68%|██████▊   | 21/31 [00:11<00:05,  1.78it/s, loss=47.1, v_num=0, train_loss_step=44.70, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  71%|███████   | 22/31 [00:12<00:05,  1.79it/s, loss=47.1, v_num=0, train_loss_step=44.70, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  71%|███████   | 22/31 [00:12<00:05,  1.79it/s, loss=47.3, v_num=0, train_loss_step=54.70, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  74%|███████▍  | 23/31 [00:12<00:04,  1.80it/s, loss=47.3, v_num=0, train_loss_step=54.70, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  74%|███████▍  | 23/31 [00:12<00:04,  1.80it/s, loss=46.4, v_num=0, train_loss_step=43.20, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  77%|███████▋  | 24/31 [00:13<00:03,  1.80it/s, loss=46.4, v_num=0, train_loss_step=43.20, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  77%|███████▋  | 24/31 [00:13<00:03,  1.80it/s, loss=45.5, v_num=0, train_loss_step=40.80, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  81%|████████  | 25/31 [00:13<00:03,  1.81it/s, loss=45.5, v_num=0, train_loss_step=40.80, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  81%|████████  | 25/31 [00:13<00:03,  1.81it/s, loss=45.1, v_num=0, train_loss_step=42.20, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  84%|████████▍ | 26/31 [00:14<00:02,  1.82it/s, loss=45.1, v_num=0, train_loss_step=42.20, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  84%|████████▍ | 26/31 [00:14<00:02,  1.82it/s, loss=45.5, v_num=0, train_loss_step=45.00, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  87%|████████▋ | 27/31 [00:14<00:02,  1.82it/s, loss=45.5, v_num=0, train_loss_step=45.00, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  87%|████████▋ | 27/31 [00:14<00:02,  1.82it/s, loss=45, v_num=0, train_loss_step=47.70, val_loss=76.10, train_loss_epoch=51.10]  #015Epoch 18:  90%|█████████ | 28/31 [00:15<00:01,  1.83it/s, loss=45, v_num=0, train_loss_step=47.70, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  90%|█████████ | 28/31 [00:15<00:01,  1.83it/s, loss=45.2, v_num=0, train_loss_step=47.00, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  94%|█████████▎| 29/31 [00:15<00:01,  1.83it/s, loss=45.2, v_num=0, train_loss_step=47.00, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  94%|█████████▎| 29/31 [00:15<00:01,  1.83it/s, loss=45.2, v_num=0, train_loss_step=46.10, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  97%|█████████▋| 30/31 [00:16<00:00,  1.83it/s, loss=45.2, v_num=0, train_loss_step=46.10, val_loss=76.10, train_loss_epoch=51.10]#015Epoch 18:  97%|█████████▋| 30/31 [00:16<00:00,  1.83it/s, loss=44.8, v_num=0, train_loss_step=49.20, val_loss=76.10, train_loss_epoch=51.10]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]#033[A#015Epoch 18: 100%|██████████| 31/31 [00:18<00:00,  1.65it/s, loss=44.8, v_num=0, train_loss_step=49.20, val_loss=77.40, train_loss_epoch=51.10]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015                                                         #033[A#015Epoch 18: 100%|██████████| 31/31 [00:19<00:00,  1.55it/s, loss=44.8, v_num=0, train_loss_step=49.20, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 18:   0%|          | 0/31 [00:00<?, ?it/s, loss=44.8, v_num=0, train_loss_step=49.20, val_loss=77.40, train_loss_epoch=46.70]         #015Epoch 19:   0%|          | 0/31 [00:00<?, ?it/s, loss=44.8, v_num=0, train_loss_step=49.20, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:   3%|▎         | 1/31 [00:01<00:31,  1.05s/it, loss=44.8, v_num=0, train_loss_step=49.20, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:   3%|▎         | 1/31 [00:01<00:31,  1.05s/it, loss=45.4, v_num=0, train_loss_step=48.70, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:   6%|▋         | 2/31 [00:01<00:23,  1.24it/s, loss=45.4, v_num=0, train_loss_step=48.70, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:   6%|▋         | 2/31 [00:01<00:23,  1.24it/s, loss=45, v_num=0, train_loss_step=48.30, val_loss=77.40, train_loss_epoch=46.70]  #015Epoch 19:  10%|▉         | 3/31 [00:02<00:20,  1.38it/s, loss=45, v_num=0, train_loss_step=48.30, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  10%|▉         | 3/31 [00:02<00:20,  1.38it/s, loss=45.1, v_num=0, train_loss_step=42.80, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  13%|█▎        | 4/31 [00:02<00:18,  1.49it/s, loss=45.1, v_num=0, train_loss_step=42.80, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  13%|█▎        | 4/31 [00:02<00:18,  1.49it/s, loss=45.5, v_num=0, train_loss_step=50.30, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  16%|█▌        | 5/31 [00:03<00:16,  1.55it/s, loss=45.5, v_num=0, train_loss_step=50.30, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  16%|█▌        | 5/31 [00:03<00:16,  1.55it/s, loss=46.1, v_num=0, train_loss_step=46.00, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  19%|█▉        | 6/31 [00:03<00:15,  1.58it/s, loss=46.1, v_num=0, train_loss_step=46.00, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  19%|█▉        | 6/31 [00:03<00:15,  1.58it/s, loss=46.4, v_num=0, train_loss_step=53.40, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  23%|██▎       | 7/31 [00:04<00:14,  1.62it/s, loss=46.4, v_num=0, train_loss_step=53.40, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  23%|██▎       | 7/31 [00:04<00:14,  1.62it/s, loss=46.9, v_num=0, train_loss_step=45.10, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  26%|██▌       | 8/31 [00:04<00:13,  1.66it/s, loss=46.9, v_num=0, train_loss_step=45.10, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  26%|██▌       | 8/31 [00:04<00:13,  1.66it/s, loss=47.3, v_num=0, train_loss_step=52.70, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  29%|██▉       | 9/31 [00:05<00:12,  1.70it/s, loss=47.3, v_num=0, train_loss_step=52.70, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  29%|██▉       | 9/31 [00:05<00:12,  1.70it/s, loss=46.9, v_num=0, train_loss_step=45.10, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  32%|███▏      | 10/31 [00:05<00:12,  1.73it/s, loss=46.9, v_num=0, train_loss_step=45.10, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  32%|███▏      | 10/31 [00:05<00:12,  1.73it/s, loss=46.6, v_num=0, train_loss_step=39.10, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  35%|███▌      | 11/31 [00:06<00:11,  1.67it/s, loss=46.6, v_num=0, train_loss_step=39.10, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  35%|███▌      | 11/31 [00:06<00:11,  1.67it/s, loss=46.3, v_num=0, train_loss_step=37.40, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  39%|███▊      | 12/31 [00:07<00:11,  1.68it/s, loss=46.3, v_num=0, train_loss_step=37.40, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  39%|███▊      | 12/31 [00:07<00:11,  1.68it/s, loss=45.8, v_num=0, train_loss_step=44.80, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  42%|████▏     | 13/31 [00:07<00:10,  1.71it/s, loss=45.8, v_num=0, train_loss_step=44.80, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  42%|████▏     | 13/31 [00:07<00:10,  1.71it/s, loss=46.2, v_num=0, train_loss_step=52.30, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  45%|████▌     | 14/31 [00:08<00:09,  1.72it/s, loss=46.2, v_num=0, train_loss_step=52.30, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  45%|████▌     | 14/31 [00:08<00:09,  1.72it/s, loss=47.1, v_num=0, train_loss_step=58.50, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  48%|████▊     | 15/31 [00:08<00:09,  1.73it/s, loss=47.1, v_num=0, train_loss_step=58.50, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  48%|████▊     | 15/31 [00:08<00:09,  1.73it/s, loss=48, v_num=0, train_loss_step=59.70, val_loss=77.40, train_loss_epoch=46.70]  #015Epoch 19:  52%|█████▏    | 16/31 [00:09<00:08,  1.74it/s, loss=48, v_num=0, train_loss_step=59.70, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  52%|█████▏    | 16/31 [00:09<00:08,  1.74it/s, loss=48, v_num=0, train_loss_step=45.00, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  55%|█████▍    | 17/31 [00:09<00:08,  1.75it/s, loss=48, v_num=0, train_loss_step=45.00, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  55%|█████▍    | 17/31 [00:09<00:08,  1.75it/s, loss=48, v_num=0, train_loss_step=48.60, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  58%|█████▊    | 18/31 [00:10<00:07,  1.76it/s, loss=48, v_num=0, train_loss_step=48.60, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  58%|█████▊    | 18/31 [00:10<00:07,  1.76it/s, loss=48, v_num=0, train_loss_step=46.40, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  61%|██████▏   | 19/31 [00:10<00:06,  1.76it/s, loss=48, v_num=0, train_loss_step=46.40, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  61%|██████▏   | 19/31 [00:10<00:06,  1.76it/s, loss=47.7, v_num=0, train_loss_step=40.70, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  65%|██████▍   | 20/31 [00:11<00:06,  1.77it/s, loss=47.7, v_num=0, train_loss_step=40.70, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  65%|██████▍   | 20/31 [00:11<00:06,  1.77it/s, loss=47.9, v_num=0, train_loss_step=52.30, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  68%|██████▊   | 21/31 [00:12<00:05,  1.73it/s, loss=47.9, v_num=0, train_loss_step=52.30, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  68%|██████▊   | 21/31 [00:12<00:05,  1.73it/s, loss=47.8, v_num=0, train_loss_step=46.50, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  71%|███████   | 22/31 [00:12<00:05,  1.73it/s, loss=47.8, v_num=0, train_loss_step=46.50, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  71%|███████   | 22/31 [00:12<00:05,  1.73it/s, loss=48, v_num=0, train_loss_step=53.10, val_loss=77.40, train_loss_epoch=46.70]  #015Epoch 19:  74%|███████▍  | 23/31 [00:13<00:04,  1.74it/s, loss=48, v_num=0, train_loss_step=53.10, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  74%|███████▍  | 23/31 [00:13<00:04,  1.74it/s, loss=48.6, v_num=0, train_loss_step=55.50, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  77%|███████▋  | 24/31 [00:13<00:04,  1.75it/s, loss=48.6, v_num=0, train_loss_step=55.50, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  77%|███████▋  | 24/31 [00:13<00:04,  1.75it/s, loss=48, v_num=0, train_loss_step=37.30, val_loss=77.40, train_loss_epoch=46.70]  #015Epoch 19:  81%|████████  | 25/31 [00:14<00:03,  1.75it/s, loss=48, v_num=0, train_loss_step=37.30, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  81%|████████  | 25/31 [00:14<00:03,  1.75it/s, loss=48.5, v_num=0, train_loss_step=56.20, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  84%|████████▍ | 26/31 [00:14<00:02,  1.76it/s, loss=48.5, v_num=0, train_loss_step=56.20, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  84%|████████▍ | 26/31 [00:14<00:02,  1.76it/s, loss=48.3, v_num=0, train_loss_step=50.00, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  87%|████████▋ | 27/31 [00:15<00:02,  1.77it/s, loss=48.3, v_num=0, train_loss_step=50.00, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  87%|████████▋ | 27/31 [00:15<00:02,  1.77it/s, loss=47.7, v_num=0, train_loss_step=33.60, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  90%|█████████ | 28/31 [00:15<00:01,  1.77it/s, loss=47.7, v_num=0, train_loss_step=33.60, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  90%|█████████ | 28/31 [00:15<00:01,  1.77it/s, loss=47, v_num=0, train_loss_step=37.60, val_loss=77.40, train_loss_epoch=46.70]  #015Epoch 19:  94%|█████████▎| 29/31 [00:16<00:01,  1.77it/s, loss=47, v_num=0, train_loss_step=37.60, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  94%|█████████▎| 29/31 [00:16<00:01,  1.77it/s, loss=46.7, v_num=0, train_loss_step=39.30, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  97%|█████████▋| 30/31 [00:16<00:00,  1.78it/s, loss=46.7, v_num=0, train_loss_step=39.30, val_loss=77.40, train_loss_epoch=46.70]#015Epoch 19:  97%|█████████▋| 30/31 [00:16<00:00,  1.78it/s, loss=47.2, v_num=0, train_loss_step=49.40, val_loss=77.40, train_loss_epoch=46.70]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]#033[A#015Epoch 19: 100%|██████████| 31/31 [00:19<00:00,  1.61it/s, loss=47.2, v_num=0, train_loss_step=49.40, val_loss=77.40, train_loss_epoch=46.70]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015                                                         #033[A#015Epoch 19: 100%|██████████| 31/31 [00:20<00:00,  1.51it/s, loss=47.2, v_num=0, train_loss_step=49.40, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 19:   0%|          | 0/31 [00:00<?, ?it/s, loss=47.2, v_num=0, train_loss_step=49.40, val_loss=77.40, train_loss_epoch=47.20]         #015Epoch 20:   0%|          | 0/31 [00:00<?, ?it/s, loss=47.2, v_num=0, train_loss_step=49.40, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:   3%|▎         | 1/31 [00:01<00:33,  1.12s/it, loss=47.2, v_num=0, train_loss_step=49.40, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:   3%|▎         | 1/31 [00:01<00:33,  1.12s/it, loss=47.7, v_num=0, train_loss_step=47.60, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:   6%|▋         | 2/31 [00:01<00:24,  1.19it/s, loss=47.7, v_num=0, train_loss_step=47.60, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:   6%|▋         | 2/31 [00:01<00:24,  1.19it/s, loss=47.7, v_num=0, train_loss_step=45.20, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  10%|▉         | 3/31 [00:02<00:20,  1.37it/s, loss=47.7, v_num=0, train_loss_step=45.20, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  10%|▉         | 3/31 [00:02<00:20,  1.37it/s, loss=47.1, v_num=0, train_loss_step=39.30, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  13%|█▎        | 4/31 [00:02<00:18,  1.42it/s, loss=47.1, v_num=0, train_loss_step=39.30, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  13%|█▎        | 4/31 [00:02<00:18,  1.42it/s, loss=46.9, v_num=0, train_loss_step=55.00, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  16%|█▌        | 5/31 [00:03<00:17,  1.47it/s, loss=46.9, v_num=0, train_loss_step=55.00, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  16%|█▌        | 5/31 [00:03<00:17,  1.47it/s, loss=46.4, v_num=0, train_loss_step=49.30, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  19%|█▉        | 6/31 [00:04<00:16,  1.49it/s, loss=46.4, v_num=0, train_loss_step=49.30, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  19%|█▉        | 6/31 [00:04<00:16,  1.49it/s, loss=47, v_num=0, train_loss_step=56.00, val_loss=77.40, train_loss_epoch=47.20]  #015Epoch 20:  23%|██▎       | 7/31 [00:04<00:15,  1.50it/s, loss=47, v_num=0, train_loss_step=56.00, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  23%|██▎       | 7/31 [00:04<00:16,  1.50it/s, loss=46.4, v_num=0, train_loss_step=38.30, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  26%|██▌       | 8/31 [00:05<00:15,  1.51it/s, loss=46.4, v_num=0, train_loss_step=38.30, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  26%|██▌       | 8/31 [00:05<00:15,  1.51it/s, loss=46.3, v_num=0, train_loss_step=42.70, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  29%|██▉       | 9/31 [00:05<00:14,  1.55it/s, loss=46.3, v_num=0, train_loss_step=42.70, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  29%|██▉       | 9/31 [00:05<00:14,  1.55it/s, loss=46.5, v_num=0, train_loss_step=46.10, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  32%|███▏      | 10/31 [00:06<00:13,  1.59it/s, loss=46.5, v_num=0, train_loss_step=46.10, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  32%|███▏      | 10/31 [00:06<00:13,  1.58it/s, loss=46.8, v_num=0, train_loss_step=58.80, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  35%|███▌      | 11/31 [00:07<00:12,  1.55it/s, loss=46.8, v_num=0, train_loss_step=58.80, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  35%|███▌      | 11/31 [00:07<00:12,  1.55it/s, loss=47, v_num=0, train_loss_step=50.30, val_loss=77.40, train_loss_epoch=47.20]  #015Epoch 20:  39%|███▊      | 12/31 [00:07<00:12,  1.56it/s, loss=47, v_num=0, train_loss_step=50.30, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  39%|███▊      | 12/31 [00:07<00:12,  1.56it/s, loss=46.6, v_num=0, train_loss_step=43.90, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  42%|████▏     | 13/31 [00:08<00:11,  1.59it/s, loss=46.6, v_num=0, train_loss_step=43.90, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  42%|████▏     | 13/31 [00:08<00:11,  1.59it/s, loss=46.8, v_num=0, train_loss_step=60.80, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  45%|████▌     | 14/31 [00:08<00:10,  1.62it/s, loss=46.8, v_num=0, train_loss_step=60.80, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  45%|████▌     | 14/31 [00:08<00:10,  1.62it/s, loss=47.4, v_num=0, train_loss_step=48.80, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  48%|████▊     | 15/31 [00:09<00:09,  1.63it/s, loss=47.4, v_num=0, train_loss_step=48.80, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  48%|████▊     | 15/31 [00:09<00:09,  1.63it/s, loss=46.8, v_num=0, train_loss_step=43.20, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  52%|█████▏    | 16/31 [00:09<00:09,  1.65it/s, loss=46.8, v_num=0, train_loss_step=43.20, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  52%|█████▏    | 16/31 [00:09<00:09,  1.65it/s, loss=46.4, v_num=0, train_loss_step=41.80, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  55%|█████▍    | 17/31 [00:10<00:08,  1.66it/s, loss=46.4, v_num=0, train_loss_step=41.80, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  55%|█████▍    | 17/31 [00:10<00:08,  1.66it/s, loss=47.3, v_num=0, train_loss_step=52.00, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  58%|█████▊    | 18/31 [00:10<00:07,  1.68it/s, loss=47.3, v_num=0, train_loss_step=52.00, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  58%|█████▊    | 18/31 [00:10<00:07,  1.68it/s, loss=47.3, v_num=0, train_loss_step=37.70, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  61%|██████▏   | 19/31 [00:11<00:07,  1.69it/s, loss=47.3, v_num=0, train_loss_step=37.70, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  61%|██████▏   | 19/31 [00:11<00:07,  1.69it/s, loss=47.8, v_num=0, train_loss_step=50.00, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  65%|██████▍   | 20/31 [00:11<00:06,  1.70it/s, loss=47.8, v_num=0, train_loss_step=50.00, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  65%|██████▍   | 20/31 [00:11<00:06,  1.70it/s, loss=48, v_num=0, train_loss_step=53.90, val_loss=77.40, train_loss_epoch=47.20]  #015Epoch 20:  68%|██████▊   | 21/31 [00:12<00:05,  1.67it/s, loss=48, v_num=0, train_loss_step=53.90, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  68%|██████▊   | 21/31 [00:12<00:05,  1.67it/s, loss=47.9, v_num=0, train_loss_step=43.90, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  71%|███████   | 22/31 [00:13<00:05,  1.68it/s, loss=47.9, v_num=0, train_loss_step=43.90, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  71%|███████   | 22/31 [00:13<00:05,  1.68it/s, loss=48, v_num=0, train_loss_step=48.50, val_loss=77.40, train_loss_epoch=47.20]  #015Epoch 20:  74%|███████▍  | 23/31 [00:13<00:04,  1.69it/s, loss=48, v_num=0, train_loss_step=48.50, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  74%|███████▍  | 23/31 [00:13<00:04,  1.69it/s, loss=48.3, v_num=0, train_loss_step=44.40, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  77%|███████▋  | 24/31 [00:14<00:04,  1.70it/s, loss=48.3, v_num=0, train_loss_step=44.40, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  77%|███████▋  | 24/31 [00:14<00:04,  1.70it/s, loss=48.2, v_num=0, train_loss_step=53.60, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  81%|████████  | 25/31 [00:14<00:03,  1.70it/s, loss=48.2, v_num=0, train_loss_step=53.60, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  81%|████████  | 25/31 [00:14<00:03,  1.70it/s, loss=48.3, v_num=0, train_loss_step=51.10, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  84%|████████▍ | 26/31 [00:15<00:02,  1.72it/s, loss=48.3, v_num=0, train_loss_step=51.10, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  84%|████████▍ | 26/31 [00:15<00:02,  1.72it/s, loss=48.5, v_num=0, train_loss_step=61.10, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  87%|████████▋ | 27/31 [00:15<00:02,  1.72it/s, loss=48.5, v_num=0, train_loss_step=61.10, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  87%|████████▋ | 27/31 [00:15<00:02,  1.72it/s, loss=49.3, v_num=0, train_loss_step=53.90, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  90%|█████████ | 28/31 [00:16<00:01,  1.73it/s, loss=49.3, v_num=0, train_loss_step=53.90, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  90%|█████████ | 28/31 [00:16<00:01,  1.73it/s, loss=50.2, v_num=0, train_loss_step=59.50, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  94%|█████████▎| 29/31 [00:16<00:01,  1.74it/s, loss=50.2, v_num=0, train_loss_step=59.50, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  94%|█████████▎| 29/31 [00:16<00:01,  1.74it/s, loss=50, v_num=0, train_loss_step=42.00, val_loss=77.40, train_loss_epoch=47.20]  #015Epoch 20:  97%|█████████▋| 30/31 [00:17<00:00,  1.75it/s, loss=50, v_num=0, train_loss_step=42.00, val_loss=77.40, train_loss_epoch=47.20]#015Epoch 20:  97%|█████████▋| 30/31 [00:17<00:00,  1.75it/s, loss=49.1, v_num=0, train_loss_step=41.40, val_loss=77.40, train_loss_epoch=47.20]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]#033[A#015Epoch 20: 100%|██████████| 31/31 [00:19<00:00,  1.61it/s, loss=49.1, v_num=0, train_loss_step=41.40, val_loss=77.70, train_loss_epoch=47.20]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015                                                         #033[A#015Epoch 20: 100%|██████████| 31/31 [00:20<00:00,  1.50it/s, loss=49.1, v_num=0, train_loss_step=41.40, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 20:   0%|          | 0/31 [00:00<?, ?it/s, loss=49.1, v_num=0, train_loss_step=41.40, val_loss=77.70, train_loss_epoch=48.70]         #015Epoch 21:   0%|          | 0/31 [00:00<?, ?it/s, loss=49.1, v_num=0, train_loss_step=41.40, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:   3%|▎         | 1/31 [00:01<00:31,  1.06s/it, loss=49.1, v_num=0, train_loss_step=41.40, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:   3%|▎         | 1/31 [00:01<00:31,  1.06s/it, loss=48.9, v_num=0, train_loss_step=45.50, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:   6%|▋         | 2/31 [00:01<00:23,  1.21it/s, loss=48.9, v_num=0, train_loss_step=45.50, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:   6%|▋         | 2/31 [00:01<00:23,  1.21it/s, loss=49.1, v_num=0, train_loss_step=48.30, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  10%|▉         | 3/31 [00:02<00:20,  1.36it/s, loss=49.1, v_num=0, train_loss_step=48.30, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  10%|▉         | 3/31 [00:02<00:20,  1.36it/s, loss=48.8, v_num=0, train_loss_step=54.90, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  13%|█▎        | 4/31 [00:02<00:18,  1.50it/s, loss=48.8, v_num=0, train_loss_step=54.90, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  13%|█▎        | 4/31 [00:02<00:18,  1.50it/s, loss=48.9, v_num=0, train_loss_step=50.80, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  16%|█▌        | 5/31 [00:03<00:16,  1.57it/s, loss=48.9, v_num=0, train_loss_step=50.80, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  16%|█▌        | 5/31 [00:03<00:16,  1.57it/s, loss=48.6, v_num=0, train_loss_step=37.60, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  19%|█▉        | 6/31 [00:03<00:15,  1.61it/s, loss=48.6, v_num=0, train_loss_step=37.60, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  19%|█▉        | 6/31 [00:03<00:15,  1.61it/s, loss=49.4, v_num=0, train_loss_step=57.90, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  23%|██▎       | 7/31 [00:04<00:14,  1.66it/s, loss=49.4, v_num=0, train_loss_step=57.90, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  23%|██▎       | 7/31 [00:04<00:14,  1.66it/s, loss=48.6, v_num=0, train_loss_step=36.70, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  26%|██▌       | 8/31 [00:04<00:13,  1.69it/s, loss=48.6, v_num=0, train_loss_step=36.70, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  26%|██▌       | 8/31 [00:04<00:13,  1.69it/s, loss=49.3, v_num=0, train_loss_step=51.50, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  29%|██▉       | 9/31 [00:05<00:12,  1.73it/s, loss=49.3, v_num=0, train_loss_step=51.50, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  29%|██▉       | 9/31 [00:05<00:12,  1.72it/s, loss=49.2, v_num=0, train_loss_step=46.80, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  32%|███▏      | 10/31 [00:05<00:11,  1.75it/s, loss=49.2, v_num=0, train_loss_step=46.80, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  32%|███▏      | 10/31 [00:05<00:11,  1.75it/s, loss=48.7, v_num=0, train_loss_step=45.40, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  35%|███▌      | 11/31 [00:06<00:11,  1.68it/s, loss=48.7, v_num=0, train_loss_step=45.40, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  35%|███▌      | 11/31 [00:06<00:11,  1.68it/s, loss=48.3, v_num=0, train_loss_step=34.50, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  39%|███▊      | 12/31 [00:07<00:11,  1.69it/s, loss=48.3, v_num=0, train_loss_step=34.50, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  39%|███▊      | 12/31 [00:07<00:11,  1.69it/s, loss=48.4, v_num=0, train_loss_step=50.80, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  42%|████▏     | 13/31 [00:07<00:10,  1.68it/s, loss=48.4, v_num=0, train_loss_step=50.80, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  42%|████▏     | 13/31 [00:07<00:10,  1.68it/s, loss=49.3, v_num=0, train_loss_step=62.10, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  45%|████▌     | 14/31 [00:08<00:10,  1.67it/s, loss=49.3, v_num=0, train_loss_step=62.10, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  45%|████▌     | 14/31 [00:08<00:10,  1.67it/s, loss=49, v_num=0, train_loss_step=47.20, val_loss=77.70, train_loss_epoch=48.70]  #015Epoch 21:  48%|████▊     | 15/31 [00:08<00:09,  1.67it/s, loss=49, v_num=0, train_loss_step=47.20, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  48%|████▊     | 15/31 [00:08<00:09,  1.67it/s, loss=48.8, v_num=0, train_loss_step=48.20, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  52%|█████▏    | 16/31 [00:09<00:08,  1.67it/s, loss=48.8, v_num=0, train_loss_step=48.20, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  52%|█████▏    | 16/31 [00:09<00:08,  1.67it/s, loss=48.3, v_num=0, train_loss_step=50.40, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  55%|█████▍    | 17/31 [00:10<00:08,  1.67it/s, loss=48.3, v_num=0, train_loss_step=50.40, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  55%|█████▍    | 17/31 [00:10<00:08,  1.67it/s, loss=47.9, v_num=0, train_loss_step=46.40, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  58%|█████▊    | 18/31 [00:10<00:07,  1.68it/s, loss=47.9, v_num=0, train_loss_step=46.40, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  58%|█████▊    | 18/31 [00:10<00:07,  1.68it/s, loss=46.6, v_num=0, train_loss_step=32.80, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  61%|██████▏   | 19/31 [00:11<00:07,  1.67it/s, loss=46.6, v_num=0, train_loss_step=32.80, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  61%|██████▏   | 19/31 [00:11<00:07,  1.67it/s, loss=46.6, v_num=0, train_loss_step=43.10, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  65%|██████▍   | 20/31 [00:12<00:06,  1.66it/s, loss=46.6, v_num=0, train_loss_step=43.10, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  65%|██████▍   | 20/31 [00:12<00:06,  1.66it/s, loss=48.6, v_num=0, train_loss_step=80.30, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  68%|██████▊   | 21/31 [00:13<00:06,  1.59it/s, loss=48.6, v_num=0, train_loss_step=80.30, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  68%|██████▊   | 21/31 [00:13<00:06,  1.59it/s, loss=48.4, v_num=0, train_loss_step=42.20, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  71%|███████   | 22/31 [00:13<00:05,  1.60it/s, loss=48.4, v_num=0, train_loss_step=42.20, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  71%|███████   | 22/31 [00:13<00:05,  1.60it/s, loss=48.5, v_num=0, train_loss_step=50.80, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  74%|███████▍  | 23/31 [00:14<00:04,  1.62it/s, loss=48.5, v_num=0, train_loss_step=50.80, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  74%|███████▍  | 23/31 [00:14<00:04,  1.62it/s, loss=48.2, v_num=0, train_loss_step=48.60, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  77%|███████▋  | 24/31 [00:14<00:04,  1.63it/s, loss=48.2, v_num=0, train_loss_step=48.60, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  77%|███████▋  | 24/31 [00:14<00:04,  1.63it/s, loss=48.3, v_num=0, train_loss_step=52.30, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  81%|████████  | 25/31 [00:15<00:03,  1.64it/s, loss=48.3, v_num=0, train_loss_step=52.30, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  81%|████████  | 25/31 [00:15<00:03,  1.64it/s, loss=48.4, v_num=0, train_loss_step=40.70, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  84%|████████▍ | 26/31 [00:15<00:03,  1.65it/s, loss=48.4, v_num=0, train_loss_step=40.70, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  84%|████████▍ | 26/31 [00:15<00:03,  1.65it/s, loss=48.2, v_num=0, train_loss_step=53.00, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  87%|████████▋ | 27/31 [00:16<00:02,  1.66it/s, loss=48.2, v_num=0, train_loss_step=53.00, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  87%|████████▋ | 27/31 [00:16<00:02,  1.66it/s, loss=48.9, v_num=0, train_loss_step=50.20, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  90%|█████████ | 28/31 [00:16<00:01,  1.68it/s, loss=48.9, v_num=0, train_loss_step=50.20, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  90%|█████████ | 28/31 [00:16<00:01,  1.68it/s, loss=48.2, v_num=0, train_loss_step=38.70, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  94%|█████████▎| 29/31 [00:17<00:01,  1.69it/s, loss=48.2, v_num=0, train_loss_step=38.70, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  94%|█████████▎| 29/31 [00:17<00:01,  1.69it/s, loss=47.9, v_num=0, train_loss_step=39.50, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  97%|█████████▋| 30/31 [00:17<00:00,  1.69it/s, loss=47.9, v_num=0, train_loss_step=39.50, val_loss=77.70, train_loss_epoch=48.70]#015Epoch 21:  97%|█████████▋| 30/31 [00:17<00:00,  1.69it/s, loss=47.6, v_num=0, train_loss_step=40.80, val_loss=77.70, train_loss_epoch=48.70]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]#033[A#015Epoch 21: 100%|██████████| 31/31 [00:19<00:00,  1.56it/s, loss=47.6, v_num=0, train_loss_step=40.80, val_loss=76.40, train_loss_epoch=48.70]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015                                                         #033[A#015Epoch 21: 100%|██████████| 31/31 [00:21<00:00,  1.46it/s, loss=47.6, v_num=0, train_loss_step=40.80, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 21:   0%|          | 0/31 [00:00<?, ?it/s, loss=47.6, v_num=0, train_loss_step=40.80, val_loss=76.40, train_loss_epoch=47.60]         #015Epoch 22:   0%|          | 0/31 [00:00<?, ?it/s, loss=47.6, v_num=0, train_loss_step=40.80, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:   3%|▎         | 1/31 [00:01<00:35,  1.20s/it, loss=47.6, v_num=0, train_loss_step=40.80, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:   3%|▎         | 1/31 [00:01<00:35,  1.20s/it, loss=48.4, v_num=0, train_loss_step=50.00, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:   6%|▋         | 2/31 [00:01<00:24,  1.17it/s, loss=48.4, v_num=0, train_loss_step=50.00, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:   6%|▋         | 2/31 [00:01<00:24,  1.17it/s, loss=47.6, v_num=0, train_loss_step=35.20, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  10%|▉         | 3/31 [00:02<00:20,  1.36it/s, loss=47.6, v_num=0, train_loss_step=35.20, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  10%|▉         | 3/31 [00:02<00:20,  1.36it/s, loss=46.5, v_num=0, train_loss_step=39.60, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  13%|█▎        | 4/31 [00:02<00:18,  1.46it/s, loss=46.5, v_num=0, train_loss_step=39.60, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  13%|█▎        | 4/31 [00:02<00:18,  1.46it/s, loss=46.2, v_num=0, train_loss_step=40.30, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  16%|█▌        | 5/31 [00:03<00:16,  1.55it/s, loss=46.2, v_num=0, train_loss_step=40.30, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  16%|█▌        | 5/31 [00:03<00:16,  1.54it/s, loss=45.7, v_num=0, train_loss_step=38.90, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  19%|█▉        | 6/31 [00:03<00:15,  1.58it/s, loss=45.7, v_num=0, train_loss_step=38.90, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  19%|█▉        | 6/31 [00:03<00:15,  1.58it/s, loss=45.5, v_num=0, train_loss_step=46.30, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  23%|██▎       | 7/31 [00:04<00:14,  1.62it/s, loss=45.5, v_num=0, train_loss_step=46.30, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  23%|██▎       | 7/31 [00:04<00:14,  1.62it/s, loss=45.3, v_num=0, train_loss_step=42.40, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  26%|██▌       | 8/31 [00:04<00:13,  1.66it/s, loss=45.3, v_num=0, train_loss_step=42.40, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  26%|██▌       | 8/31 [00:04<00:13,  1.66it/s, loss=46.6, v_num=0, train_loss_step=58.40, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  29%|██▉       | 9/31 [00:05<00:12,  1.70it/s, loss=46.6, v_num=0, train_loss_step=58.40, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  29%|██▉       | 9/31 [00:05<00:12,  1.70it/s, loss=46.4, v_num=0, train_loss_step=39.30, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  32%|███▏      | 10/31 [00:05<00:12,  1.73it/s, loss=46.4, v_num=0, train_loss_step=39.30, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  32%|███▏      | 10/31 [00:05<00:12,  1.73it/s, loss=44.1, v_num=0, train_loss_step=34.10, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  35%|███▌      | 11/31 [00:06<00:12,  1.66it/s, loss=44.1, v_num=0, train_loss_step=34.10, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  35%|███▌      | 11/31 [00:06<00:12,  1.66it/s, loss=44.3, v_num=0, train_loss_step=47.60, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  39%|███▊      | 12/31 [00:07<00:11,  1.67it/s, loss=44.3, v_num=0, train_loss_step=47.60, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  39%|███▊      | 12/31 [00:07<00:11,  1.67it/s, loss=43.8, v_num=0, train_loss_step=39.20, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  42%|████▏     | 13/31 [00:07<00:10,  1.69it/s, loss=43.8, v_num=0, train_loss_step=39.20, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  42%|████▏     | 13/31 [00:07<00:10,  1.69it/s, loss=42.9, v_num=0, train_loss_step=32.50, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  45%|████▌     | 14/31 [00:08<00:09,  1.71it/s, loss=42.9, v_num=0, train_loss_step=32.50, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  45%|████▌     | 14/31 [00:08<00:09,  1.71it/s, loss=42.5, v_num=0, train_loss_step=43.40, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  48%|████▊     | 15/31 [00:08<00:09,  1.72it/s, loss=42.5, v_num=0, train_loss_step=43.40, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  48%|████▊     | 15/31 [00:08<00:09,  1.72it/s, loss=42.8, v_num=0, train_loss_step=45.60, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  52%|█████▏    | 16/31 [00:09<00:08,  1.74it/s, loss=42.8, v_num=0, train_loss_step=45.60, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  52%|█████▏    | 16/31 [00:09<00:08,  1.74it/s, loss=42.4, v_num=0, train_loss_step=45.40, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  55%|█████▍    | 17/31 [00:09<00:08,  1.74it/s, loss=42.4, v_num=0, train_loss_step=45.40, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  55%|█████▍    | 17/31 [00:09<00:08,  1.74it/s, loss=42, v_num=0, train_loss_step=42.80, val_loss=76.40, train_loss_epoch=47.60]  #015Epoch 22:  58%|█████▊    | 18/31 [00:10<00:07,  1.75it/s, loss=42, v_num=0, train_loss_step=42.80, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  58%|█████▊    | 18/31 [00:10<00:07,  1.75it/s, loss=42.1, v_num=0, train_loss_step=39.80, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  61%|██████▏   | 19/31 [00:10<00:06,  1.75it/s, loss=42.1, v_num=0, train_loss_step=39.80, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  61%|██████▏   | 19/31 [00:10<00:06,  1.75it/s, loss=42.1, v_num=0, train_loss_step=40.30, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  65%|██████▍   | 20/31 [00:11<00:06,  1.77it/s, loss=42.1, v_num=0, train_loss_step=40.30, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  65%|██████▍   | 20/31 [00:11<00:06,  1.77it/s, loss=41.9, v_num=0, train_loss_step=37.60, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  68%|██████▊   | 21/31 [00:12<00:05,  1.72it/s, loss=41.9, v_num=0, train_loss_step=37.60, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  68%|██████▊   | 21/31 [00:12<00:05,  1.71it/s, loss=41.9, v_num=0, train_loss_step=49.10, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  71%|███████   | 22/31 [00:12<00:05,  1.73it/s, loss=41.9, v_num=0, train_loss_step=49.10, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  71%|███████   | 22/31 [00:12<00:05,  1.73it/s, loss=43.1, v_num=0, train_loss_step=58.50, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  74%|███████▍  | 23/31 [00:13<00:04,  1.73it/s, loss=43.1, v_num=0, train_loss_step=58.50, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  74%|███████▍  | 23/31 [00:13<00:04,  1.73it/s, loss=43.7, v_num=0, train_loss_step=52.40, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  77%|███████▋  | 24/31 [00:13<00:04,  1.73it/s, loss=43.7, v_num=0, train_loss_step=52.40, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  77%|███████▋  | 24/31 [00:13<00:04,  1.73it/s, loss=44.7, v_num=0, train_loss_step=60.00, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  81%|████████  | 25/31 [00:14<00:03,  1.74it/s, loss=44.7, v_num=0, train_loss_step=60.00, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  81%|████████  | 25/31 [00:14<00:03,  1.74it/s, loss=44.7, v_num=0, train_loss_step=39.30, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  84%|████████▍ | 26/31 [00:14<00:02,  1.75it/s, loss=44.7, v_num=0, train_loss_step=39.30, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  84%|████████▍ | 26/31 [00:14<00:02,  1.75it/s, loss=44.4, v_num=0, train_loss_step=40.00, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  87%|████████▋ | 27/31 [00:15<00:02,  1.76it/s, loss=44.4, v_num=0, train_loss_step=40.00, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  87%|████████▋ | 27/31 [00:15<00:02,  1.76it/s, loss=44.7, v_num=0, train_loss_step=47.80, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  90%|█████████ | 28/31 [00:15<00:01,  1.76it/s, loss=44.7, v_num=0, train_loss_step=47.80, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  90%|█████████ | 28/31 [00:15<00:01,  1.76it/s, loss=43.7, v_num=0, train_loss_step=39.40, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  94%|█████████▎| 29/31 [00:16<00:01,  1.77it/s, loss=43.7, v_num=0, train_loss_step=39.40, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  94%|█████████▎| 29/31 [00:16<00:01,  1.77it/s, loss=43.4, v_num=0, train_loss_step=32.80, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  97%|█████████▋| 30/31 [00:16<00:00,  1.77it/s, loss=43.4, v_num=0, train_loss_step=32.80, val_loss=76.40, train_loss_epoch=47.60]#015Epoch 22:  97%|█████████▋| 30/31 [00:16<00:00,  1.77it/s, loss=43.5, v_num=0, train_loss_step=37.10, val_loss=76.40, train_loss_epoch=47.60]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 1/1 [00:01<00:00,  1.07s/it]#033[A#015Epoch 22: 100%|██████████| 31/31 [00:19<00:00,  1.62it/s, loss=43.5, v_num=0, train_loss_step=37.10, val_loss=77.00, train_loss_epoch=47.60]\u001b[0m\n",
      "\u001b[34m#015                                                         #033[A#015Epoch 22: 100%|██████████| 31/31 [00:20<00:00,  1.50it/s, loss=43.5, v_num=0, train_loss_step=37.10, val_loss=77.00, train_loss_epoch=43.20]#015Epoch 22: 100%|██████████| 31/31 [00:20<00:00,  1.49it/s, loss=43.5, v_num=0, train_loss_step=37.10, val_loss=77.00, train_loss_epoch=43.20]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2022-08-22 10:22:12 Uploading - Uploading generated training model\u001b[34mGPU available: True, used: True\u001b[0m\n",
      "\u001b[34mTPU available: False, using: 0 TPU cores\u001b[0m\n",
      "\u001b[34mIPU available: False, using: 0 IPUs\u001b[0m\n",
      "\u001b[34mLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "   | Name                               | Type                            | Params\u001b[0m\n",
      "\u001b[34m----------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m0  | loss                               | QuantileLoss                    | 0     \u001b[0m\n",
      "\u001b[34m1  | logging_metrics                    | ModuleList                      | 0     \u001b[0m\n",
      "\u001b[34m2  | input_embeddings                   | MultiEmbedding                  | 1.3 K \u001b[0m\n",
      "\u001b[34m3  | prescalers                         | ModuleDict                      | 256   \u001b[0m\n",
      "\u001b[34m4  | static_variable_selection          | VariableSelectionNetwork        | 3.4 K \u001b[0m\n",
      "\u001b[34m5  | encoder_variable_selection         | VariableSelectionNetwork        | 8.0 K \u001b[0m\n",
      "\u001b[34m6  | decoder_variable_selection         | VariableSelectionNetwork        | 2.7 K \u001b[0m\n",
      "\u001b[34m7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K \u001b[0m\n",
      "\u001b[34m8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K \u001b[0m\n",
      "\u001b[34m9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K \u001b[0m\n",
      "\u001b[34m10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K \u001b[0m\n",
      "\u001b[34m11 | lstm_encoder                       | LSTM                            | 2.2 K \u001b[0m\n",
      "\u001b[34m12 | lstm_decoder                       | LSTM                            | 2.2 K \u001b[0m\n",
      "\u001b[34m13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544   \u001b[0m\n",
      "\u001b[34m14 | post_lstm_add_norm_encoder         | AddNorm                         | 32    \u001b[0m\n",
      "\u001b[34m15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K \u001b[0m\n",
      "\u001b[34m16 | multihead_attn                     | InterpretableMultiHeadAttention | 1.1 K \u001b[0m\n",
      "\u001b[34m17 | post_attn_gate_norm                | GateAddNorm                     | 576   \u001b[0m\n",
      "\u001b[34m18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K \u001b[0m\n",
      "\u001b[34m19 | pre_output_gate_norm               | GateAddNorm                     | 576   \u001b[0m\n",
      "\u001b[34m20 | output_layer                       | Linear                          | 119   \u001b[0m\n",
      "\u001b[34m----------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m29.7 K    Trainable params\u001b[0m\n",
      "\u001b[34m0         Non-trainable params\u001b[0m\n",
      "\u001b[34m29.7 K    Total params\u001b[0m\n",
      "\u001b[34m0.119     Total estimated model params size (MB)\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/pytorch_lightning/utilities/data.py:60: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 350. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/pytorch_lightning/trainer/data_loading.py:433: UserWarning: The number of training samples (30) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  f\"The number of training samples ({self.num_training_batches}) is smaller than the logging interval\"\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/pytorch_lightning/utilities/data.py:60: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 128. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\u001b[0m\n",
      "\u001b[34m2022-08-22 10:22:09,044 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-08-22 10:22:52 Completed - Training job completed\n",
      "ProfilerReport-1661162732: IssuesFound\n",
      "Training seconds: 895\n",
      "Billable seconds: 895\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.debugger import TensorBoardOutputConfig\n",
    "\n",
    "\n",
    "hyperparameters = {\n",
    "        'epochs': 100,\n",
    "        'data-filename': \"stallion_data.parquet\",\n",
    "        'metadata-filename': \"stallion_metadata.json\"\n",
    "    }\n",
    "\n",
    "tensorboard_output_config = TensorBoardOutputConfig(\n",
    "    s3_output_path='s3://sagemaker-us-east-1-551329315830/tensorboard',\n",
    "    container_local_output_path='/lightning_logs'\n",
    ")\n",
    "\n",
    "spot_estimator  = PyTorch(entry_point='TFT_docker/TFT.py',\n",
    "                            dependencies=['TFT_docker/requirements.txt'],\n",
    "                            role=role,\n",
    "                            framework_version='1.7.1',\n",
    "                            py_version='py3',\n",
    "                            instance_count=1,\n",
    "#                             instance_type='local',\n",
    "#                             instance_type='ml.p3.2xlarge',\n",
    "                            instance_type='ml.p2.xlarge',\n",
    "                            base_job_name='tft-pytorch-spot-1',\n",
    "                            hyperparameters=hyperparameters,\n",
    "                            checkpoint_s3_uri=checkpoint_s3_path,\n",
    "                            debugger_hook_config=False,\n",
    "                            input_mode = 'FastFile',\n",
    "                            use_spot_instances=use_spot_instances,\n",
    "                            max_run=max_run,\n",
    "                            max_wait=max_wait,\n",
    "                            tensorboard_output_config=tensorboard_output_config\n",
    "                           )\n",
    "\n",
    "spot_estimator.fit(\n",
    "                inputs,\n",
    "                logs = 'All'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8f4aed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320952b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_estimator.latest_job_tensorboard_artifacts_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24362870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # deploy the trained model\n",
    "# predictor=estimator.deploy(1, instance_type)\n",
    "tensorflow_logs_path = \"lightning_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfaf32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_region = sagemaker_session.boto_region_name\n",
    "!AWS_REGION={aws_region}\n",
    "!echo tensorboard --logdir {tensorflow_logs_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6146cf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "!AWS_REGION=eu-east-1 tensorboard --logdir s3://sagemaker-us-east-1-551329315830/tensorboard/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
